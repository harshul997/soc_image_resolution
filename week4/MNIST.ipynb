{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee3c24b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 9912422/9912422 [00:02<00:00, 4043771.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 28881/28881 [00:00<00:00, 86053.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 1648877/1648877 [00:01<00:00, 1403006.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 4542/4542 [00:00<00:00, 1203824.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             320\n",
      "         MaxPool2d-2           [-1, 32, 14, 14]               0\n",
      "            Conv2d-3           [-1, 64, 14, 14]          18,496\n",
      "         MaxPool2d-4             [-1, 64, 7, 7]               0\n",
      "            Linear-5                  [-1, 128]         401,536\n",
      "           Dropout-6                  [-1, 128]               0\n",
      "            Linear-7                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 421,642\n",
      "Trainable params: 421,642\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.36\n",
      "Params size (MB): 1.61\n",
      "Estimated Total Size (MB): 1.97\n",
      "----------------------------------------------------------------\n",
      "Epoch: 0, Batch: 0, Loss: 2.3085784912109375\n",
      "Epoch: 0, Batch: 1, Loss: 2.242992401123047\n",
      "Epoch: 0, Batch: 2, Loss: 2.2436108589172363\n",
      "Epoch: 0, Batch: 3, Loss: 2.128464460372925\n",
      "Epoch: 0, Batch: 4, Loss: 2.173234224319458\n",
      "Epoch: 0, Batch: 5, Loss: 1.9523308277130127\n",
      "Epoch: 0, Batch: 6, Loss: 1.8356804847717285\n",
      "Epoch: 0, Batch: 7, Loss: 1.7786253690719604\n",
      "Epoch: 0, Batch: 8, Loss: 1.691626787185669\n",
      "Epoch: 0, Batch: 9, Loss: 1.4303046464920044\n",
      "Epoch: 0, Batch: 10, Loss: 1.3118044137954712\n",
      "Epoch: 0, Batch: 11, Loss: 1.2539650201797485\n",
      "Epoch: 0, Batch: 12, Loss: 1.0603493452072144\n",
      "Epoch: 0, Batch: 13, Loss: 1.442060947418213\n",
      "Epoch: 0, Batch: 14, Loss: 1.2024585008621216\n",
      "Epoch: 0, Batch: 15, Loss: 0.944945216178894\n",
      "Epoch: 0, Batch: 16, Loss: 0.9690096974372864\n",
      "Epoch: 0, Batch: 17, Loss: 0.9019312858581543\n",
      "Epoch: 0, Batch: 18, Loss: 0.8496354222297668\n",
      "Epoch: 0, Batch: 19, Loss: 1.144651174545288\n",
      "Epoch: 0, Batch: 20, Loss: 0.8331874012947083\n",
      "Epoch: 0, Batch: 21, Loss: 0.7239360809326172\n",
      "Epoch: 0, Batch: 22, Loss: 0.6869887709617615\n",
      "Epoch: 0, Batch: 23, Loss: 0.7568957805633545\n",
      "Epoch: 0, Batch: 24, Loss: 0.6531375050544739\n",
      "Epoch: 0, Batch: 25, Loss: 0.5678828358650208\n",
      "Epoch: 0, Batch: 26, Loss: 0.7298069596290588\n",
      "Epoch: 0, Batch: 27, Loss: 0.6303988695144653\n",
      "Epoch: 0, Batch: 28, Loss: 0.549788236618042\n",
      "Epoch: 0, Batch: 29, Loss: 0.4560695290565491\n",
      "Epoch: 0, Batch: 30, Loss: 0.4960421621799469\n",
      "Epoch: 0, Batch: 31, Loss: 0.5015039443969727\n",
      "Epoch: 0, Batch: 32, Loss: 0.5994827151298523\n",
      "Epoch: 0, Batch: 33, Loss: 0.8018323183059692\n",
      "Epoch: 0, Batch: 34, Loss: 0.6887911558151245\n",
      "Epoch: 0, Batch: 35, Loss: 0.3206634223461151\n",
      "Epoch: 0, Batch: 36, Loss: 0.5413261651992798\n",
      "Epoch: 0, Batch: 37, Loss: 0.4004254937171936\n",
      "Epoch: 0, Batch: 38, Loss: 0.5049301385879517\n",
      "Epoch: 0, Batch: 39, Loss: 0.4447825253009796\n",
      "Epoch: 0, Batch: 40, Loss: 0.35940563678741455\n",
      "Epoch: 0, Batch: 41, Loss: 0.37203991413116455\n",
      "Epoch: 0, Batch: 42, Loss: 0.7108644843101501\n",
      "Epoch: 0, Batch: 43, Loss: 0.20712319016456604\n",
      "Epoch: 0, Batch: 44, Loss: 0.3888339698314667\n",
      "Epoch: 0, Batch: 45, Loss: 0.6189427375793457\n",
      "Epoch: 0, Batch: 46, Loss: 0.3382479250431061\n",
      "Epoch: 0, Batch: 47, Loss: 0.4808289706707001\n",
      "Epoch: 0, Batch: 48, Loss: 0.3675484359264374\n",
      "Epoch: 0, Batch: 49, Loss: 0.4155014753341675\n",
      "Epoch: 0, Batch: 50, Loss: 0.40476083755493164\n",
      "Epoch: 0, Batch: 51, Loss: 0.22529026865959167\n",
      "Epoch: 0, Batch: 52, Loss: 0.23620392382144928\n",
      "Epoch: 0, Batch: 53, Loss: 0.4663812816143036\n",
      "Epoch: 0, Batch: 54, Loss: 0.3521399199962616\n",
      "Epoch: 0, Batch: 55, Loss: 0.427998423576355\n",
      "Epoch: 0, Batch: 56, Loss: 0.31069374084472656\n",
      "Epoch: 0, Batch: 57, Loss: 0.3645398020744324\n",
      "Epoch: 0, Batch: 58, Loss: 0.2589993178844452\n",
      "Epoch: 0, Batch: 59, Loss: 0.3320066034793854\n",
      "Epoch: 0, Batch: 60, Loss: 0.21704015135765076\n",
      "Epoch: 0, Batch: 61, Loss: 0.26766037940979004\n",
      "Epoch: 0, Batch: 62, Loss: 0.20219890773296356\n",
      "Epoch: 0, Batch: 63, Loss: 0.3420060873031616\n",
      "Epoch: 0, Batch: 64, Loss: 0.47955507040023804\n",
      "Epoch: 0, Batch: 65, Loss: 0.16817037761211395\n",
      "Epoch: 0, Batch: 66, Loss: 0.245302215218544\n",
      "Epoch: 0, Batch: 67, Loss: 0.3220427632331848\n",
      "Epoch: 0, Batch: 68, Loss: 0.36030179262161255\n",
      "Epoch: 0, Batch: 69, Loss: 0.1943196803331375\n",
      "Epoch: 0, Batch: 70, Loss: 0.25808316469192505\n",
      "Epoch: 0, Batch: 71, Loss: 0.30622461438179016\n",
      "Epoch: 0, Batch: 72, Loss: 0.18379049003124237\n",
      "Epoch: 0, Batch: 73, Loss: 0.3637244999408722\n",
      "Epoch: 0, Batch: 74, Loss: 0.24563857913017273\n",
      "Epoch: 0, Batch: 75, Loss: 0.20426996052265167\n",
      "Epoch: 0, Batch: 76, Loss: 0.31816771626472473\n",
      "Epoch: 0, Batch: 77, Loss: 0.23088368773460388\n",
      "Epoch: 0, Batch: 78, Loss: 0.4205533266067505\n",
      "Epoch: 0, Batch: 79, Loss: 0.2323964536190033\n",
      "Epoch: 0, Batch: 80, Loss: 0.46378272771835327\n",
      "Epoch: 0, Batch: 81, Loss: 0.21538145840168\n",
      "Epoch: 0, Batch: 82, Loss: 0.2179906666278839\n",
      "Epoch: 0, Batch: 83, Loss: 0.31745702028274536\n",
      "Epoch: 0, Batch: 84, Loss: 0.2409062385559082\n",
      "Epoch: 0, Batch: 85, Loss: 0.1872299611568451\n",
      "Epoch: 0, Batch: 86, Loss: 0.2591668963432312\n",
      "Epoch: 0, Batch: 87, Loss: 0.28961122035980225\n",
      "Epoch: 0, Batch: 88, Loss: 0.21850848197937012\n",
      "Epoch: 0, Batch: 89, Loss: 0.30285322666168213\n",
      "Epoch: 0, Batch: 90, Loss: 0.22340865433216095\n",
      "Epoch: 0, Batch: 91, Loss: 0.07779351621866226\n",
      "Epoch: 0, Batch: 92, Loss: 0.2422448992729187\n",
      "Epoch: 0, Batch: 93, Loss: 0.21864444017410278\n",
      "Epoch: 0, Batch: 94, Loss: 0.1978786587715149\n",
      "Epoch: 0, Batch: 95, Loss: 0.16561919450759888\n",
      "Epoch: 0, Batch: 96, Loss: 0.13680489361286163\n",
      "Epoch: 0, Batch: 97, Loss: 0.17708855867385864\n",
      "Epoch: 0, Batch: 98, Loss: 0.11820561438798904\n",
      "Epoch: 0, Batch: 99, Loss: 0.25635620951652527\n",
      "Epoch: 0, Batch: 100, Loss: 0.17543773353099823\n",
      "Epoch: 0, Batch: 101, Loss: 0.28380075097084045\n",
      "Epoch: 0, Batch: 102, Loss: 0.2090243101119995\n",
      "Epoch: 0, Batch: 103, Loss: 0.15790626406669617\n",
      "Epoch: 0, Batch: 104, Loss: 0.1583598554134369\n",
      "Epoch: 0, Batch: 105, Loss: 0.2546665072441101\n",
      "Epoch: 0, Batch: 106, Loss: 0.19209474325180054\n",
      "Epoch: 0, Batch: 107, Loss: 0.36837443709373474\n",
      "Epoch: 0, Batch: 108, Loss: 0.11893782764673233\n",
      "Epoch: 0, Batch: 109, Loss: 0.13894259929656982\n",
      "Epoch: 0, Batch: 110, Loss: 0.19349436461925507\n",
      "Epoch: 0, Batch: 111, Loss: 0.3328421711921692\n",
      "Epoch: 0, Batch: 112, Loss: 0.22742703557014465\n",
      "Epoch: 0, Batch: 113, Loss: 0.23742707073688507\n",
      "Epoch: 0, Batch: 114, Loss: 0.16997282207012177\n",
      "Epoch: 0, Batch: 115, Loss: 0.1825522631406784\n",
      "Epoch: 0, Batch: 116, Loss: 0.12954336404800415\n",
      "Epoch: 0, Batch: 117, Loss: 0.2128797173500061\n",
      "Epoch: 0, Batch: 118, Loss: 0.04544411227107048\n",
      "Epoch: 0, Batch: 119, Loss: 0.24566395580768585\n",
      "Epoch: 0, Batch: 120, Loss: 0.14416226744651794\n",
      "Epoch: 0, Batch: 121, Loss: 0.1603754162788391\n",
      "Epoch: 0, Batch: 122, Loss: 0.0638575553894043\n",
      "Epoch: 0, Batch: 123, Loss: 0.18395869433879852\n",
      "Epoch: 0, Batch: 124, Loss: 0.614675760269165\n",
      "Epoch: 0, Batch: 125, Loss: 0.1511932909488678\n",
      "Epoch: 0, Batch: 126, Loss: 0.20724982023239136\n",
      "Epoch: 0, Batch: 127, Loss: 0.2504569888114929\n",
      "Epoch: 0, Batch: 128, Loss: 0.1718897819519043\n",
      "Epoch: 0, Batch: 129, Loss: 0.5255480408668518\n",
      "Epoch: 0, Batch: 130, Loss: 0.2094637155532837\n",
      "Epoch: 0, Batch: 131, Loss: 0.2162674516439438\n",
      "Epoch: 0, Batch: 132, Loss: 0.18881221115589142\n",
      "Epoch: 0, Batch: 133, Loss: 0.14836694300174713\n",
      "Epoch: 0, Batch: 134, Loss: 0.2052856981754303\n",
      "Epoch: 0, Batch: 135, Loss: 0.23889203369617462\n",
      "Epoch: 0, Batch: 136, Loss: 0.12131747603416443\n",
      "Epoch: 0, Batch: 137, Loss: 0.24556578695774078\n",
      "Epoch: 0, Batch: 138, Loss: 0.24397340416908264\n",
      "Epoch: 0, Batch: 139, Loss: 0.17298996448516846\n",
      "Epoch: 0, Batch: 140, Loss: 0.13478732109069824\n",
      "Epoch: 0, Batch: 141, Loss: 0.1705918163061142\n",
      "Epoch: 0, Batch: 142, Loss: 0.11591407656669617\n",
      "Epoch: 0, Batch: 143, Loss: 0.06262753903865814\n",
      "Epoch: 0, Batch: 144, Loss: 0.22442223131656647\n",
      "Epoch: 0, Batch: 145, Loss: 0.36631301045417786\n",
      "Epoch: 0, Batch: 146, Loss: 0.2689461410045624\n",
      "Epoch: 0, Batch: 147, Loss: 0.24859020113945007\n",
      "Epoch: 0, Batch: 148, Loss: 0.10679338872432709\n",
      "Epoch: 0, Batch: 149, Loss: 0.15303750336170197\n",
      "Epoch: 0, Batch: 150, Loss: 0.129268079996109\n",
      "Epoch: 0, Batch: 151, Loss: 0.09929143637418747\n",
      "Epoch: 0, Batch: 152, Loss: 0.11760111898183823\n",
      "Epoch: 0, Batch: 153, Loss: 0.16226878762245178\n",
      "Epoch: 0, Batch: 154, Loss: 0.1262703835964203\n",
      "Epoch: 0, Batch: 155, Loss: 0.12678343057632446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 156, Loss: 0.0762493684887886\n",
      "Epoch: 0, Batch: 157, Loss: 0.4278678596019745\n",
      "Epoch: 0, Batch: 158, Loss: 0.39547210931777954\n",
      "Epoch: 0, Batch: 159, Loss: 0.07259298115968704\n",
      "Epoch: 0, Batch: 160, Loss: 0.04993126541376114\n",
      "Epoch: 0, Batch: 161, Loss: 0.15344206988811493\n",
      "Epoch: 0, Batch: 162, Loss: 0.20023107528686523\n",
      "Epoch: 0, Batch: 163, Loss: 0.11912524700164795\n",
      "Epoch: 0, Batch: 164, Loss: 0.19348539412021637\n",
      "Epoch: 0, Batch: 165, Loss: 0.07752583920955658\n",
      "Epoch: 0, Batch: 166, Loss: 0.19472482800483704\n",
      "Epoch: 0, Batch: 167, Loss: 0.12082517147064209\n",
      "Epoch: 0, Batch: 168, Loss: 0.08375637978315353\n",
      "Epoch: 0, Batch: 169, Loss: 0.18200159072875977\n",
      "Epoch: 0, Batch: 170, Loss: 0.09323187917470932\n",
      "Epoch: 0, Batch: 171, Loss: 0.11674588918685913\n",
      "Epoch: 0, Batch: 172, Loss: 0.23903514444828033\n",
      "Epoch: 0, Batch: 173, Loss: 0.21681813895702362\n",
      "Epoch: 0, Batch: 174, Loss: 0.09527775645256042\n",
      "Epoch: 0, Batch: 175, Loss: 0.2936694025993347\n",
      "Epoch: 0, Batch: 176, Loss: 0.2645503878593445\n",
      "Epoch: 0, Batch: 177, Loss: 0.11536113917827606\n",
      "Epoch: 0, Batch: 178, Loss: 0.16220039129257202\n",
      "Epoch: 0, Batch: 179, Loss: 0.1170298308134079\n",
      "Epoch: 0, Batch: 180, Loss: 0.36334559321403503\n",
      "Epoch: 0, Batch: 181, Loss: 0.10555116087198257\n",
      "Epoch: 0, Batch: 182, Loss: 0.16485923528671265\n",
      "Epoch: 0, Batch: 183, Loss: 0.21642376482486725\n",
      "Epoch: 0, Batch: 184, Loss: 0.09264762699604034\n",
      "Epoch: 0, Batch: 185, Loss: 0.12498234957456589\n",
      "Epoch: 0, Batch: 186, Loss: 0.08801505714654922\n",
      "Epoch: 0, Batch: 187, Loss: 0.182261124253273\n",
      "Epoch: 0, Batch: 188, Loss: 0.11274687945842743\n",
      "Epoch: 0, Batch: 189, Loss: 0.14636701345443726\n",
      "Epoch: 0, Batch: 190, Loss: 0.091949962079525\n",
      "Epoch: 0, Batch: 191, Loss: 0.0963461846113205\n",
      "Epoch: 0, Batch: 192, Loss: 0.0832642987370491\n",
      "Epoch: 0, Batch: 193, Loss: 0.12512652575969696\n",
      "Epoch: 0, Batch: 194, Loss: 0.10916570574045181\n",
      "Epoch: 0, Batch: 195, Loss: 0.1370794028043747\n",
      "Epoch: 0, Batch: 196, Loss: 0.03615671023726463\n",
      "Epoch: 0, Batch: 197, Loss: 0.2042338252067566\n",
      "Epoch: 0, Batch: 198, Loss: 0.09942594170570374\n",
      "Epoch: 0, Batch: 199, Loss: 0.1196778267621994\n",
      "Epoch: 0, Batch: 200, Loss: 0.2503995895385742\n",
      "Epoch: 0, Batch: 201, Loss: 0.18065842986106873\n",
      "Epoch: 0, Batch: 202, Loss: 0.1594848334789276\n",
      "Epoch: 0, Batch: 203, Loss: 0.07758690416812897\n",
      "Epoch: 0, Batch: 204, Loss: 0.08124615997076035\n",
      "Epoch: 0, Batch: 205, Loss: 0.08265133202075958\n",
      "Epoch: 0, Batch: 206, Loss: 0.21223965287208557\n",
      "Epoch: 0, Batch: 207, Loss: 0.3457915782928467\n",
      "Epoch: 0, Batch: 208, Loss: 0.06808498501777649\n",
      "Epoch: 0, Batch: 209, Loss: 0.09204113483428955\n",
      "Epoch: 0, Batch: 210, Loss: 0.071710504591465\n",
      "Epoch: 0, Batch: 211, Loss: 0.07564910501241684\n",
      "Epoch: 0, Batch: 212, Loss: 0.224690243601799\n",
      "Epoch: 0, Batch: 213, Loss: 0.07838735729455948\n",
      "Epoch: 0, Batch: 214, Loss: 0.20587027072906494\n",
      "Epoch: 0, Batch: 215, Loss: 0.11986692994832993\n",
      "Epoch: 0, Batch: 216, Loss: 0.23230360448360443\n",
      "Epoch: 0, Batch: 217, Loss: 0.11672329157590866\n",
      "Epoch: 0, Batch: 218, Loss: 0.1682773232460022\n",
      "Epoch: 0, Batch: 219, Loss: 0.1956188827753067\n",
      "Epoch: 0, Batch: 220, Loss: 0.14337624609470367\n",
      "Epoch: 0, Batch: 221, Loss: 0.08450475335121155\n",
      "Epoch: 0, Batch: 222, Loss: 0.044931743294000626\n",
      "Epoch: 0, Batch: 223, Loss: 0.18037599325180054\n",
      "Epoch: 0, Batch: 224, Loss: 0.07087353616952896\n",
      "Epoch: 0, Batch: 225, Loss: 0.10850418359041214\n",
      "Epoch: 0, Batch: 226, Loss: 0.1632039099931717\n",
      "Epoch: 0, Batch: 227, Loss: 0.18459424376487732\n",
      "Epoch: 0, Batch: 228, Loss: 0.15666724741458893\n",
      "Epoch: 0, Batch: 229, Loss: 0.11720655858516693\n",
      "Epoch: 0, Batch: 230, Loss: 0.1467844396829605\n",
      "Epoch: 0, Batch: 231, Loss: 0.18756987154483795\n",
      "Epoch: 0, Batch: 232, Loss: 0.15782029926776886\n",
      "Epoch: 0, Batch: 233, Loss: 0.08440452814102173\n",
      "Epoch: 0, Batch: 234, Loss: 0.12778161466121674\n",
      "Epoch: 0, Batch: 235, Loss: 0.18194545805454254\n",
      "Epoch: 0, Batch: 236, Loss: 0.26596829295158386\n",
      "Epoch: 0, Batch: 237, Loss: 0.12010373920202255\n",
      "Epoch: 0, Batch: 238, Loss: 0.20076961815357208\n",
      "Epoch: 0, Batch: 239, Loss: 0.13494883477687836\n",
      "Epoch: 0, Batch: 240, Loss: 0.040124502032995224\n",
      "Epoch: 0, Batch: 241, Loss: 0.11661446839570999\n",
      "Epoch: 0, Batch: 242, Loss: 0.11489831656217575\n",
      "Epoch: 0, Batch: 243, Loss: 0.1640838235616684\n",
      "Epoch: 0, Batch: 244, Loss: 0.2733752429485321\n",
      "Epoch: 0, Batch: 245, Loss: 0.20240849256515503\n",
      "Epoch: 0, Batch: 246, Loss: 0.20409953594207764\n",
      "Epoch: 0, Batch: 247, Loss: 0.08912600576877594\n",
      "Epoch: 0, Batch: 248, Loss: 0.07851149886846542\n",
      "Epoch: 0, Batch: 249, Loss: 0.17114335298538208\n",
      "Epoch: 0, Batch: 250, Loss: 0.20424702763557434\n",
      "Epoch: 0, Batch: 251, Loss: 0.1869075894355774\n",
      "Epoch: 0, Batch: 252, Loss: 0.0750381276011467\n",
      "Epoch: 0, Batch: 253, Loss: 0.18354156613349915\n",
      "Epoch: 0, Batch: 254, Loss: 0.14847204089164734\n",
      "Epoch: 0, Batch: 255, Loss: 0.27745330333709717\n",
      "Epoch: 0, Batch: 256, Loss: 0.1140124574303627\n",
      "Epoch: 0, Batch: 257, Loss: 0.05497483164072037\n",
      "Epoch: 0, Batch: 258, Loss: 0.13676849007606506\n",
      "Epoch: 0, Batch: 259, Loss: 0.15331517159938812\n",
      "Epoch: 0, Batch: 260, Loss: 0.1851167529821396\n",
      "Epoch: 0, Batch: 261, Loss: 0.1441175490617752\n",
      "Epoch: 0, Batch: 262, Loss: 0.11720282584428787\n",
      "Epoch: 0, Batch: 263, Loss: 0.12325163185596466\n",
      "Epoch: 0, Batch: 264, Loss: 0.07207833230495453\n",
      "Epoch: 0, Batch: 265, Loss: 0.2035580277442932\n",
      "Epoch: 0, Batch: 266, Loss: 0.18318292498588562\n",
      "Epoch: 0, Batch: 267, Loss: 0.2954622209072113\n",
      "Epoch: 0, Batch: 268, Loss: 0.1513257473707199\n",
      "Epoch: 0, Batch: 269, Loss: 0.17553706467151642\n",
      "Epoch: 0, Batch: 270, Loss: 0.07992313802242279\n",
      "Epoch: 0, Batch: 271, Loss: 0.051605913788080215\n",
      "Epoch: 0, Batch: 272, Loss: 0.17585770785808563\n",
      "Epoch: 0, Batch: 273, Loss: 0.07297506928443909\n",
      "Epoch: 0, Batch: 274, Loss: 0.07913357764482498\n",
      "Epoch: 0, Batch: 275, Loss: 0.10783980041742325\n",
      "Epoch: 0, Batch: 276, Loss: 0.26163026690483093\n",
      "Epoch: 0, Batch: 277, Loss: 0.40878844261169434\n",
      "Epoch: 0, Batch: 278, Loss: 0.10443252325057983\n",
      "Epoch: 0, Batch: 279, Loss: 0.28297996520996094\n",
      "Epoch: 0, Batch: 280, Loss: 0.07234574109315872\n",
      "Epoch: 0, Batch: 281, Loss: 0.023198453709483147\n",
      "Epoch: 0, Batch: 282, Loss: 0.1194939911365509\n",
      "Epoch: 0, Batch: 283, Loss: 0.0715266689658165\n",
      "Epoch: 0, Batch: 284, Loss: 0.07732187956571579\n",
      "Epoch: 0, Batch: 285, Loss: 0.12884382903575897\n",
      "Epoch: 0, Batch: 286, Loss: 0.17537644505500793\n",
      "Epoch: 0, Batch: 287, Loss: 0.053915511816740036\n",
      "Epoch: 0, Batch: 288, Loss: 0.09632355719804764\n",
      "Epoch: 0, Batch: 289, Loss: 0.2821948230266571\n",
      "Epoch: 0, Batch: 290, Loss: 0.15965589880943298\n",
      "Epoch: 0, Batch: 291, Loss: 0.11065894365310669\n",
      "Epoch: 0, Batch: 292, Loss: 0.1241319328546524\n",
      "Epoch: 0, Batch: 293, Loss: 0.24719727039337158\n",
      "Epoch: 0, Batch: 294, Loss: 0.29536327719688416\n",
      "Epoch: 0, Batch: 295, Loss: 0.13848906755447388\n",
      "Epoch: 0, Batch: 296, Loss: 0.07740176469087601\n",
      "Epoch: 0, Batch: 297, Loss: 0.11743602901697159\n",
      "Epoch: 0, Batch: 298, Loss: 0.14128431677818298\n",
      "Epoch: 0, Batch: 299, Loss: 0.11188224703073502\n",
      "Epoch: 0, Batch: 300, Loss: 0.12382098287343979\n",
      "Epoch: 0, Batch: 301, Loss: 0.07058197259902954\n",
      "Epoch: 0, Batch: 302, Loss: 0.056401219218969345\n",
      "Epoch: 0, Batch: 303, Loss: 0.2174970805644989\n",
      "Epoch: 0, Batch: 304, Loss: 0.12085332721471786\n",
      "Epoch: 0, Batch: 305, Loss: 0.16718491911888123\n",
      "Epoch: 0, Batch: 306, Loss: 0.09286301583051682\n",
      "Epoch: 0, Batch: 307, Loss: 0.09751296043395996\n",
      "Epoch: 0, Batch: 308, Loss: 0.037243083119392395\n",
      "Epoch: 0, Batch: 309, Loss: 0.16107510030269623\n",
      "Epoch: 0, Batch: 310, Loss: 0.14428918063640594\n",
      "Epoch: 0, Batch: 311, Loss: 0.13716042041778564\n",
      "Epoch: 0, Batch: 312, Loss: 0.05650944635272026\n",
      "Epoch: 0, Batch: 313, Loss: 0.08857554942369461\n",
      "Epoch: 0, Batch: 314, Loss: 0.2088828831911087\n",
      "Epoch: 0, Batch: 315, Loss: 0.17276617884635925\n",
      "Epoch: 0, Batch: 316, Loss: 0.22095419466495514\n",
      "Epoch: 0, Batch: 317, Loss: 0.08806975185871124\n",
      "Epoch: 0, Batch: 318, Loss: 0.166939377784729\n",
      "Epoch: 0, Batch: 319, Loss: 0.10211606323719025\n",
      "Epoch: 0, Batch: 320, Loss: 0.11634862422943115\n",
      "Epoch: 0, Batch: 321, Loss: 0.21019096672534943\n",
      "Epoch: 0, Batch: 322, Loss: 0.050802234560251236\n",
      "Epoch: 0, Batch: 323, Loss: 0.050309278070926666\n",
      "Epoch: 0, Batch: 324, Loss: 0.04314372316002846\n",
      "Epoch: 0, Batch: 325, Loss: 0.30263644456863403\n",
      "Epoch: 0, Batch: 326, Loss: 0.17156744003295898\n",
      "Epoch: 0, Batch: 327, Loss: 0.047165755182504654\n",
      "Epoch: 0, Batch: 328, Loss: 0.09159631282091141\n",
      "Epoch: 0, Batch: 329, Loss: 0.052809938788414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 330, Loss: 0.09693551063537598\n",
      "Epoch: 0, Batch: 331, Loss: 0.09602813422679901\n",
      "Epoch: 0, Batch: 332, Loss: 0.04795698821544647\n",
      "Epoch: 0, Batch: 333, Loss: 0.2895236611366272\n",
      "Epoch: 0, Batch: 334, Loss: 0.03345222771167755\n",
      "Epoch: 0, Batch: 335, Loss: 0.04837293550372124\n",
      "Epoch: 0, Batch: 336, Loss: 0.0944899469614029\n",
      "Epoch: 0, Batch: 337, Loss: 0.18609720468521118\n",
      "Epoch: 0, Batch: 338, Loss: 0.0828772783279419\n",
      "Epoch: 0, Batch: 339, Loss: 0.19208286702632904\n",
      "Epoch: 0, Batch: 340, Loss: 0.12995827198028564\n",
      "Epoch: 0, Batch: 341, Loss: 0.15184782445430756\n",
      "Epoch: 0, Batch: 342, Loss: 0.06220334768295288\n",
      "Epoch: 0, Batch: 343, Loss: 0.026688646525144577\n",
      "Epoch: 0, Batch: 344, Loss: 0.0673476904630661\n",
      "Epoch: 0, Batch: 345, Loss: 0.07647959887981415\n",
      "Epoch: 0, Batch: 346, Loss: 0.09987469762563705\n",
      "Epoch: 0, Batch: 347, Loss: 0.1262763887643814\n",
      "Epoch: 0, Batch: 348, Loss: 0.09351664781570435\n",
      "Epoch: 0, Batch: 349, Loss: 0.08169000595808029\n",
      "Epoch: 0, Batch: 350, Loss: 0.027732348069548607\n",
      "Epoch: 0, Batch: 351, Loss: 0.07785909622907639\n",
      "Epoch: 0, Batch: 352, Loss: 0.11731608211994171\n",
      "Epoch: 0, Batch: 353, Loss: 0.05823097005486488\n",
      "Epoch: 0, Batch: 354, Loss: 0.11470428109169006\n",
      "Epoch: 0, Batch: 355, Loss: 0.11977368593215942\n",
      "Epoch: 0, Batch: 356, Loss: 0.026382258161902428\n",
      "Epoch: 0, Batch: 357, Loss: 0.10716027766466141\n",
      "Epoch: 0, Batch: 358, Loss: 0.17547927796840668\n",
      "Epoch: 0, Batch: 359, Loss: 0.03301708400249481\n",
      "Epoch: 0, Batch: 360, Loss: 0.12143563479185104\n",
      "Epoch: 0, Batch: 361, Loss: 0.11901518702507019\n",
      "Epoch: 0, Batch: 362, Loss: 0.1019560694694519\n",
      "Epoch: 0, Batch: 363, Loss: 0.12565582990646362\n",
      "Epoch: 0, Batch: 364, Loss: 0.027993321418762207\n",
      "Epoch: 0, Batch: 365, Loss: 0.08641670644283295\n",
      "Epoch: 0, Batch: 366, Loss: 0.18315953016281128\n",
      "Epoch: 0, Batch: 367, Loss: 0.0966804027557373\n",
      "Epoch: 0, Batch: 368, Loss: 0.00946797989308834\n",
      "Epoch: 0, Batch: 369, Loss: 0.06283286958932877\n",
      "Epoch: 0, Batch: 370, Loss: 0.06803204119205475\n",
      "Epoch: 0, Batch: 371, Loss: 0.04239306226372719\n",
      "Epoch: 0, Batch: 372, Loss: 0.12140439450740814\n",
      "Epoch: 0, Batch: 373, Loss: 0.13220283389091492\n",
      "Epoch: 0, Batch: 374, Loss: 0.10808425396680832\n",
      "Epoch: 0, Batch: 375, Loss: 0.03638814389705658\n",
      "Epoch: 0, Batch: 376, Loss: 0.07849892228841782\n",
      "Epoch: 0, Batch: 377, Loss: 0.16887755692005157\n",
      "Epoch: 0, Batch: 378, Loss: 0.23194515705108643\n",
      "Epoch: 0, Batch: 379, Loss: 0.0704401358962059\n",
      "Epoch: 0, Batch: 380, Loss: 0.09472867846488953\n",
      "Epoch: 0, Batch: 381, Loss: 0.024839235469698906\n",
      "Epoch: 0, Batch: 382, Loss: 0.04673781245946884\n",
      "Epoch: 0, Batch: 383, Loss: 0.07540856301784515\n",
      "Epoch: 0, Batch: 384, Loss: 0.12912829220294952\n",
      "Epoch: 0, Batch: 385, Loss: 0.048728104680776596\n",
      "Epoch: 0, Batch: 386, Loss: 0.08026951551437378\n",
      "Epoch: 0, Batch: 387, Loss: 0.07863505929708481\n",
      "Epoch: 0, Batch: 388, Loss: 0.1895262598991394\n",
      "Epoch: 0, Batch: 389, Loss: 0.033669427037239075\n",
      "Epoch: 0, Batch: 390, Loss: 0.19630254805088043\n",
      "Epoch: 0, Batch: 391, Loss: 0.24579577147960663\n",
      "Epoch: 0, Batch: 392, Loss: 0.029748287051916122\n",
      "Epoch: 0, Batch: 393, Loss: 0.04407380893826485\n",
      "Epoch: 0, Batch: 394, Loss: 0.0873643234372139\n",
      "Epoch: 0, Batch: 395, Loss: 0.16789144277572632\n",
      "Epoch: 0, Batch: 396, Loss: 0.16819129884243011\n",
      "Epoch: 0, Batch: 397, Loss: 0.05202847346663475\n",
      "Epoch: 0, Batch: 398, Loss: 0.11906778812408447\n",
      "Epoch: 0, Batch: 399, Loss: 0.08400879055261612\n",
      "Epoch: 0, Batch: 400, Loss: 0.04436344653367996\n",
      "Epoch: 0, Batch: 401, Loss: 0.11638343334197998\n",
      "Epoch: 0, Batch: 402, Loss: 0.11709022521972656\n",
      "Epoch: 0, Batch: 403, Loss: 0.21716932952404022\n",
      "Epoch: 0, Batch: 404, Loss: 0.04780939221382141\n",
      "Epoch: 0, Batch: 405, Loss: 0.07783441990613937\n",
      "Epoch: 0, Batch: 406, Loss: 0.021704910323023796\n",
      "Epoch: 0, Batch: 407, Loss: 0.12460849434137344\n",
      "Epoch: 0, Batch: 408, Loss: 0.4265138804912567\n",
      "Epoch: 0, Batch: 409, Loss: 0.13740018010139465\n",
      "Epoch: 0, Batch: 410, Loss: 0.10168353468179703\n",
      "Epoch: 0, Batch: 411, Loss: 0.11675985902547836\n",
      "Epoch: 0, Batch: 412, Loss: 0.05369338020682335\n",
      "Epoch: 0, Batch: 413, Loss: 0.21789585053920746\n",
      "Epoch: 0, Batch: 414, Loss: 0.16777868568897247\n",
      "Epoch: 0, Batch: 415, Loss: 0.05955610051751137\n",
      "Epoch: 0, Batch: 416, Loss: 0.026118537411093712\n",
      "Epoch: 0, Batch: 417, Loss: 0.05431194603443146\n",
      "Epoch: 0, Batch: 418, Loss: 0.043897613883018494\n",
      "Epoch: 0, Batch: 419, Loss: 0.12024842947721481\n",
      "Epoch: 0, Batch: 420, Loss: 0.05766214057803154\n",
      "Epoch: 0, Batch: 421, Loss: 0.1179904043674469\n",
      "Epoch: 0, Batch: 422, Loss: 0.06606661528348923\n",
      "Epoch: 0, Batch: 423, Loss: 0.10882861167192459\n",
      "Epoch: 0, Batch: 424, Loss: 0.030642976984381676\n",
      "Epoch: 0, Batch: 425, Loss: 0.056572772562503815\n",
      "Epoch: 0, Batch: 426, Loss: 0.07387421280145645\n",
      "Epoch: 0, Batch: 427, Loss: 0.04956890270113945\n",
      "Epoch: 0, Batch: 428, Loss: 0.09254832565784454\n",
      "Epoch: 0, Batch: 429, Loss: 0.06927009671926498\n",
      "Epoch: 0, Batch: 430, Loss: 0.061705976724624634\n",
      "Epoch: 0, Batch: 431, Loss: 0.05272439867258072\n",
      "Epoch: 0, Batch: 432, Loss: 0.17792047560214996\n",
      "Epoch: 0, Batch: 433, Loss: 0.2185114026069641\n",
      "Epoch: 0, Batch: 434, Loss: 0.07820545136928558\n",
      "Epoch: 0, Batch: 435, Loss: 0.026294123381376266\n",
      "Epoch: 0, Batch: 436, Loss: 0.11488817632198334\n",
      "Epoch: 0, Batch: 437, Loss: 0.06265471875667572\n",
      "Epoch: 0, Batch: 438, Loss: 0.018838705494999886\n",
      "Epoch: 0, Batch: 439, Loss: 0.08500407636165619\n",
      "Epoch: 0, Batch: 440, Loss: 0.059648267924785614\n",
      "Epoch: 0, Batch: 441, Loss: 0.0852341428399086\n",
      "Epoch: 0, Batch: 442, Loss: 0.200155109167099\n",
      "Epoch: 0, Batch: 443, Loss: 0.0793200358748436\n",
      "Epoch: 0, Batch: 444, Loss: 0.038766540586948395\n",
      "Epoch: 0, Batch: 445, Loss: 0.070208840072155\n",
      "Epoch: 0, Batch: 446, Loss: 0.10683409869670868\n",
      "Epoch: 0, Batch: 447, Loss: 0.03463561087846756\n",
      "Epoch: 0, Batch: 448, Loss: 0.022771639749407768\n",
      "Epoch: 0, Batch: 449, Loss: 0.045177266001701355\n",
      "Epoch: 0, Batch: 450, Loss: 0.1006002277135849\n",
      "Epoch: 0, Batch: 451, Loss: 0.08333946764469147\n",
      "Epoch: 0, Batch: 452, Loss: 0.16756397485733032\n",
      "Epoch: 0, Batch: 453, Loss: 0.10011735558509827\n",
      "Epoch: 0, Batch: 454, Loss: 0.043508607894182205\n",
      "Epoch: 0, Batch: 455, Loss: 0.11251338571310043\n",
      "Epoch: 0, Batch: 456, Loss: 0.1467823088169098\n",
      "Epoch: 0, Batch: 457, Loss: 0.07900073379278183\n",
      "Epoch: 0, Batch: 458, Loss: 0.03766237571835518\n",
      "Epoch: 0, Batch: 459, Loss: 0.08547762036323547\n",
      "Epoch: 0, Batch: 460, Loss: 0.0742587149143219\n",
      "Epoch: 0, Batch: 461, Loss: 0.03917423635721207\n",
      "Epoch: 0, Batch: 462, Loss: 0.04563358798623085\n",
      "Epoch: 0, Batch: 463, Loss: 0.09047825634479523\n",
      "Epoch: 0, Batch: 464, Loss: 0.10215821117162704\n",
      "Epoch: 0, Batch: 465, Loss: 0.02759196050465107\n",
      "Epoch: 0, Batch: 466, Loss: 0.10792667418718338\n",
      "Epoch: 0, Batch: 467, Loss: 0.1638553887605667\n",
      "Epoch: 0, Batch: 468, Loss: 0.0657816231250763\n",
      "Epoch: 0, Batch: 469, Loss: 0.09045829623937607\n",
      "Epoch: 0, Batch: 470, Loss: 0.05204861983656883\n",
      "Epoch: 0, Batch: 471, Loss: 0.05632196366786957\n",
      "Epoch: 0, Batch: 472, Loss: 0.22129349410533905\n",
      "Epoch: 0, Batch: 473, Loss: 0.09430602937936783\n",
      "Epoch: 0, Batch: 474, Loss: 0.03420738875865936\n",
      "Epoch: 0, Batch: 475, Loss: 0.03753514215350151\n",
      "Epoch: 0, Batch: 476, Loss: 0.14334513247013092\n",
      "Epoch: 0, Batch: 477, Loss: 0.10678243637084961\n",
      "Epoch: 0, Batch: 478, Loss: 0.07569113373756409\n",
      "Epoch: 0, Batch: 479, Loss: 0.13871869444847107\n",
      "Epoch: 0, Batch: 480, Loss: 0.08597086369991302\n",
      "Epoch: 0, Batch: 481, Loss: 0.05973175913095474\n",
      "Epoch: 0, Batch: 482, Loss: 0.03155328333377838\n",
      "Epoch: 0, Batch: 483, Loss: 0.06633571535348892\n",
      "Epoch: 0, Batch: 484, Loss: 0.05439507216215134\n",
      "Epoch: 0, Batch: 485, Loss: 0.012298813089728355\n",
      "Epoch: 0, Batch: 486, Loss: 0.12403292208909988\n",
      "Epoch: 0, Batch: 487, Loss: 0.22175127267837524\n",
      "Epoch: 0, Batch: 488, Loss: 0.15824541449546814\n",
      "Epoch: 0, Batch: 489, Loss: 0.14101220667362213\n",
      "Epoch: 0, Batch: 490, Loss: 0.05173604562878609\n",
      "Epoch: 0, Batch: 491, Loss: 0.12401644885540009\n",
      "Epoch: 0, Batch: 492, Loss: 0.09083034098148346\n",
      "Epoch: 0, Batch: 493, Loss: 0.01088696252554655\n",
      "Epoch: 0, Batch: 494, Loss: 0.045727040618658066\n",
      "Epoch: 0, Batch: 495, Loss: 0.06349427253007889\n",
      "Epoch: 0, Batch: 496, Loss: 0.15580761432647705\n",
      "Epoch: 0, Batch: 497, Loss: 0.24323879182338715\n",
      "Epoch: 0, Batch: 498, Loss: 0.04367256909608841\n",
      "Epoch: 0, Batch: 499, Loss: 0.04480255767703056\n",
      "Epoch: 0, Batch: 500, Loss: 0.12967367470264435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 501, Loss: 0.05201299116015434\n",
      "Epoch: 0, Batch: 502, Loss: 0.04692130535840988\n",
      "Epoch: 0, Batch: 503, Loss: 0.03077039308845997\n",
      "Epoch: 0, Batch: 504, Loss: 0.03790997713804245\n",
      "Epoch: 0, Batch: 505, Loss: 0.13534227013587952\n",
      "Epoch: 0, Batch: 506, Loss: 0.04441148415207863\n",
      "Epoch: 0, Batch: 507, Loss: 0.1885419338941574\n",
      "Epoch: 0, Batch: 508, Loss: 0.12947556376457214\n",
      "Epoch: 0, Batch: 509, Loss: 0.06541029363870621\n",
      "Epoch: 0, Batch: 510, Loss: 0.04081672057509422\n",
      "Epoch: 0, Batch: 511, Loss: 0.07257766276597977\n",
      "Epoch: 0, Batch: 512, Loss: 0.029802221804857254\n",
      "Epoch: 0, Batch: 513, Loss: 0.18926943838596344\n",
      "Epoch: 0, Batch: 514, Loss: 0.03914489969611168\n",
      "Epoch: 0, Batch: 515, Loss: 0.0862589180469513\n",
      "Epoch: 0, Batch: 516, Loss: 0.10972937196493149\n",
      "Epoch: 0, Batch: 517, Loss: 0.04697035998106003\n",
      "Epoch: 0, Batch: 518, Loss: 0.053659092634916306\n",
      "Epoch: 0, Batch: 519, Loss: 0.04062135890126228\n",
      "Epoch: 0, Batch: 520, Loss: 0.17192037403583527\n",
      "Epoch: 0, Batch: 521, Loss: 0.07685534656047821\n",
      "Epoch: 0, Batch: 522, Loss: 0.068341925740242\n",
      "Epoch: 0, Batch: 523, Loss: 0.15580517053604126\n",
      "Epoch: 0, Batch: 524, Loss: 0.1173911988735199\n",
      "Epoch: 0, Batch: 525, Loss: 0.02249709889292717\n",
      "Epoch: 0, Batch: 526, Loss: 0.06687192618846893\n",
      "Epoch: 0, Batch: 527, Loss: 0.08198978006839752\n",
      "Epoch: 0, Batch: 528, Loss: 0.02463659644126892\n",
      "Epoch: 0, Batch: 529, Loss: 0.12430490553379059\n",
      "Epoch: 0, Batch: 530, Loss: 0.09783170372247696\n",
      "Epoch: 0, Batch: 531, Loss: 0.1048111841082573\n",
      "Epoch: 0, Batch: 532, Loss: 0.07338134199380875\n",
      "Epoch: 0, Batch: 533, Loss: 0.0793161615729332\n",
      "Epoch: 0, Batch: 534, Loss: 0.042207006365060806\n",
      "Epoch: 0, Batch: 535, Loss: 0.07654453814029694\n",
      "Epoch: 0, Batch: 536, Loss: 0.01909615658223629\n",
      "Epoch: 0, Batch: 537, Loss: 0.06822498887777328\n",
      "Epoch: 0, Batch: 538, Loss: 0.13744941353797913\n",
      "Epoch: 0, Batch: 539, Loss: 0.12173714488744736\n",
      "Epoch: 0, Batch: 540, Loss: 0.04068003594875336\n",
      "Epoch: 0, Batch: 541, Loss: 0.013091634027659893\n",
      "Epoch: 0, Batch: 542, Loss: 0.09595607221126556\n",
      "Epoch: 0, Batch: 543, Loss: 0.17576192319393158\n",
      "Epoch: 0, Batch: 544, Loss: 0.07142245769500732\n",
      "Epoch: 0, Batch: 545, Loss: 0.20926342904567719\n",
      "Epoch: 0, Batch: 546, Loss: 0.17671898007392883\n",
      "Epoch: 0, Batch: 547, Loss: 0.06933010369539261\n",
      "Epoch: 0, Batch: 548, Loss: 0.03520906716585159\n",
      "Epoch: 0, Batch: 549, Loss: 0.13405096530914307\n",
      "Epoch: 0, Batch: 550, Loss: 0.09477631002664566\n",
      "Epoch: 0, Batch: 551, Loss: 0.035241663455963135\n",
      "Epoch: 0, Batch: 552, Loss: 0.08964920789003372\n",
      "Epoch: 0, Batch: 553, Loss: 0.20619121193885803\n",
      "Epoch: 0, Batch: 554, Loss: 0.007049615029245615\n",
      "Epoch: 0, Batch: 555, Loss: 0.1984022557735443\n",
      "Epoch: 0, Batch: 556, Loss: 0.07791135460138321\n",
      "Epoch: 0, Batch: 557, Loss: 0.060231320559978485\n",
      "Epoch: 0, Batch: 558, Loss: 0.025349242612719536\n",
      "Epoch: 0, Batch: 559, Loss: 0.04923935607075691\n",
      "Epoch: 0, Batch: 560, Loss: 0.03072284534573555\n",
      "Epoch: 0, Batch: 561, Loss: 0.15875621140003204\n",
      "Epoch: 0, Batch: 562, Loss: 0.032156527042388916\n",
      "Epoch: 0, Batch: 563, Loss: 0.03422311320900917\n",
      "Epoch: 0, Batch: 564, Loss: 0.1024315357208252\n",
      "Epoch: 0, Batch: 565, Loss: 0.13855144381523132\n",
      "Epoch: 0, Batch: 566, Loss: 0.07431790977716446\n",
      "Epoch: 0, Batch: 567, Loss: 0.09421414136886597\n",
      "Epoch: 0, Batch: 568, Loss: 0.05855070427060127\n",
      "Epoch: 0, Batch: 569, Loss: 0.17495256662368774\n",
      "Epoch: 0, Batch: 570, Loss: 0.11373070627450943\n",
      "Epoch: 0, Batch: 571, Loss: 0.06970745325088501\n",
      "Epoch: 0, Batch: 572, Loss: 0.09565573930740356\n",
      "Epoch: 0, Batch: 573, Loss: 0.13569246232509613\n",
      "Epoch: 0, Batch: 574, Loss: 0.11158952862024307\n",
      "Epoch: 0, Batch: 575, Loss: 0.09101562201976776\n",
      "Epoch: 0, Batch: 576, Loss: 0.17804743349552155\n",
      "Epoch: 0, Batch: 577, Loss: 0.0696134865283966\n",
      "Epoch: 0, Batch: 578, Loss: 0.07965703308582306\n",
      "Epoch: 0, Batch: 579, Loss: 0.14166054129600525\n",
      "Epoch: 0, Batch: 580, Loss: 0.009933210909366608\n",
      "Epoch: 0, Batch: 581, Loss: 0.182892307639122\n",
      "Epoch: 0, Batch: 582, Loss: 0.04490266367793083\n",
      "Epoch: 0, Batch: 583, Loss: 0.04389107972383499\n",
      "Epoch: 0, Batch: 584, Loss: 0.026585284620523453\n",
      "Epoch: 0, Batch: 585, Loss: 0.05976715683937073\n",
      "Epoch: 0, Batch: 586, Loss: 0.04696455970406532\n",
      "Epoch: 0, Batch: 587, Loss: 0.029718754813075066\n",
      "Epoch: 0, Batch: 588, Loss: 0.038136985152959824\n",
      "Epoch: 0, Batch: 589, Loss: 0.05424467474222183\n",
      "Epoch: 0, Batch: 590, Loss: 0.07472532987594604\n",
      "Epoch: 0, Batch: 591, Loss: 0.15652845799922943\n",
      "Epoch: 0, Batch: 592, Loss: 0.05402734503149986\n",
      "Epoch: 0, Batch: 593, Loss: 0.00923898909240961\n",
      "Epoch: 0, Batch: 594, Loss: 0.04818372800946236\n",
      "Epoch: 0, Batch: 595, Loss: 0.025702694430947304\n",
      "Epoch: 0, Batch: 596, Loss: 0.44998154044151306\n",
      "Epoch: 0, Batch: 597, Loss: 0.2715624272823334\n",
      "Epoch: 0, Batch: 598, Loss: 0.13802506029605865\n",
      "Epoch: 0, Batch: 599, Loss: 0.046464476734399796\n",
      "Epoch: 0, Batch: 600, Loss: 0.013451832346618176\n",
      "Epoch: 0, Batch: 601, Loss: 0.07411850243806839\n",
      "Epoch: 0, Batch: 602, Loss: 0.045188482850790024\n",
      "Epoch: 0, Batch: 603, Loss: 0.14882566034793854\n",
      "Epoch: 0, Batch: 604, Loss: 0.03708771616220474\n",
      "Epoch: 0, Batch: 605, Loss: 0.016049865633249283\n",
      "Epoch: 0, Batch: 606, Loss: 0.10228799283504486\n",
      "Epoch: 0, Batch: 607, Loss: 0.063703753054142\n",
      "Epoch: 0, Batch: 608, Loss: 0.06626985222101212\n",
      "Epoch: 0, Batch: 609, Loss: 0.1086602658033371\n",
      "Epoch: 0, Batch: 610, Loss: 0.08426222205162048\n",
      "Epoch: 0, Batch: 611, Loss: 0.02914527617394924\n",
      "Epoch: 0, Batch: 612, Loss: 0.11559993773698807\n",
      "Epoch: 0, Batch: 613, Loss: 0.062448881566524506\n",
      "Epoch: 0, Batch: 614, Loss: 0.04866601154208183\n",
      "Epoch: 0, Batch: 615, Loss: 0.06598494201898575\n",
      "Epoch: 0, Batch: 616, Loss: 0.038928400725126266\n",
      "Epoch: 0, Batch: 617, Loss: 0.025742756202816963\n",
      "Epoch: 0, Batch: 618, Loss: 0.061817556619644165\n",
      "Epoch: 0, Batch: 619, Loss: 0.029907681047916412\n",
      "Epoch: 0, Batch: 620, Loss: 0.07318218797445297\n",
      "Epoch: 0, Batch: 621, Loss: 0.05799912288784981\n",
      "Epoch: 0, Batch: 622, Loss: 0.20850595831871033\n",
      "Epoch: 0, Batch: 623, Loss: 0.031231921166181564\n",
      "Epoch: 0, Batch: 624, Loss: 0.03181646764278412\n",
      "Epoch: 0, Batch: 625, Loss: 0.11838994175195694\n",
      "Epoch: 0, Batch: 626, Loss: 0.09077006578445435\n",
      "Epoch: 0, Batch: 627, Loss: 0.08586395531892776\n",
      "Epoch: 0, Batch: 628, Loss: 0.04536016285419464\n",
      "Epoch: 0, Batch: 629, Loss: 0.10453527420759201\n",
      "Epoch: 0, Batch: 630, Loss: 0.014024985954165459\n",
      "Epoch: 0, Batch: 631, Loss: 0.08839279413223267\n",
      "Epoch: 0, Batch: 632, Loss: 0.013773678801953793\n",
      "Epoch: 0, Batch: 633, Loss: 0.0914919525384903\n",
      "Epoch: 0, Batch: 634, Loss: 0.12133569270372391\n",
      "Epoch: 0, Batch: 635, Loss: 0.08294158428907394\n",
      "Epoch: 0, Batch: 636, Loss: 0.24888594448566437\n",
      "Epoch: 0, Batch: 637, Loss: 0.1402357965707779\n",
      "Epoch: 0, Batch: 638, Loss: 0.05040876567363739\n",
      "Epoch: 0, Batch: 639, Loss: 0.05013732239603996\n",
      "Epoch: 0, Batch: 640, Loss: 0.24444541335105896\n",
      "Epoch: 0, Batch: 641, Loss: 0.055245570838451385\n",
      "Epoch: 0, Batch: 642, Loss: 0.15539899468421936\n",
      "Epoch: 0, Batch: 643, Loss: 0.11465935409069061\n",
      "Epoch: 0, Batch: 644, Loss: 0.14052528142929077\n",
      "Epoch: 0, Batch: 645, Loss: 0.2156188040971756\n",
      "Epoch: 0, Batch: 646, Loss: 0.06118237227201462\n",
      "Epoch: 0, Batch: 647, Loss: 0.06309941411018372\n",
      "Epoch: 0, Batch: 648, Loss: 0.16750568151474\n",
      "Epoch: 0, Batch: 649, Loss: 0.1618022471666336\n",
      "Epoch: 0, Batch: 650, Loss: 0.05728020519018173\n",
      "Epoch: 0, Batch: 651, Loss: 0.17407874763011932\n",
      "Epoch: 0, Batch: 652, Loss: 0.03279384598135948\n",
      "Epoch: 0, Batch: 653, Loss: 0.08431265503168106\n",
      "Epoch: 0, Batch: 654, Loss: 0.1629340648651123\n",
      "Epoch: 0, Batch: 655, Loss: 0.013040821999311447\n",
      "Epoch: 0, Batch: 656, Loss: 0.05822550877928734\n",
      "Epoch: 0, Batch: 657, Loss: 0.09912628680467606\n",
      "Epoch: 0, Batch: 658, Loss: 0.07607821375131607\n",
      "Epoch: 0, Batch: 659, Loss: 0.15565696358680725\n",
      "Epoch: 0, Batch: 660, Loss: 0.03938768804073334\n",
      "Epoch: 0, Batch: 661, Loss: 0.14300571382045746\n",
      "Epoch: 0, Batch: 662, Loss: 0.09807941317558289\n",
      "Epoch: 0, Batch: 663, Loss: 0.1741480976343155\n",
      "Epoch: 0, Batch: 664, Loss: 0.11755266785621643\n",
      "Epoch: 0, Batch: 665, Loss: 0.07959136366844177\n",
      "Epoch: 0, Batch: 666, Loss: 0.03888662904500961\n",
      "Epoch: 0, Batch: 667, Loss: 0.08523070812225342\n",
      "Epoch: 0, Batch: 668, Loss: 0.04684489592909813\n",
      "Epoch: 0, Batch: 669, Loss: 0.02722274325788021\n",
      "Epoch: 0, Batch: 670, Loss: 0.10392910987138748\n",
      "Epoch: 0, Batch: 671, Loss: 0.049635112285614014\n",
      "Epoch: 0, Batch: 672, Loss: 0.017141124233603477\n",
      "Epoch: 0, Batch: 673, Loss: 0.12776963412761688\n",
      "Epoch: 0, Batch: 674, Loss: 0.05103142932057381\n",
      "Epoch: 0, Batch: 675, Loss: 0.07250688225030899\n",
      "Epoch: 0, Batch: 676, Loss: 0.14927423000335693\n",
      "Epoch: 0, Batch: 677, Loss: 0.03272092714905739\n",
      "Epoch: 0, Batch: 678, Loss: 0.06808456778526306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 679, Loss: 0.12728175520896912\n",
      "Epoch: 0, Batch: 680, Loss: 0.09096041321754456\n",
      "Epoch: 0, Batch: 681, Loss: 0.052911702543497086\n",
      "Epoch: 0, Batch: 682, Loss: 0.020086847245693207\n",
      "Epoch: 0, Batch: 683, Loss: 0.012474419549107552\n",
      "Epoch: 0, Batch: 684, Loss: 0.04990432411432266\n",
      "Epoch: 0, Batch: 685, Loss: 0.14555755257606506\n",
      "Epoch: 0, Batch: 686, Loss: 0.15176358819007874\n",
      "Epoch: 0, Batch: 687, Loss: 0.17761431634426117\n",
      "Epoch: 0, Batch: 688, Loss: 0.013439756818115711\n",
      "Epoch: 0, Batch: 689, Loss: 0.016536861658096313\n",
      "Epoch: 0, Batch: 690, Loss: 0.04502809792757034\n",
      "Epoch: 0, Batch: 691, Loss: 0.0752691924571991\n",
      "Epoch: 0, Batch: 692, Loss: 0.11884789168834686\n",
      "Epoch: 0, Batch: 693, Loss: 0.17623892426490784\n",
      "Epoch: 0, Batch: 694, Loss: 0.03982635587453842\n",
      "Epoch: 0, Batch: 695, Loss: 0.02149164490401745\n",
      "Epoch: 0, Batch: 696, Loss: 0.022953394800424576\n",
      "Epoch: 0, Batch: 697, Loss: 0.1676417887210846\n",
      "Epoch: 0, Batch: 698, Loss: 0.13446007668972015\n",
      "Epoch: 0, Batch: 699, Loss: 0.09063028544187546\n",
      "Epoch: 0, Batch: 700, Loss: 0.11890760064125061\n",
      "Epoch: 0, Batch: 701, Loss: 0.05240625888109207\n",
      "Epoch: 0, Batch: 702, Loss: 0.020145177841186523\n",
      "Epoch: 0, Batch: 703, Loss: 0.06423861533403397\n",
      "Epoch: 0, Batch: 704, Loss: 0.019159425050020218\n",
      "Epoch: 0, Batch: 705, Loss: 0.013779847882688046\n",
      "Epoch: 0, Batch: 706, Loss: 0.11394563317298889\n",
      "Epoch: 0, Batch: 707, Loss: 0.054004356265068054\n",
      "Epoch: 0, Batch: 708, Loss: 0.1289706975221634\n",
      "Epoch: 0, Batch: 709, Loss: 0.0168375913053751\n",
      "Epoch: 0, Batch: 710, Loss: 0.07527828961610794\n",
      "Epoch: 0, Batch: 711, Loss: 0.08266355842351913\n",
      "Epoch: 0, Batch: 712, Loss: 0.045579902827739716\n",
      "Epoch: 0, Batch: 713, Loss: 0.04658643156290054\n",
      "Epoch: 0, Batch: 714, Loss: 0.04135406017303467\n",
      "Epoch: 0, Batch: 715, Loss: 0.020231543108820915\n",
      "Epoch: 0, Batch: 716, Loss: 0.08286096900701523\n",
      "Epoch: 0, Batch: 717, Loss: 0.048189807683229446\n",
      "Epoch: 0, Batch: 718, Loss: 0.1135592982172966\n",
      "Epoch: 0, Batch: 719, Loss: 0.05385541915893555\n",
      "Epoch: 0, Batch: 720, Loss: 0.051756296306848526\n",
      "Epoch: 0, Batch: 721, Loss: 0.08077878504991531\n",
      "Epoch: 0, Batch: 722, Loss: 0.03719502314925194\n",
      "Epoch: 0, Batch: 723, Loss: 0.07033588737249374\n",
      "Epoch: 0, Batch: 724, Loss: 0.03141641244292259\n",
      "Epoch: 0, Batch: 725, Loss: 0.18377940356731415\n",
      "Epoch: 0, Batch: 726, Loss: 0.09779033809900284\n",
      "Epoch: 0, Batch: 727, Loss: 0.059144265949726105\n",
      "Epoch: 0, Batch: 728, Loss: 0.12532225251197815\n",
      "Epoch: 0, Batch: 729, Loss: 0.14950606226921082\n",
      "Epoch: 0, Batch: 730, Loss: 0.06765841692686081\n",
      "Epoch: 0, Batch: 731, Loss: 0.03608690947294235\n",
      "Epoch: 0, Batch: 732, Loss: 0.02114083431661129\n",
      "Epoch: 0, Batch: 733, Loss: 0.200267493724823\n",
      "Epoch: 0, Batch: 734, Loss: 0.05995786190032959\n",
      "Epoch: 0, Batch: 735, Loss: 0.1874377727508545\n",
      "Epoch: 0, Batch: 736, Loss: 0.04024699702858925\n",
      "Epoch: 0, Batch: 737, Loss: 0.1056400015950203\n",
      "Epoch: 0, Batch: 738, Loss: 0.09302584081888199\n",
      "Epoch: 0, Batch: 739, Loss: 0.024661490693688393\n",
      "Epoch: 0, Batch: 740, Loss: 0.027062449604272842\n",
      "Epoch: 0, Batch: 741, Loss: 0.1437435895204544\n",
      "Epoch: 0, Batch: 742, Loss: 0.05598745122551918\n",
      "Epoch: 0, Batch: 743, Loss: 0.024496562778949738\n",
      "Epoch: 0, Batch: 744, Loss: 0.04125693440437317\n",
      "Epoch: 0, Batch: 745, Loss: 0.20455974340438843\n",
      "Epoch: 0, Batch: 746, Loss: 0.06322171539068222\n",
      "Epoch: 0, Batch: 747, Loss: 0.01580880396068096\n",
      "Epoch: 0, Batch: 748, Loss: 0.07742580771446228\n",
      "Epoch: 0, Batch: 749, Loss: 0.04544216766953468\n",
      "Epoch: 0, Batch: 750, Loss: 0.14095741510391235\n",
      "Epoch: 0, Batch: 751, Loss: 0.05805186554789543\n",
      "Epoch: 0, Batch: 752, Loss: 0.0429408960044384\n",
      "Epoch: 0, Batch: 753, Loss: 0.02029113471508026\n",
      "Epoch: 0, Batch: 754, Loss: 0.16825754940509796\n",
      "Epoch: 0, Batch: 755, Loss: 0.1188192293047905\n",
      "Epoch: 0, Batch: 756, Loss: 0.06859458237886429\n",
      "Epoch: 0, Batch: 757, Loss: 0.15632756054401398\n",
      "Epoch: 0, Batch: 758, Loss: 0.087655209004879\n",
      "Epoch: 0, Batch: 759, Loss: 0.039218250662088394\n",
      "Epoch: 0, Batch: 760, Loss: 0.10146985948085785\n",
      "Epoch: 0, Batch: 761, Loss: 0.1563376486301422\n",
      "Epoch: 0, Batch: 762, Loss: 0.14734245836734772\n",
      "Epoch: 0, Batch: 763, Loss: 0.09484198689460754\n",
      "Epoch: 0, Batch: 764, Loss: 0.027293145656585693\n",
      "Epoch: 0, Batch: 765, Loss: 0.15396881103515625\n",
      "Epoch: 0, Batch: 766, Loss: 0.04340038821101189\n",
      "Epoch: 0, Batch: 767, Loss: 0.16428260505199432\n",
      "Epoch: 0, Batch: 768, Loss: 0.06680625677108765\n",
      "Epoch: 0, Batch: 769, Loss: 0.03673107922077179\n",
      "Epoch: 0, Batch: 770, Loss: 0.10225502401590347\n",
      "Epoch: 0, Batch: 771, Loss: 0.021131200715899467\n",
      "Epoch: 0, Batch: 772, Loss: 0.11089375615119934\n",
      "Epoch: 0, Batch: 773, Loss: 0.09139809757471085\n",
      "Epoch: 0, Batch: 774, Loss: 0.014579200185835361\n",
      "Epoch: 0, Batch: 775, Loss: 0.15568213164806366\n",
      "Epoch: 0, Batch: 776, Loss: 0.024789512157440186\n",
      "Epoch: 0, Batch: 777, Loss: 0.00703405262902379\n",
      "Epoch: 0, Batch: 778, Loss: 0.01513663213700056\n",
      "Epoch: 0, Batch: 779, Loss: 0.0508161298930645\n",
      "Epoch: 0, Batch: 780, Loss: 0.03254304453730583\n",
      "Epoch: 0, Batch: 781, Loss: 0.041515182703733444\n",
      "Epoch: 0, Batch: 782, Loss: 0.13475556671619415\n",
      "Epoch: 0, Batch: 783, Loss: 0.05380389839410782\n",
      "Epoch: 0, Batch: 784, Loss: 0.07069237530231476\n",
      "Epoch: 0, Batch: 785, Loss: 0.04290660470724106\n",
      "Epoch: 0, Batch: 786, Loss: 0.1855577975511551\n",
      "Epoch: 0, Batch: 787, Loss: 0.027344241738319397\n",
      "Epoch: 0, Batch: 788, Loss: 0.17155109345912933\n",
      "Epoch: 0, Batch: 789, Loss: 0.06648313999176025\n",
      "Epoch: 0, Batch: 790, Loss: 0.0388759970664978\n",
      "Epoch: 0, Batch: 791, Loss: 0.2140020728111267\n",
      "Epoch: 0, Batch: 792, Loss: 0.0401119738817215\n",
      "Epoch: 0, Batch: 793, Loss: 0.05443303659558296\n",
      "Epoch: 0, Batch: 794, Loss: 0.07585492730140686\n",
      "Epoch: 0, Batch: 795, Loss: 0.06819285452365875\n",
      "Epoch: 0, Batch: 796, Loss: 0.06226767972111702\n",
      "Epoch: 0, Batch: 797, Loss: 0.07153461873531342\n",
      "Epoch: 0, Batch: 798, Loss: 0.015306365676224232\n",
      "Epoch: 0, Batch: 799, Loss: 0.04582604393362999\n",
      "Epoch: 0, Batch: 800, Loss: 0.11421561986207962\n",
      "Epoch: 0, Batch: 801, Loss: 0.24525292217731476\n",
      "Epoch: 0, Batch: 802, Loss: 0.07450735569000244\n",
      "Epoch: 0, Batch: 803, Loss: 0.04380510374903679\n",
      "Epoch: 0, Batch: 804, Loss: 0.019525835290551186\n",
      "Epoch: 0, Batch: 805, Loss: 0.015536658465862274\n",
      "Epoch: 0, Batch: 806, Loss: 0.06583620607852936\n",
      "Epoch: 0, Batch: 807, Loss: 0.11616793274879456\n",
      "Epoch: 0, Batch: 808, Loss: 0.03794834017753601\n",
      "Epoch: 0, Batch: 809, Loss: 0.0348205529153347\n",
      "Epoch: 0, Batch: 810, Loss: 0.11031138896942139\n",
      "Epoch: 0, Batch: 811, Loss: 0.022441530600190163\n",
      "Epoch: 0, Batch: 812, Loss: 0.0770750343799591\n",
      "Epoch: 0, Batch: 813, Loss: 0.0362321138381958\n",
      "Epoch: 0, Batch: 814, Loss: 0.10393571108579636\n",
      "Epoch: 0, Batch: 815, Loss: 0.017328036949038506\n",
      "Epoch: 0, Batch: 816, Loss: 0.1729624718427658\n",
      "Epoch: 0, Batch: 817, Loss: 0.052085358649492264\n",
      "Epoch: 0, Batch: 818, Loss: 0.08562657237052917\n",
      "Epoch: 0, Batch: 819, Loss: 0.12639349699020386\n",
      "Epoch: 0, Batch: 820, Loss: 0.07295717298984528\n",
      "Epoch: 0, Batch: 821, Loss: 0.02032444439828396\n",
      "Epoch: 0, Batch: 822, Loss: 0.07705516368150711\n",
      "Epoch: 0, Batch: 823, Loss: 0.10985744744539261\n",
      "Epoch: 0, Batch: 824, Loss: 0.01943156123161316\n",
      "Epoch: 0, Batch: 825, Loss: 0.024928152561187744\n",
      "Epoch: 0, Batch: 826, Loss: 0.06347520649433136\n",
      "Epoch: 0, Batch: 827, Loss: 0.12792396545410156\n",
      "Epoch: 0, Batch: 828, Loss: 0.10242822021245956\n",
      "Epoch: 0, Batch: 829, Loss: 0.04898760840296745\n",
      "Epoch: 0, Batch: 830, Loss: 0.05263960734009743\n",
      "Epoch: 0, Batch: 831, Loss: 0.010866828262805939\n",
      "Epoch: 0, Batch: 832, Loss: 0.08772487193346024\n",
      "Epoch: 0, Batch: 833, Loss: 0.04703066870570183\n",
      "Epoch: 0, Batch: 834, Loss: 0.1015450656414032\n",
      "Epoch: 0, Batch: 835, Loss: 0.02263382077217102\n",
      "Epoch: 0, Batch: 836, Loss: 0.018489545211195946\n",
      "Epoch: 0, Batch: 837, Loss: 0.015098641626536846\n",
      "Epoch: 0, Batch: 838, Loss: 0.04349852725863457\n",
      "Epoch: 0, Batch: 839, Loss: 0.038928572088479996\n",
      "Epoch: 0, Batch: 840, Loss: 0.025433547794818878\n",
      "Epoch: 0, Batch: 841, Loss: 0.15114279091358185\n",
      "Epoch: 0, Batch: 842, Loss: 0.18195344507694244\n",
      "Epoch: 0, Batch: 843, Loss: 0.09497666358947754\n",
      "Epoch: 0, Batch: 844, Loss: 0.007828260771930218\n",
      "Epoch: 0, Batch: 845, Loss: 0.1464919000864029\n",
      "Epoch: 0, Batch: 846, Loss: 0.03481770306825638\n",
      "Epoch: 0, Batch: 847, Loss: 0.07801292836666107\n",
      "Epoch: 0, Batch: 848, Loss: 0.03521811217069626\n",
      "Epoch: 0, Batch: 849, Loss: 0.0468270480632782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 850, Loss: 0.1069214940071106\n",
      "Epoch: 0, Batch: 851, Loss: 0.019470693543553352\n",
      "Epoch: 0, Batch: 852, Loss: 0.12321151793003082\n",
      "Epoch: 0, Batch: 853, Loss: 0.03201204538345337\n",
      "Epoch: 0, Batch: 854, Loss: 0.09513824433088303\n",
      "Epoch: 0, Batch: 855, Loss: 0.005568801425397396\n",
      "Epoch: 0, Batch: 856, Loss: 0.03181377053260803\n",
      "Epoch: 0, Batch: 857, Loss: 0.1064450591802597\n",
      "Epoch: 0, Batch: 858, Loss: 0.06433666497468948\n",
      "Epoch: 0, Batch: 859, Loss: 0.08137604594230652\n",
      "Epoch: 0, Batch: 860, Loss: 0.11952650547027588\n",
      "Epoch: 0, Batch: 861, Loss: 0.08607444912195206\n",
      "Epoch: 0, Batch: 862, Loss: 0.048951540142297745\n",
      "Epoch: 0, Batch: 863, Loss: 0.1595868319272995\n",
      "Epoch: 0, Batch: 864, Loss: 0.08293909579515457\n",
      "Epoch: 0, Batch: 865, Loss: 0.043682098388671875\n",
      "Epoch: 0, Batch: 866, Loss: 0.029431764036417007\n",
      "Epoch: 0, Batch: 867, Loss: 0.023622576147317886\n",
      "Epoch: 0, Batch: 868, Loss: 0.0028028765227645636\n",
      "Epoch: 0, Batch: 869, Loss: 0.08370964974164963\n",
      "Epoch: 0, Batch: 870, Loss: 0.0812857523560524\n",
      "Epoch: 0, Batch: 871, Loss: 0.1789780557155609\n",
      "Epoch: 0, Batch: 872, Loss: 0.009413694962859154\n",
      "Epoch: 0, Batch: 873, Loss: 0.08134689927101135\n",
      "Epoch: 0, Batch: 874, Loss: 0.05412480607628822\n",
      "Epoch: 0, Batch: 875, Loss: 0.029706964269280434\n",
      "Epoch: 0, Batch: 876, Loss: 0.034947469830513\n",
      "Epoch: 0, Batch: 877, Loss: 0.05014520511031151\n",
      "Epoch: 0, Batch: 878, Loss: 0.14153708517551422\n",
      "Epoch: 0, Batch: 879, Loss: 0.09152958542108536\n",
      "Epoch: 0, Batch: 880, Loss: 0.01011178083717823\n",
      "Epoch: 0, Batch: 881, Loss: 0.4829849302768707\n",
      "Epoch: 0, Batch: 882, Loss: 0.3674045503139496\n",
      "Epoch: 0, Batch: 883, Loss: 0.09689637273550034\n",
      "Epoch: 0, Batch: 884, Loss: 0.07493539899587631\n",
      "Epoch: 0, Batch: 885, Loss: 0.138333261013031\n",
      "Epoch: 0, Batch: 886, Loss: 0.09692232310771942\n",
      "Epoch: 0, Batch: 887, Loss: 0.17196977138519287\n",
      "Epoch: 0, Batch: 888, Loss: 0.05871753767132759\n",
      "Epoch: 0, Batch: 889, Loss: 0.12965933978557587\n",
      "Epoch: 0, Batch: 890, Loss: 0.08056093007326126\n",
      "Epoch: 0, Batch: 891, Loss: 0.18842244148254395\n",
      "Epoch: 0, Batch: 892, Loss: 0.019085964187979698\n",
      "Epoch: 0, Batch: 893, Loss: 0.04235714301466942\n",
      "Epoch: 0, Batch: 894, Loss: 0.14938028156757355\n",
      "Epoch: 0, Batch: 895, Loss: 0.016661453992128372\n",
      "Epoch: 0, Batch: 896, Loss: 0.02100810967385769\n",
      "Epoch: 0, Batch: 897, Loss: 0.029178118333220482\n",
      "Epoch: 0, Batch: 898, Loss: 0.06286001205444336\n",
      "Epoch: 0, Batch: 899, Loss: 0.15384049713611603\n",
      "Epoch: 0, Batch: 900, Loss: 0.08505014330148697\n",
      "Epoch: 0, Batch: 901, Loss: 0.057231493294239044\n",
      "Epoch: 0, Batch: 902, Loss: 0.08953925967216492\n",
      "Epoch: 0, Batch: 903, Loss: 0.052005648612976074\n",
      "Epoch: 0, Batch: 904, Loss: 0.027715099975466728\n",
      "Epoch: 0, Batch: 905, Loss: 0.14123408496379852\n",
      "Epoch: 0, Batch: 906, Loss: 0.08676958084106445\n",
      "Epoch: 0, Batch: 907, Loss: 0.07300399243831635\n",
      "Epoch: 0, Batch: 908, Loss: 0.0532836876809597\n",
      "Epoch: 0, Batch: 909, Loss: 0.037141792476177216\n",
      "Epoch: 0, Batch: 910, Loss: 0.03432590141892433\n",
      "Epoch: 0, Batch: 911, Loss: 0.01987656019628048\n",
      "Epoch: 0, Batch: 912, Loss: 0.286458820104599\n",
      "Epoch: 0, Batch: 913, Loss: 0.10621814429759979\n",
      "Epoch: 0, Batch: 914, Loss: 0.08863165229558945\n",
      "Epoch: 0, Batch: 915, Loss: 0.140155628323555\n",
      "Epoch: 0, Batch: 916, Loss: 0.05560549348592758\n",
      "Epoch: 0, Batch: 917, Loss: 0.022329682484269142\n",
      "Epoch: 0, Batch: 918, Loss: 0.09401847422122955\n",
      "Epoch: 0, Batch: 919, Loss: 0.12644773721694946\n",
      "Epoch: 0, Batch: 920, Loss: 0.10514486581087112\n",
      "Epoch: 0, Batch: 921, Loss: 0.01196601428091526\n",
      "Epoch: 0, Batch: 922, Loss: 0.03388472646474838\n",
      "Epoch: 0, Batch: 923, Loss: 0.06983448565006256\n",
      "Epoch: 0, Batch: 924, Loss: 0.10364273190498352\n",
      "Epoch: 0, Batch: 925, Loss: 0.042153250426054\n",
      "Epoch: 0, Batch: 926, Loss: 0.02671588584780693\n",
      "Epoch: 0, Batch: 927, Loss: 0.047200556844472885\n",
      "Epoch: 0, Batch: 928, Loss: 0.024749262258410454\n",
      "Epoch: 0, Batch: 929, Loss: 0.032113995403051376\n",
      "Epoch: 0, Batch: 930, Loss: 0.06810123473405838\n",
      "Epoch: 0, Batch: 931, Loss: 0.05115969106554985\n",
      "Epoch: 0, Batch: 932, Loss: 0.11161480098962784\n",
      "Epoch: 0, Batch: 933, Loss: 0.10312967002391815\n",
      "Epoch: 0, Batch: 934, Loss: 0.13450537621974945\n",
      "Epoch: 0, Batch: 935, Loss: 0.11489075422286987\n",
      "Epoch: 0, Batch: 936, Loss: 0.11571665853261948\n",
      "Epoch: 0, Batch: 937, Loss: 0.0048920572735369205\n",
      "Epoch: 1, Batch: 0, Loss: 0.020449034869670868\n",
      "Epoch: 1, Batch: 1, Loss: 0.015000706538558006\n",
      "Epoch: 1, Batch: 2, Loss: 0.03659433126449585\n",
      "Epoch: 1, Batch: 3, Loss: 0.014800840057432652\n",
      "Epoch: 1, Batch: 4, Loss: 0.066503144800663\n",
      "Epoch: 1, Batch: 5, Loss: 0.011237571947276592\n",
      "Epoch: 1, Batch: 6, Loss: 0.10393465310335159\n",
      "Epoch: 1, Batch: 7, Loss: 0.017643507570028305\n",
      "Epoch: 1, Batch: 8, Loss: 0.059288837015628815\n",
      "Epoch: 1, Batch: 9, Loss: 0.0981248989701271\n",
      "Epoch: 1, Batch: 10, Loss: 0.039838846772909164\n",
      "Epoch: 1, Batch: 11, Loss: 0.006472896318882704\n",
      "Epoch: 1, Batch: 12, Loss: 0.01621519774198532\n",
      "Epoch: 1, Batch: 13, Loss: 0.08295366168022156\n",
      "Epoch: 1, Batch: 14, Loss: 0.09608318656682968\n",
      "Epoch: 1, Batch: 15, Loss: 0.0194851066917181\n",
      "Epoch: 1, Batch: 16, Loss: 0.05191861465573311\n",
      "Epoch: 1, Batch: 17, Loss: 0.10206671804189682\n",
      "Epoch: 1, Batch: 18, Loss: 0.07363744080066681\n",
      "Epoch: 1, Batch: 19, Loss: 0.021275699138641357\n",
      "Epoch: 1, Batch: 20, Loss: 0.042302247136831284\n",
      "Epoch: 1, Batch: 21, Loss: 0.06502304971218109\n",
      "Epoch: 1, Batch: 22, Loss: 0.14667002856731415\n",
      "Epoch: 1, Batch: 23, Loss: 0.043805792927742004\n",
      "Epoch: 1, Batch: 24, Loss: 0.08012139797210693\n",
      "Epoch: 1, Batch: 25, Loss: 0.06137499213218689\n",
      "Epoch: 1, Batch: 26, Loss: 0.03536912053823471\n",
      "Epoch: 1, Batch: 27, Loss: 0.03779325634241104\n",
      "Epoch: 1, Batch: 28, Loss: 0.02808360569179058\n",
      "Epoch: 1, Batch: 29, Loss: 0.06217482313513756\n",
      "Epoch: 1, Batch: 30, Loss: 0.042333297431468964\n",
      "Epoch: 1, Batch: 31, Loss: 0.042481858283281326\n",
      "Epoch: 1, Batch: 32, Loss: 0.009339951910078526\n",
      "Epoch: 1, Batch: 33, Loss: 0.015967225655913353\n",
      "Epoch: 1, Batch: 34, Loss: 0.05083208158612251\n",
      "Epoch: 1, Batch: 35, Loss: 0.0397145040333271\n",
      "Epoch: 1, Batch: 36, Loss: 0.013694988563656807\n",
      "Epoch: 1, Batch: 37, Loss: 0.005698560271412134\n",
      "Epoch: 1, Batch: 38, Loss: 0.005659330636262894\n",
      "Epoch: 1, Batch: 39, Loss: 0.1438625156879425\n",
      "Epoch: 1, Batch: 40, Loss: 0.003226775210350752\n",
      "Epoch: 1, Batch: 41, Loss: 0.06641840189695358\n",
      "Epoch: 1, Batch: 42, Loss: 0.1884143352508545\n",
      "Epoch: 1, Batch: 43, Loss: 0.11254063993692398\n",
      "Epoch: 1, Batch: 44, Loss: 0.023935239762067795\n",
      "Epoch: 1, Batch: 45, Loss: 0.031627994030714035\n",
      "Epoch: 1, Batch: 46, Loss: 0.03714124113321304\n",
      "Epoch: 1, Batch: 47, Loss: 0.07191134244203568\n",
      "Epoch: 1, Batch: 48, Loss: 0.09172564744949341\n",
      "Epoch: 1, Batch: 49, Loss: 0.01582551747560501\n",
      "Epoch: 1, Batch: 50, Loss: 0.0770532637834549\n",
      "Epoch: 1, Batch: 51, Loss: 0.05982105806469917\n",
      "Epoch: 1, Batch: 52, Loss: 0.017813650891184807\n",
      "Epoch: 1, Batch: 53, Loss: 0.08847340196371078\n",
      "Epoch: 1, Batch: 54, Loss: 0.04700604826211929\n",
      "Epoch: 1, Batch: 55, Loss: 0.03963309898972511\n",
      "Epoch: 1, Batch: 56, Loss: 0.008964315988123417\n",
      "Epoch: 1, Batch: 57, Loss: 0.004779870621860027\n",
      "Epoch: 1, Batch: 58, Loss: 0.1092350110411644\n",
      "Epoch: 1, Batch: 59, Loss: 0.0466555655002594\n",
      "Epoch: 1, Batch: 60, Loss: 0.11807859688997269\n",
      "Epoch: 1, Batch: 61, Loss: 0.03757471963763237\n",
      "Epoch: 1, Batch: 62, Loss: 0.006166636478155851\n",
      "Epoch: 1, Batch: 63, Loss: 0.04226037114858627\n",
      "Epoch: 1, Batch: 64, Loss: 0.06633634865283966\n",
      "Epoch: 1, Batch: 65, Loss: 0.03190803900361061\n",
      "Epoch: 1, Batch: 66, Loss: 0.05445850268006325\n",
      "Epoch: 1, Batch: 67, Loss: 0.01356896199285984\n",
      "Epoch: 1, Batch: 68, Loss: 0.03021784871816635\n",
      "Epoch: 1, Batch: 69, Loss: 0.03410946577787399\n",
      "Epoch: 1, Batch: 70, Loss: 0.034760601818561554\n",
      "Epoch: 1, Batch: 71, Loss: 0.011893116869032383\n",
      "Epoch: 1, Batch: 72, Loss: 0.03763306140899658\n",
      "Epoch: 1, Batch: 73, Loss: 0.028827643021941185\n",
      "Epoch: 1, Batch: 74, Loss: 0.022662591189146042\n",
      "Epoch: 1, Batch: 75, Loss: 0.016686011105775833\n",
      "Epoch: 1, Batch: 76, Loss: 0.05258733034133911\n",
      "Epoch: 1, Batch: 77, Loss: 0.01507917232811451\n",
      "Epoch: 1, Batch: 78, Loss: 0.0491337776184082\n",
      "Epoch: 1, Batch: 79, Loss: 0.3454415798187256\n",
      "Epoch: 1, Batch: 80, Loss: 0.07648575305938721\n",
      "Epoch: 1, Batch: 81, Loss: 0.009477632120251656\n",
      "Epoch: 1, Batch: 82, Loss: 0.061468563973903656\n",
      "Epoch: 1, Batch: 83, Loss: 0.021242503076791763\n",
      "Epoch: 1, Batch: 84, Loss: 0.002316974103450775\n",
      "Epoch: 1, Batch: 85, Loss: 0.0310817901045084\n",
      "Epoch: 1, Batch: 86, Loss: 0.018935052677989006\n",
      "Epoch: 1, Batch: 87, Loss: 0.03839803487062454\n",
      "Epoch: 1, Batch: 88, Loss: 0.02276308834552765\n",
      "Epoch: 1, Batch: 89, Loss: 0.12443544715642929\n",
      "Epoch: 1, Batch: 90, Loss: 0.03402980789542198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 91, Loss: 0.039270419627428055\n",
      "Epoch: 1, Batch: 92, Loss: 0.0022137428168207407\n",
      "Epoch: 1, Batch: 93, Loss: 0.008678264915943146\n",
      "Epoch: 1, Batch: 94, Loss: 0.1216074600815773\n",
      "Epoch: 1, Batch: 95, Loss: 0.05733492597937584\n",
      "Epoch: 1, Batch: 96, Loss: 0.005074009299278259\n",
      "Epoch: 1, Batch: 97, Loss: 0.16439278423786163\n",
      "Epoch: 1, Batch: 98, Loss: 0.015469365753233433\n",
      "Epoch: 1, Batch: 99, Loss: 0.03229444473981857\n",
      "Epoch: 1, Batch: 100, Loss: 0.08654247224330902\n",
      "Epoch: 1, Batch: 101, Loss: 0.16839629411697388\n",
      "Epoch: 1, Batch: 102, Loss: 0.056458428502082825\n",
      "Epoch: 1, Batch: 103, Loss: 0.15265829861164093\n",
      "Epoch: 1, Batch: 104, Loss: 0.06556954979896545\n",
      "Epoch: 1, Batch: 105, Loss: 0.03648741543292999\n",
      "Epoch: 1, Batch: 106, Loss: 0.044623371213674545\n",
      "Epoch: 1, Batch: 107, Loss: 0.030948329716920853\n",
      "Epoch: 1, Batch: 108, Loss: 0.15291127562522888\n",
      "Epoch: 1, Batch: 109, Loss: 0.16872890293598175\n",
      "Epoch: 1, Batch: 110, Loss: 0.12768618762493134\n",
      "Epoch: 1, Batch: 111, Loss: 0.014314127154648304\n",
      "Epoch: 1, Batch: 112, Loss: 0.0704650804400444\n",
      "Epoch: 1, Batch: 113, Loss: 0.0355592779815197\n",
      "Epoch: 1, Batch: 114, Loss: 0.01863396354019642\n",
      "Epoch: 1, Batch: 115, Loss: 0.02854136750102043\n",
      "Epoch: 1, Batch: 116, Loss: 0.02720648981630802\n",
      "Epoch: 1, Batch: 117, Loss: 0.07663939893245697\n",
      "Epoch: 1, Batch: 118, Loss: 0.06467869132757187\n",
      "Epoch: 1, Batch: 119, Loss: 0.04763563722372055\n",
      "Epoch: 1, Batch: 120, Loss: 0.0769050121307373\n",
      "Epoch: 1, Batch: 121, Loss: 0.10786404460668564\n",
      "Epoch: 1, Batch: 122, Loss: 0.061452466994524\n",
      "Epoch: 1, Batch: 123, Loss: 0.014334007166326046\n",
      "Epoch: 1, Batch: 124, Loss: 0.07151911407709122\n",
      "Epoch: 1, Batch: 125, Loss: 0.027555719017982483\n",
      "Epoch: 1, Batch: 126, Loss: 0.036859653890132904\n",
      "Epoch: 1, Batch: 127, Loss: 0.048540495336055756\n",
      "Epoch: 1, Batch: 128, Loss: 0.16767250001430511\n",
      "Epoch: 1, Batch: 129, Loss: 0.14654679596424103\n",
      "Epoch: 1, Batch: 130, Loss: 0.04931586980819702\n",
      "Epoch: 1, Batch: 131, Loss: 0.0726282149553299\n",
      "Epoch: 1, Batch: 132, Loss: 0.09382732957601547\n",
      "Epoch: 1, Batch: 133, Loss: 0.046218909323215485\n",
      "Epoch: 1, Batch: 134, Loss: 0.0626232922077179\n",
      "Epoch: 1, Batch: 135, Loss: 0.055546749383211136\n",
      "Epoch: 1, Batch: 136, Loss: 0.03644238039851189\n",
      "Epoch: 1, Batch: 137, Loss: 0.034616414457559586\n",
      "Epoch: 1, Batch: 138, Loss: 0.03343943879008293\n",
      "Epoch: 1, Batch: 139, Loss: 0.0657012090086937\n",
      "Epoch: 1, Batch: 140, Loss: 0.030349237844347954\n",
      "Epoch: 1, Batch: 141, Loss: 0.04934081435203552\n",
      "Epoch: 1, Batch: 142, Loss: 0.10586553066968918\n",
      "Epoch: 1, Batch: 143, Loss: 0.00727270869538188\n",
      "Epoch: 1, Batch: 144, Loss: 0.02391638606786728\n",
      "Epoch: 1, Batch: 145, Loss: 0.10542163997888565\n",
      "Epoch: 1, Batch: 146, Loss: 0.009762436151504517\n",
      "Epoch: 1, Batch: 147, Loss: 0.11036381870508194\n",
      "Epoch: 1, Batch: 148, Loss: 0.031020842492580414\n",
      "Epoch: 1, Batch: 149, Loss: 0.0781126394867897\n",
      "Epoch: 1, Batch: 150, Loss: 0.1973576843738556\n",
      "Epoch: 1, Batch: 151, Loss: 0.019146524369716644\n",
      "Epoch: 1, Batch: 152, Loss: 0.026726869866251945\n",
      "Epoch: 1, Batch: 153, Loss: 0.00977454986423254\n",
      "Epoch: 1, Batch: 154, Loss: 0.03062913753092289\n",
      "Epoch: 1, Batch: 155, Loss: 0.10767253488302231\n",
      "Epoch: 1, Batch: 156, Loss: 0.027897590771317482\n",
      "Epoch: 1, Batch: 157, Loss: 0.08471998572349548\n",
      "Epoch: 1, Batch: 158, Loss: 0.020401043817400932\n",
      "Epoch: 1, Batch: 159, Loss: 0.018996089696884155\n",
      "Epoch: 1, Batch: 160, Loss: 0.07572243362665176\n",
      "Epoch: 1, Batch: 161, Loss: 0.07100515067577362\n",
      "Epoch: 1, Batch: 162, Loss: 0.03862082213163376\n",
      "Epoch: 1, Batch: 163, Loss: 0.03788004815578461\n",
      "Epoch: 1, Batch: 164, Loss: 0.0019101535435765982\n",
      "Epoch: 1, Batch: 165, Loss: 0.013992362655699253\n",
      "Epoch: 1, Batch: 166, Loss: 0.08061772584915161\n",
      "Epoch: 1, Batch: 167, Loss: 0.03663383051753044\n",
      "Epoch: 1, Batch: 168, Loss: 0.012810347601771355\n",
      "Epoch: 1, Batch: 169, Loss: 0.03630637750029564\n",
      "Epoch: 1, Batch: 170, Loss: 0.015627428889274597\n",
      "Epoch: 1, Batch: 171, Loss: 0.059048671275377274\n",
      "Epoch: 1, Batch: 172, Loss: 0.10933808982372284\n",
      "Epoch: 1, Batch: 173, Loss: 0.04463944211602211\n",
      "Epoch: 1, Batch: 174, Loss: 0.003452685195952654\n",
      "Epoch: 1, Batch: 175, Loss: 0.0670231506228447\n",
      "Epoch: 1, Batch: 176, Loss: 0.01996198482811451\n",
      "Epoch: 1, Batch: 177, Loss: 0.017763618379831314\n",
      "Epoch: 1, Batch: 178, Loss: 0.005469230003654957\n",
      "Epoch: 1, Batch: 179, Loss: 0.112998366355896\n",
      "Epoch: 1, Batch: 180, Loss: 0.017518624663352966\n",
      "Epoch: 1, Batch: 181, Loss: 0.008745445869863033\n",
      "Epoch: 1, Batch: 182, Loss: 0.02472246065735817\n",
      "Epoch: 1, Batch: 183, Loss: 0.015966180711984634\n",
      "Epoch: 1, Batch: 184, Loss: 0.04711955785751343\n",
      "Epoch: 1, Batch: 185, Loss: 0.009169874712824821\n",
      "Epoch: 1, Batch: 186, Loss: 0.021089961752295494\n",
      "Epoch: 1, Batch: 187, Loss: 0.0012263942044228315\n",
      "Epoch: 1, Batch: 188, Loss: 0.01717885211110115\n",
      "Epoch: 1, Batch: 189, Loss: 0.037881627678871155\n",
      "Epoch: 1, Batch: 190, Loss: 0.0544898621737957\n",
      "Epoch: 1, Batch: 191, Loss: 0.0055347285233438015\n",
      "Epoch: 1, Batch: 192, Loss: 0.029579786583781242\n",
      "Epoch: 1, Batch: 193, Loss: 0.21651072800159454\n",
      "Epoch: 1, Batch: 194, Loss: 0.007179947569966316\n",
      "Epoch: 1, Batch: 195, Loss: 0.07403863221406937\n",
      "Epoch: 1, Batch: 196, Loss: 0.017071014270186424\n",
      "Epoch: 1, Batch: 197, Loss: 0.08049999922513962\n",
      "Epoch: 1, Batch: 198, Loss: 0.03119712509214878\n",
      "Epoch: 1, Batch: 199, Loss: 0.0028811623342335224\n",
      "Epoch: 1, Batch: 200, Loss: 0.030544091016054153\n",
      "Epoch: 1, Batch: 201, Loss: 0.06190061196684837\n",
      "Epoch: 1, Batch: 202, Loss: 0.05511647090315819\n",
      "Epoch: 1, Batch: 203, Loss: 0.021790077909827232\n",
      "Epoch: 1, Batch: 204, Loss: 0.02887897752225399\n",
      "Epoch: 1, Batch: 205, Loss: 0.05413879081606865\n",
      "Epoch: 1, Batch: 206, Loss: 0.14366643130779266\n",
      "Epoch: 1, Batch: 207, Loss: 0.01071265246719122\n",
      "Epoch: 1, Batch: 208, Loss: 0.14890792965888977\n",
      "Epoch: 1, Batch: 209, Loss: 0.016863327473402023\n",
      "Epoch: 1, Batch: 210, Loss: 0.13509653508663177\n",
      "Epoch: 1, Batch: 211, Loss: 0.029203880578279495\n",
      "Epoch: 1, Batch: 212, Loss: 0.010805994272232056\n",
      "Epoch: 1, Batch: 213, Loss: 0.02514015883207321\n",
      "Epoch: 1, Batch: 214, Loss: 0.07590567320585251\n",
      "Epoch: 1, Batch: 215, Loss: 0.014086751267313957\n",
      "Epoch: 1, Batch: 216, Loss: 0.026509899646043777\n",
      "Epoch: 1, Batch: 217, Loss: 0.07005926966667175\n",
      "Epoch: 1, Batch: 218, Loss: 0.09281748533248901\n",
      "Epoch: 1, Batch: 219, Loss: 0.03981446474790573\n",
      "Epoch: 1, Batch: 220, Loss: 0.013060147874057293\n",
      "Epoch: 1, Batch: 221, Loss: 0.01546196173876524\n",
      "Epoch: 1, Batch: 222, Loss: 0.022459371015429497\n",
      "Epoch: 1, Batch: 223, Loss: 0.016636302694678307\n",
      "Epoch: 1, Batch: 224, Loss: 0.05200597643852234\n",
      "Epoch: 1, Batch: 225, Loss: 0.04080018773674965\n",
      "Epoch: 1, Batch: 226, Loss: 0.06494668126106262\n",
      "Epoch: 1, Batch: 227, Loss: 0.0355064794421196\n",
      "Epoch: 1, Batch: 228, Loss: 0.04305436462163925\n",
      "Epoch: 1, Batch: 229, Loss: 0.0699525699019432\n",
      "Epoch: 1, Batch: 230, Loss: 0.13627305626869202\n",
      "Epoch: 1, Batch: 231, Loss: 0.07960855960845947\n",
      "Epoch: 1, Batch: 232, Loss: 0.04549723491072655\n",
      "Epoch: 1, Batch: 233, Loss: 0.1343873292207718\n",
      "Epoch: 1, Batch: 234, Loss: 0.1406489461660385\n",
      "Epoch: 1, Batch: 235, Loss: 0.060036711394786835\n",
      "Epoch: 1, Batch: 236, Loss: 0.013170573860406876\n",
      "Epoch: 1, Batch: 237, Loss: 0.04010925069451332\n",
      "Epoch: 1, Batch: 238, Loss: 0.12148191779851913\n",
      "Epoch: 1, Batch: 239, Loss: 0.02203000709414482\n",
      "Epoch: 1, Batch: 240, Loss: 0.008828234858810902\n",
      "Epoch: 1, Batch: 241, Loss: 0.04961134120821953\n",
      "Epoch: 1, Batch: 242, Loss: 0.028892530128359795\n",
      "Epoch: 1, Batch: 243, Loss: 0.06525825709104538\n",
      "Epoch: 1, Batch: 244, Loss: 0.16376520693302155\n",
      "Epoch: 1, Batch: 245, Loss: 0.03206970915198326\n",
      "Epoch: 1, Batch: 246, Loss: 0.03893132880330086\n",
      "Epoch: 1, Batch: 247, Loss: 0.17046257853507996\n",
      "Epoch: 1, Batch: 248, Loss: 0.14951571822166443\n",
      "Epoch: 1, Batch: 249, Loss: 0.013251669704914093\n",
      "Epoch: 1, Batch: 250, Loss: 0.050944726914167404\n",
      "Epoch: 1, Batch: 251, Loss: 0.05427227541804314\n",
      "Epoch: 1, Batch: 252, Loss: 0.0906762182712555\n",
      "Epoch: 1, Batch: 253, Loss: 0.06864959746599197\n",
      "Epoch: 1, Batch: 254, Loss: 0.1381838321685791\n",
      "Epoch: 1, Batch: 255, Loss: 0.059259798377752304\n",
      "Epoch: 1, Batch: 256, Loss: 0.041621629148721695\n",
      "Epoch: 1, Batch: 257, Loss: 0.007977192290127277\n",
      "Epoch: 1, Batch: 258, Loss: 0.026232510805130005\n",
      "Epoch: 1, Batch: 259, Loss: 0.08828829228878021\n",
      "Epoch: 1, Batch: 260, Loss: 0.007173856254667044\n",
      "Epoch: 1, Batch: 261, Loss: 0.10787462443113327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 262, Loss: 0.014715784229338169\n",
      "Epoch: 1, Batch: 263, Loss: 0.09036853164434433\n",
      "Epoch: 1, Batch: 264, Loss: 0.09145523607730865\n",
      "Epoch: 1, Batch: 265, Loss: 0.11131054908037186\n",
      "Epoch: 1, Batch: 266, Loss: 0.06884802132844925\n",
      "Epoch: 1, Batch: 267, Loss: 0.022984113544225693\n",
      "Epoch: 1, Batch: 268, Loss: 0.13017848134040833\n",
      "Epoch: 1, Batch: 269, Loss: 0.031290050595998764\n",
      "Epoch: 1, Batch: 270, Loss: 0.12234240025281906\n",
      "Epoch: 1, Batch: 271, Loss: 0.014388328418135643\n",
      "Epoch: 1, Batch: 272, Loss: 0.0707973763346672\n",
      "Epoch: 1, Batch: 273, Loss: 0.028389066457748413\n",
      "Epoch: 1, Batch: 274, Loss: 0.10546912252902985\n",
      "Epoch: 1, Batch: 275, Loss: 0.08547940105199814\n",
      "Epoch: 1, Batch: 276, Loss: 0.08480631560087204\n",
      "Epoch: 1, Batch: 277, Loss: 0.018801560625433922\n",
      "Epoch: 1, Batch: 278, Loss: 0.0754423514008522\n",
      "Epoch: 1, Batch: 279, Loss: 0.07723581045866013\n",
      "Epoch: 1, Batch: 280, Loss: 0.1370503306388855\n",
      "Epoch: 1, Batch: 281, Loss: 0.03304995968937874\n",
      "Epoch: 1, Batch: 282, Loss: 0.01315661333501339\n",
      "Epoch: 1, Batch: 283, Loss: 0.05457879230380058\n",
      "Epoch: 1, Batch: 284, Loss: 0.05855179205536842\n",
      "Epoch: 1, Batch: 285, Loss: 0.04381655529141426\n",
      "Epoch: 1, Batch: 286, Loss: 0.008364666253328323\n",
      "Epoch: 1, Batch: 287, Loss: 0.09325108677148819\n",
      "Epoch: 1, Batch: 288, Loss: 0.08222141116857529\n",
      "Epoch: 1, Batch: 289, Loss: 0.0742395892739296\n",
      "Epoch: 1, Batch: 290, Loss: 0.026424452662467957\n",
      "Epoch: 1, Batch: 291, Loss: 0.08984179049730301\n",
      "Epoch: 1, Batch: 292, Loss: 0.06810420006513596\n",
      "Epoch: 1, Batch: 293, Loss: 0.13816845417022705\n",
      "Epoch: 1, Batch: 294, Loss: 0.011138875968754292\n",
      "Epoch: 1, Batch: 295, Loss: 0.04600856080651283\n",
      "Epoch: 1, Batch: 296, Loss: 0.12216215580701828\n",
      "Epoch: 1, Batch: 297, Loss: 0.030232323333621025\n",
      "Epoch: 1, Batch: 298, Loss: 0.06354621797800064\n",
      "Epoch: 1, Batch: 299, Loss: 0.11862076073884964\n",
      "Epoch: 1, Batch: 300, Loss: 0.061846621334552765\n",
      "Epoch: 1, Batch: 301, Loss: 0.014117734506726265\n",
      "Epoch: 1, Batch: 302, Loss: 0.026126939803361893\n",
      "Epoch: 1, Batch: 303, Loss: 0.007654306013137102\n",
      "Epoch: 1, Batch: 304, Loss: 0.036177318543195724\n",
      "Epoch: 1, Batch: 305, Loss: 0.029911020770668983\n",
      "Epoch: 1, Batch: 306, Loss: 0.1135544702410698\n",
      "Epoch: 1, Batch: 307, Loss: 0.0936998650431633\n",
      "Epoch: 1, Batch: 308, Loss: 0.06073273345828056\n",
      "Epoch: 1, Batch: 309, Loss: 0.011372842825949192\n",
      "Epoch: 1, Batch: 310, Loss: 0.05785507336258888\n",
      "Epoch: 1, Batch: 311, Loss: 0.0896700844168663\n",
      "Epoch: 1, Batch: 312, Loss: 0.06413821876049042\n",
      "Epoch: 1, Batch: 313, Loss: 0.024694930762052536\n",
      "Epoch: 1, Batch: 314, Loss: 0.012384072877466679\n",
      "Epoch: 1, Batch: 315, Loss: 0.03793847933411598\n",
      "Epoch: 1, Batch: 316, Loss: 0.08349061757326126\n",
      "Epoch: 1, Batch: 317, Loss: 0.049839310348033905\n",
      "Epoch: 1, Batch: 318, Loss: 0.005429109558463097\n",
      "Epoch: 1, Batch: 319, Loss: 0.04892103746533394\n",
      "Epoch: 1, Batch: 320, Loss: 0.01826317049562931\n",
      "Epoch: 1, Batch: 321, Loss: 0.034989133477211\n",
      "Epoch: 1, Batch: 322, Loss: 0.047097768634557724\n",
      "Epoch: 1, Batch: 323, Loss: 0.06424882262945175\n",
      "Epoch: 1, Batch: 324, Loss: 0.008230695500969887\n",
      "Epoch: 1, Batch: 325, Loss: 0.04931667074561119\n",
      "Epoch: 1, Batch: 326, Loss: 0.06540504097938538\n",
      "Epoch: 1, Batch: 327, Loss: 0.010670321993529797\n",
      "Epoch: 1, Batch: 328, Loss: 0.015202142298221588\n",
      "Epoch: 1, Batch: 329, Loss: 0.009456641972064972\n",
      "Epoch: 1, Batch: 330, Loss: 0.05109802633523941\n",
      "Epoch: 1, Batch: 331, Loss: 0.007335604168474674\n",
      "Epoch: 1, Batch: 332, Loss: 0.003097264328971505\n",
      "Epoch: 1, Batch: 333, Loss: 0.046065978705883026\n",
      "Epoch: 1, Batch: 334, Loss: 0.07290493696928024\n",
      "Epoch: 1, Batch: 335, Loss: 0.06322994083166122\n",
      "Epoch: 1, Batch: 336, Loss: 0.0373147651553154\n",
      "Epoch: 1, Batch: 337, Loss: 0.05663762614130974\n",
      "Epoch: 1, Batch: 338, Loss: 0.04850037768483162\n",
      "Epoch: 1, Batch: 339, Loss: 0.13242052495479584\n",
      "Epoch: 1, Batch: 340, Loss: 0.07007762789726257\n",
      "Epoch: 1, Batch: 341, Loss: 0.04326403886079788\n",
      "Epoch: 1, Batch: 342, Loss: 0.017223041504621506\n",
      "Epoch: 1, Batch: 343, Loss: 0.02500244788825512\n",
      "Epoch: 1, Batch: 344, Loss: 0.005198677536100149\n",
      "Epoch: 1, Batch: 345, Loss: 0.005548478104174137\n",
      "Epoch: 1, Batch: 346, Loss: 0.06411974877119064\n",
      "Epoch: 1, Batch: 347, Loss: 0.027547698467969894\n",
      "Epoch: 1, Batch: 348, Loss: 0.054978299885988235\n",
      "Epoch: 1, Batch: 349, Loss: 0.020065058022737503\n",
      "Epoch: 1, Batch: 350, Loss: 0.060655031353235245\n",
      "Epoch: 1, Batch: 351, Loss: 0.09991259127855301\n",
      "Epoch: 1, Batch: 352, Loss: 0.14350786805152893\n",
      "Epoch: 1, Batch: 353, Loss: 0.10843447595834732\n",
      "Epoch: 1, Batch: 354, Loss: 0.02788623422384262\n",
      "Epoch: 1, Batch: 355, Loss: 0.09274443238973618\n",
      "Epoch: 1, Batch: 356, Loss: 0.014612648636102676\n",
      "Epoch: 1, Batch: 357, Loss: 0.04554327577352524\n",
      "Epoch: 1, Batch: 358, Loss: 0.028583398088812828\n",
      "Epoch: 1, Batch: 359, Loss: 0.0523134246468544\n",
      "Epoch: 1, Batch: 360, Loss: 0.005146815441548824\n",
      "Epoch: 1, Batch: 361, Loss: 0.031040813773870468\n",
      "Epoch: 1, Batch: 362, Loss: 0.022365937009453773\n",
      "Epoch: 1, Batch: 363, Loss: 0.07212822139263153\n",
      "Epoch: 1, Batch: 364, Loss: 0.10280298441648483\n",
      "Epoch: 1, Batch: 365, Loss: 0.04810546338558197\n",
      "Epoch: 1, Batch: 366, Loss: 0.0076115746051073074\n",
      "Epoch: 1, Batch: 367, Loss: 0.07446669787168503\n",
      "Epoch: 1, Batch: 368, Loss: 0.019899234175682068\n",
      "Epoch: 1, Batch: 369, Loss: 0.05530621111392975\n",
      "Epoch: 1, Batch: 370, Loss: 0.03775830194354057\n",
      "Epoch: 1, Batch: 371, Loss: 0.008694831281900406\n",
      "Epoch: 1, Batch: 372, Loss: 0.21386021375656128\n",
      "Epoch: 1, Batch: 373, Loss: 0.044852592051029205\n",
      "Epoch: 1, Batch: 374, Loss: 0.036061786115169525\n",
      "Epoch: 1, Batch: 375, Loss: 0.03278225660324097\n",
      "Epoch: 1, Batch: 376, Loss: 0.06830982863903046\n",
      "Epoch: 1, Batch: 377, Loss: 0.015533371828496456\n",
      "Epoch: 1, Batch: 378, Loss: 0.004115368239581585\n",
      "Epoch: 1, Batch: 379, Loss: 0.03962447866797447\n",
      "Epoch: 1, Batch: 380, Loss: 0.056909605860710144\n",
      "Epoch: 1, Batch: 381, Loss: 0.005146971438080072\n",
      "Epoch: 1, Batch: 382, Loss: 0.07810565084218979\n",
      "Epoch: 1, Batch: 383, Loss: 0.026082871481776237\n",
      "Epoch: 1, Batch: 384, Loss: 0.06729346513748169\n",
      "Epoch: 1, Batch: 385, Loss: 0.022527579218149185\n",
      "Epoch: 1, Batch: 386, Loss: 0.020997948944568634\n",
      "Epoch: 1, Batch: 387, Loss: 0.1533440798521042\n",
      "Epoch: 1, Batch: 388, Loss: 0.02891814149916172\n",
      "Epoch: 1, Batch: 389, Loss: 0.08745104819536209\n",
      "Epoch: 1, Batch: 390, Loss: 0.012406009249389172\n",
      "Epoch: 1, Batch: 391, Loss: 0.031016880646348\n",
      "Epoch: 1, Batch: 392, Loss: 0.07653550058603287\n",
      "Epoch: 1, Batch: 393, Loss: 0.015910299494862556\n",
      "Epoch: 1, Batch: 394, Loss: 0.10346536338329315\n",
      "Epoch: 1, Batch: 395, Loss: 0.015634069219231606\n",
      "Epoch: 1, Batch: 396, Loss: 0.09424781054258347\n",
      "Epoch: 1, Batch: 397, Loss: 0.010657167062163353\n",
      "Epoch: 1, Batch: 398, Loss: 0.13334746658802032\n",
      "Epoch: 1, Batch: 399, Loss: 0.028833674266934395\n",
      "Epoch: 1, Batch: 400, Loss: 0.09248881787061691\n",
      "Epoch: 1, Batch: 401, Loss: 0.014927605167031288\n",
      "Epoch: 1, Batch: 402, Loss: 0.020916171371936798\n",
      "Epoch: 1, Batch: 403, Loss: 0.007943420670926571\n",
      "Epoch: 1, Batch: 404, Loss: 0.040612444281578064\n",
      "Epoch: 1, Batch: 405, Loss: 0.015035184100270271\n",
      "Epoch: 1, Batch: 406, Loss: 0.022396959364414215\n",
      "Epoch: 1, Batch: 407, Loss: 0.07217872142791748\n",
      "Epoch: 1, Batch: 408, Loss: 0.017454221844673157\n",
      "Epoch: 1, Batch: 409, Loss: 0.018578117713332176\n",
      "Epoch: 1, Batch: 410, Loss: 0.16661688685417175\n",
      "Epoch: 1, Batch: 411, Loss: 0.011320262216031551\n",
      "Epoch: 1, Batch: 412, Loss: 0.024223772808909416\n",
      "Epoch: 1, Batch: 413, Loss: 0.034522004425525665\n",
      "Epoch: 1, Batch: 414, Loss: 0.008850685320794582\n",
      "Epoch: 1, Batch: 415, Loss: 0.03517347574234009\n",
      "Epoch: 1, Batch: 416, Loss: 0.005945809185504913\n",
      "Epoch: 1, Batch: 417, Loss: 0.05427872762084007\n",
      "Epoch: 1, Batch: 418, Loss: 0.16673913598060608\n",
      "Epoch: 1, Batch: 419, Loss: 0.09301508218050003\n",
      "Epoch: 1, Batch: 420, Loss: 0.0732583999633789\n",
      "Epoch: 1, Batch: 421, Loss: 0.013074700720608234\n",
      "Epoch: 1, Batch: 422, Loss: 0.10766267031431198\n",
      "Epoch: 1, Batch: 423, Loss: 0.05245243012905121\n",
      "Epoch: 1, Batch: 424, Loss: 0.154361754655838\n",
      "Epoch: 1, Batch: 425, Loss: 0.14233817160129547\n",
      "Epoch: 1, Batch: 426, Loss: 0.12600813806056976\n",
      "Epoch: 1, Batch: 427, Loss: 0.028444748371839523\n",
      "Epoch: 1, Batch: 428, Loss: 0.022013885900378227\n",
      "Epoch: 1, Batch: 429, Loss: 0.049026213586330414\n",
      "Epoch: 1, Batch: 430, Loss: 0.018685542047023773\n",
      "Epoch: 1, Batch: 431, Loss: 0.023293068632483482\n",
      "Epoch: 1, Batch: 432, Loss: 0.09841037541627884\n",
      "Epoch: 1, Batch: 433, Loss: 0.013634608127176762\n",
      "Epoch: 1, Batch: 434, Loss: 0.038486987352371216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 435, Loss: 0.1153571754693985\n",
      "Epoch: 1, Batch: 436, Loss: 0.07686148583889008\n",
      "Epoch: 1, Batch: 437, Loss: 0.13718080520629883\n",
      "Epoch: 1, Batch: 438, Loss: 0.024645017459988594\n",
      "Epoch: 1, Batch: 439, Loss: 0.0065572187304496765\n",
      "Epoch: 1, Batch: 440, Loss: 0.029302094131708145\n",
      "Epoch: 1, Batch: 441, Loss: 0.07635423541069031\n",
      "Epoch: 1, Batch: 442, Loss: 0.09563934057950974\n",
      "Epoch: 1, Batch: 443, Loss: 0.10014890134334564\n",
      "Epoch: 1, Batch: 444, Loss: 0.022506026551127434\n",
      "Epoch: 1, Batch: 445, Loss: 0.014885825105011463\n",
      "Epoch: 1, Batch: 446, Loss: 0.07980494201183319\n",
      "Epoch: 1, Batch: 447, Loss: 0.02201337181031704\n",
      "Epoch: 1, Batch: 448, Loss: 0.032318271696567535\n",
      "Epoch: 1, Batch: 449, Loss: 0.14156125485897064\n",
      "Epoch: 1, Batch: 450, Loss: 0.1567486971616745\n",
      "Epoch: 1, Batch: 451, Loss: 0.02784048207104206\n",
      "Epoch: 1, Batch: 452, Loss: 0.30299556255340576\n",
      "Epoch: 1, Batch: 453, Loss: 0.07016708701848984\n",
      "Epoch: 1, Batch: 454, Loss: 0.047177720814943314\n",
      "Epoch: 1, Batch: 455, Loss: 0.07399387657642365\n",
      "Epoch: 1, Batch: 456, Loss: 0.05892355367541313\n",
      "Epoch: 1, Batch: 457, Loss: 0.18176119029521942\n",
      "Epoch: 1, Batch: 458, Loss: 0.004514316562563181\n",
      "Epoch: 1, Batch: 459, Loss: 0.027513710781931877\n",
      "Epoch: 1, Batch: 460, Loss: 0.029655613005161285\n",
      "Epoch: 1, Batch: 461, Loss: 0.03683362901210785\n",
      "Epoch: 1, Batch: 462, Loss: 0.04311886802315712\n",
      "Epoch: 1, Batch: 463, Loss: 0.1284303516149521\n",
      "Epoch: 1, Batch: 464, Loss: 0.02308652736246586\n",
      "Epoch: 1, Batch: 465, Loss: 0.008164207451045513\n",
      "Epoch: 1, Batch: 466, Loss: 0.02911476604640484\n",
      "Epoch: 1, Batch: 467, Loss: 0.03634483739733696\n",
      "Epoch: 1, Batch: 468, Loss: 0.021305276080965996\n",
      "Epoch: 1, Batch: 469, Loss: 0.02017100900411606\n",
      "Epoch: 1, Batch: 470, Loss: 0.0076522487215697765\n",
      "Epoch: 1, Batch: 471, Loss: 0.016213877126574516\n",
      "Epoch: 1, Batch: 472, Loss: 0.051860127598047256\n",
      "Epoch: 1, Batch: 473, Loss: 0.04415453225374222\n",
      "Epoch: 1, Batch: 474, Loss: 0.06587471812963486\n",
      "Epoch: 1, Batch: 475, Loss: 0.11365173757076263\n",
      "Epoch: 1, Batch: 476, Loss: 0.019136561080813408\n",
      "Epoch: 1, Batch: 477, Loss: 0.010559621267020702\n",
      "Epoch: 1, Batch: 478, Loss: 0.0323949009180069\n",
      "Epoch: 1, Batch: 479, Loss: 0.0597355030477047\n",
      "Epoch: 1, Batch: 480, Loss: 0.02035258337855339\n",
      "Epoch: 1, Batch: 481, Loss: 0.11825580894947052\n",
      "Epoch: 1, Batch: 482, Loss: 0.030240189284086227\n",
      "Epoch: 1, Batch: 483, Loss: 0.017917301505804062\n",
      "Epoch: 1, Batch: 484, Loss: 0.10062477737665176\n",
      "Epoch: 1, Batch: 485, Loss: 0.03464455530047417\n",
      "Epoch: 1, Batch: 486, Loss: 0.1377250999212265\n",
      "Epoch: 1, Batch: 487, Loss: 0.060859497636556625\n",
      "Epoch: 1, Batch: 488, Loss: 0.021385354921221733\n",
      "Epoch: 1, Batch: 489, Loss: 0.018394462764263153\n",
      "Epoch: 1, Batch: 490, Loss: 0.030219055712223053\n",
      "Epoch: 1, Batch: 491, Loss: 0.20837755501270294\n",
      "Epoch: 1, Batch: 492, Loss: 0.07186812162399292\n",
      "Epoch: 1, Batch: 493, Loss: 0.015455683693289757\n",
      "Epoch: 1, Batch: 494, Loss: 0.01661999523639679\n",
      "Epoch: 1, Batch: 495, Loss: 0.04105168953537941\n",
      "Epoch: 1, Batch: 496, Loss: 0.026815911754965782\n",
      "Epoch: 1, Batch: 497, Loss: 0.038043078035116196\n",
      "Epoch: 1, Batch: 498, Loss: 0.0077135623432695866\n",
      "Epoch: 1, Batch: 499, Loss: 0.040234025567770004\n",
      "Epoch: 1, Batch: 500, Loss: 0.04110512137413025\n",
      "Epoch: 1, Batch: 501, Loss: 0.024662772193551064\n",
      "Epoch: 1, Batch: 502, Loss: 0.013561949133872986\n",
      "Epoch: 1, Batch: 503, Loss: 0.011851434595882893\n",
      "Epoch: 1, Batch: 504, Loss: 0.1173485666513443\n",
      "Epoch: 1, Batch: 505, Loss: 0.018641268834471703\n",
      "Epoch: 1, Batch: 506, Loss: 0.014237545430660248\n",
      "Epoch: 1, Batch: 507, Loss: 0.021618464961647987\n",
      "Epoch: 1, Batch: 508, Loss: 0.0027313814498484135\n",
      "Epoch: 1, Batch: 509, Loss: 0.04908979684114456\n",
      "Epoch: 1, Batch: 510, Loss: 0.10470632463693619\n",
      "Epoch: 1, Batch: 511, Loss: 0.028398877009749413\n",
      "Epoch: 1, Batch: 512, Loss: 0.004900340456515551\n",
      "Epoch: 1, Batch: 513, Loss: 0.015999753028154373\n",
      "Epoch: 1, Batch: 514, Loss: 0.19457828998565674\n",
      "Epoch: 1, Batch: 515, Loss: 0.011658081784844398\n",
      "Epoch: 1, Batch: 516, Loss: 0.15441390872001648\n",
      "Epoch: 1, Batch: 517, Loss: 0.006612005643546581\n",
      "Epoch: 1, Batch: 518, Loss: 0.050579097121953964\n",
      "Epoch: 1, Batch: 519, Loss: 0.07189934700727463\n",
      "Epoch: 1, Batch: 520, Loss: 0.01147538423538208\n",
      "Epoch: 1, Batch: 521, Loss: 0.060980841517448425\n",
      "Epoch: 1, Batch: 522, Loss: 0.08685555309057236\n",
      "Epoch: 1, Batch: 523, Loss: 0.021249284967780113\n",
      "Epoch: 1, Batch: 524, Loss: 0.012933391146361828\n",
      "Epoch: 1, Batch: 525, Loss: 0.09704175591468811\n",
      "Epoch: 1, Batch: 526, Loss: 0.012527571059763432\n",
      "Epoch: 1, Batch: 527, Loss: 0.09760407358407974\n",
      "Epoch: 1, Batch: 528, Loss: 0.054239917546510696\n",
      "Epoch: 1, Batch: 529, Loss: 0.08844467997550964\n",
      "Epoch: 1, Batch: 530, Loss: 0.014451393857598305\n",
      "Epoch: 1, Batch: 531, Loss: 0.05337883532047272\n",
      "Epoch: 1, Batch: 532, Loss: 0.016485854983329773\n",
      "Epoch: 1, Batch: 533, Loss: 0.035115938633680344\n",
      "Epoch: 1, Batch: 534, Loss: 0.0260035190731287\n",
      "Epoch: 1, Batch: 535, Loss: 0.10598787665367126\n",
      "Epoch: 1, Batch: 536, Loss: 0.021935321390628815\n",
      "Epoch: 1, Batch: 537, Loss: 0.009757837280631065\n",
      "Epoch: 1, Batch: 538, Loss: 0.03003990463912487\n",
      "Epoch: 1, Batch: 539, Loss: 0.016286471858620644\n",
      "Epoch: 1, Batch: 540, Loss: 0.03733839839696884\n",
      "Epoch: 1, Batch: 541, Loss: 0.09042114019393921\n",
      "Epoch: 1, Batch: 542, Loss: 0.11818357557058334\n",
      "Epoch: 1, Batch: 543, Loss: 0.0018625549273565412\n",
      "Epoch: 1, Batch: 544, Loss: 0.019382622092962265\n",
      "Epoch: 1, Batch: 545, Loss: 0.025430185720324516\n",
      "Epoch: 1, Batch: 546, Loss: 0.03692620247602463\n",
      "Epoch: 1, Batch: 547, Loss: 0.0727461650967598\n",
      "Epoch: 1, Batch: 548, Loss: 0.03886162489652634\n",
      "Epoch: 1, Batch: 549, Loss: 0.05118994042277336\n",
      "Epoch: 1, Batch: 550, Loss: 0.07191245257854462\n",
      "Epoch: 1, Batch: 551, Loss: 0.024737637490034103\n",
      "Epoch: 1, Batch: 552, Loss: 0.039664097130298615\n",
      "Epoch: 1, Batch: 553, Loss: 0.027003133669495583\n",
      "Epoch: 1, Batch: 554, Loss: 0.049873948097229004\n",
      "Epoch: 1, Batch: 555, Loss: 0.05936276167631149\n",
      "Epoch: 1, Batch: 556, Loss: 0.1058342307806015\n",
      "Epoch: 1, Batch: 557, Loss: 0.049837809056043625\n",
      "Epoch: 1, Batch: 558, Loss: 0.17227186262607574\n",
      "Epoch: 1, Batch: 559, Loss: 0.11101905256509781\n",
      "Epoch: 1, Batch: 560, Loss: 0.09405016154050827\n",
      "Epoch: 1, Batch: 561, Loss: 0.03421610966324806\n",
      "Epoch: 1, Batch: 562, Loss: 0.03951609879732132\n",
      "Epoch: 1, Batch: 563, Loss: 0.0031158546917140484\n",
      "Epoch: 1, Batch: 564, Loss: 0.048730578273534775\n",
      "Epoch: 1, Batch: 565, Loss: 0.046341247856616974\n",
      "Epoch: 1, Batch: 566, Loss: 0.041087258607149124\n",
      "Epoch: 1, Batch: 567, Loss: 0.32883918285369873\n",
      "Epoch: 1, Batch: 568, Loss: 0.016920803114771843\n",
      "Epoch: 1, Batch: 569, Loss: 0.013517310842871666\n",
      "Epoch: 1, Batch: 570, Loss: 0.006545969285070896\n",
      "Epoch: 1, Batch: 571, Loss: 0.07525777071714401\n",
      "Epoch: 1, Batch: 572, Loss: 0.02754340134561062\n",
      "Epoch: 1, Batch: 573, Loss: 0.0843832865357399\n",
      "Epoch: 1, Batch: 574, Loss: 0.02025335654616356\n",
      "Epoch: 1, Batch: 575, Loss: 0.07187765091657639\n",
      "Epoch: 1, Batch: 576, Loss: 0.038844894617795944\n",
      "Epoch: 1, Batch: 577, Loss: 0.013014677911996841\n",
      "Epoch: 1, Batch: 578, Loss: 0.12444984167814255\n",
      "Epoch: 1, Batch: 579, Loss: 0.05072151497006416\n",
      "Epoch: 1, Batch: 580, Loss: 0.1143743246793747\n",
      "Epoch: 1, Batch: 581, Loss: 0.07319282740354538\n",
      "Epoch: 1, Batch: 582, Loss: 0.023681016638875008\n",
      "Epoch: 1, Batch: 583, Loss: 0.0733778327703476\n",
      "Epoch: 1, Batch: 584, Loss: 0.09302786737680435\n",
      "Epoch: 1, Batch: 585, Loss: 0.0973455160856247\n",
      "Epoch: 1, Batch: 586, Loss: 0.056186940521001816\n",
      "Epoch: 1, Batch: 587, Loss: 0.02776181325316429\n",
      "Epoch: 1, Batch: 588, Loss: 0.02318122237920761\n",
      "Epoch: 1, Batch: 589, Loss: 0.014308430254459381\n",
      "Epoch: 1, Batch: 590, Loss: 0.05118247866630554\n",
      "Epoch: 1, Batch: 591, Loss: 0.1775256246328354\n",
      "Epoch: 1, Batch: 592, Loss: 0.06257933378219604\n",
      "Epoch: 1, Batch: 593, Loss: 0.0215814970433712\n",
      "Epoch: 1, Batch: 594, Loss: 0.041323453187942505\n",
      "Epoch: 1, Batch: 595, Loss: 0.08346784859895706\n",
      "Epoch: 1, Batch: 596, Loss: 0.0797756016254425\n",
      "Epoch: 1, Batch: 597, Loss: 0.010815269313752651\n",
      "Epoch: 1, Batch: 598, Loss: 0.05131400749087334\n",
      "Epoch: 1, Batch: 599, Loss: 0.030888631939888\n",
      "Epoch: 1, Batch: 600, Loss: 0.27353668212890625\n",
      "Epoch: 1, Batch: 601, Loss: 0.11882225424051285\n",
      "Epoch: 1, Batch: 602, Loss: 0.0823499858379364\n",
      "Epoch: 1, Batch: 603, Loss: 0.015321210026741028\n",
      "Epoch: 1, Batch: 604, Loss: 0.11150695383548737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 605, Loss: 0.032211173325777054\n",
      "Epoch: 1, Batch: 606, Loss: 0.05386004596948624\n",
      "Epoch: 1, Batch: 607, Loss: 0.03505537658929825\n",
      "Epoch: 1, Batch: 608, Loss: 0.11033542454242706\n",
      "Epoch: 1, Batch: 609, Loss: 0.1673736423254013\n",
      "Epoch: 1, Batch: 610, Loss: 0.04540573060512543\n",
      "Epoch: 1, Batch: 611, Loss: 0.02703188546001911\n",
      "Epoch: 1, Batch: 612, Loss: 0.03575542941689491\n",
      "Epoch: 1, Batch: 613, Loss: 0.07448583096265793\n",
      "Epoch: 1, Batch: 614, Loss: 0.12832395732402802\n",
      "Epoch: 1, Batch: 615, Loss: 0.042042579501867294\n",
      "Epoch: 1, Batch: 616, Loss: 0.040190503001213074\n",
      "Epoch: 1, Batch: 617, Loss: 0.06820060312747955\n",
      "Epoch: 1, Batch: 618, Loss: 0.014873862266540527\n",
      "Epoch: 1, Batch: 619, Loss: 0.00827767513692379\n",
      "Epoch: 1, Batch: 620, Loss: 0.03695562854409218\n",
      "Epoch: 1, Batch: 621, Loss: 0.051968324929475784\n",
      "Epoch: 1, Batch: 622, Loss: 0.05402360111474991\n",
      "Epoch: 1, Batch: 623, Loss: 0.07889962941408157\n",
      "Epoch: 1, Batch: 624, Loss: 0.043475788086652756\n",
      "Epoch: 1, Batch: 625, Loss: 0.041495613753795624\n",
      "Epoch: 1, Batch: 626, Loss: 0.042951010167598724\n",
      "Epoch: 1, Batch: 627, Loss: 0.023196274414658546\n",
      "Epoch: 1, Batch: 628, Loss: 0.03263299912214279\n",
      "Epoch: 1, Batch: 629, Loss: 0.03062530979514122\n",
      "Epoch: 1, Batch: 630, Loss: 0.061169739812612534\n",
      "Epoch: 1, Batch: 631, Loss: 0.012162488885223866\n",
      "Epoch: 1, Batch: 632, Loss: 0.046724095940589905\n",
      "Epoch: 1, Batch: 633, Loss: 0.07066898047924042\n",
      "Epoch: 1, Batch: 634, Loss: 0.03241942450404167\n",
      "Epoch: 1, Batch: 635, Loss: 0.010673885233700275\n",
      "Epoch: 1, Batch: 636, Loss: 0.017375817522406578\n",
      "Epoch: 1, Batch: 637, Loss: 0.06497390568256378\n",
      "Epoch: 1, Batch: 638, Loss: 0.1715679168701172\n",
      "Epoch: 1, Batch: 639, Loss: 0.11306990683078766\n",
      "Epoch: 1, Batch: 640, Loss: 0.03275551274418831\n",
      "Epoch: 1, Batch: 641, Loss: 0.06920265406370163\n",
      "Epoch: 1, Batch: 642, Loss: 0.0366080105304718\n",
      "Epoch: 1, Batch: 643, Loss: 0.009462159126996994\n",
      "Epoch: 1, Batch: 644, Loss: 0.35647767782211304\n",
      "Epoch: 1, Batch: 645, Loss: 0.03753931075334549\n",
      "Epoch: 1, Batch: 646, Loss: 0.21515701711177826\n",
      "Epoch: 1, Batch: 647, Loss: 0.0045754555612802505\n",
      "Epoch: 1, Batch: 648, Loss: 0.02118508517742157\n",
      "Epoch: 1, Batch: 649, Loss: 0.045760855078697205\n",
      "Epoch: 1, Batch: 650, Loss: 0.026413900777697563\n",
      "Epoch: 1, Batch: 651, Loss: 0.11992038041353226\n",
      "Epoch: 1, Batch: 652, Loss: 0.015093663707375526\n",
      "Epoch: 1, Batch: 653, Loss: 0.04237222298979759\n",
      "Epoch: 1, Batch: 654, Loss: 0.020280642434954643\n",
      "Epoch: 1, Batch: 655, Loss: 0.12057814747095108\n",
      "Epoch: 1, Batch: 656, Loss: 0.028155267238616943\n",
      "Epoch: 1, Batch: 657, Loss: 0.06337155401706696\n",
      "Epoch: 1, Batch: 658, Loss: 0.008002834394574165\n",
      "Epoch: 1, Batch: 659, Loss: 0.058760929852724075\n",
      "Epoch: 1, Batch: 660, Loss: 0.049500130116939545\n",
      "Epoch: 1, Batch: 661, Loss: 0.039285436272621155\n",
      "Epoch: 1, Batch: 662, Loss: 0.12557438015937805\n",
      "Epoch: 1, Batch: 663, Loss: 0.016635574400424957\n",
      "Epoch: 1, Batch: 664, Loss: 0.015052830800414085\n",
      "Epoch: 1, Batch: 665, Loss: 0.09256624430418015\n",
      "Epoch: 1, Batch: 666, Loss: 0.03985495865345001\n",
      "Epoch: 1, Batch: 667, Loss: 0.012727975845336914\n",
      "Epoch: 1, Batch: 668, Loss: 0.018425356596708298\n",
      "Epoch: 1, Batch: 669, Loss: 0.017208807170391083\n",
      "Epoch: 1, Batch: 670, Loss: 0.06246680021286011\n",
      "Epoch: 1, Batch: 671, Loss: 0.01611354947090149\n",
      "Epoch: 1, Batch: 672, Loss: 0.00648318137973547\n",
      "Epoch: 1, Batch: 673, Loss: 0.15883119404315948\n",
      "Epoch: 1, Batch: 674, Loss: 0.005715308710932732\n",
      "Epoch: 1, Batch: 675, Loss: 0.011974203400313854\n",
      "Epoch: 1, Batch: 676, Loss: 0.042701683938503265\n",
      "Epoch: 1, Batch: 677, Loss: 0.04741857945919037\n",
      "Epoch: 1, Batch: 678, Loss: 0.1312437355518341\n",
      "Epoch: 1, Batch: 679, Loss: 0.08840867131948471\n",
      "Epoch: 1, Batch: 680, Loss: 0.007945617660880089\n",
      "Epoch: 1, Batch: 681, Loss: 0.16659307479858398\n",
      "Epoch: 1, Batch: 682, Loss: 0.04633304104208946\n",
      "Epoch: 1, Batch: 683, Loss: 0.00950131006538868\n",
      "Epoch: 1, Batch: 684, Loss: 0.017646828666329384\n",
      "Epoch: 1, Batch: 685, Loss: 0.0026984219439327717\n",
      "Epoch: 1, Batch: 686, Loss: 0.0018742324318736792\n",
      "Epoch: 1, Batch: 687, Loss: 0.05072988197207451\n",
      "Epoch: 1, Batch: 688, Loss: 0.008069450035691261\n",
      "Epoch: 1, Batch: 689, Loss: 0.020768368616700172\n",
      "Epoch: 1, Batch: 690, Loss: 0.10266370326280594\n",
      "Epoch: 1, Batch: 691, Loss: 0.05056639760732651\n",
      "Epoch: 1, Batch: 692, Loss: 0.022632751613855362\n",
      "Epoch: 1, Batch: 693, Loss: 0.08712345361709595\n",
      "Epoch: 1, Batch: 694, Loss: 0.05727193504571915\n",
      "Epoch: 1, Batch: 695, Loss: 0.07056102901697159\n",
      "Epoch: 1, Batch: 696, Loss: 0.047362394630908966\n",
      "Epoch: 1, Batch: 697, Loss: 0.011868287809193134\n",
      "Epoch: 1, Batch: 698, Loss: 0.027187205851078033\n",
      "Epoch: 1, Batch: 699, Loss: 0.018978334963321686\n",
      "Epoch: 1, Batch: 700, Loss: 0.017841104418039322\n",
      "Epoch: 1, Batch: 701, Loss: 0.03144891560077667\n",
      "Epoch: 1, Batch: 702, Loss: 0.05657155439257622\n",
      "Epoch: 1, Batch: 703, Loss: 0.10251927375793457\n",
      "Epoch: 1, Batch: 704, Loss: 0.08026152104139328\n",
      "Epoch: 1, Batch: 705, Loss: 0.008739150129258633\n",
      "Epoch: 1, Batch: 706, Loss: 0.00849796924740076\n",
      "Epoch: 1, Batch: 707, Loss: 0.05545220524072647\n",
      "Epoch: 1, Batch: 708, Loss: 0.19437360763549805\n",
      "Epoch: 1, Batch: 709, Loss: 0.03995230048894882\n",
      "Epoch: 1, Batch: 710, Loss: 0.022951191291213036\n",
      "Epoch: 1, Batch: 711, Loss: 0.07338713109493256\n",
      "Epoch: 1, Batch: 712, Loss: 0.007000897079706192\n",
      "Epoch: 1, Batch: 713, Loss: 0.002762101823464036\n",
      "Epoch: 1, Batch: 714, Loss: 0.06253912299871445\n",
      "Epoch: 1, Batch: 715, Loss: 0.17465443909168243\n",
      "Epoch: 1, Batch: 716, Loss: 0.04018296301364899\n",
      "Epoch: 1, Batch: 717, Loss: 0.07299952954053879\n",
      "Epoch: 1, Batch: 718, Loss: 0.003603921039029956\n",
      "Epoch: 1, Batch: 719, Loss: 0.09340716153383255\n",
      "Epoch: 1, Batch: 720, Loss: 0.004528614692389965\n",
      "Epoch: 1, Batch: 721, Loss: 0.010036170482635498\n",
      "Epoch: 1, Batch: 722, Loss: 0.03715837746858597\n",
      "Epoch: 1, Batch: 723, Loss: 0.05531392619013786\n",
      "Epoch: 1, Batch: 724, Loss: 0.00413143215700984\n",
      "Epoch: 1, Batch: 725, Loss: 0.022320201620459557\n",
      "Epoch: 1, Batch: 726, Loss: 0.09973303973674774\n",
      "Epoch: 1, Batch: 727, Loss: 0.05932749807834625\n",
      "Epoch: 1, Batch: 728, Loss: 0.08670467883348465\n",
      "Epoch: 1, Batch: 729, Loss: 0.03515985235571861\n",
      "Epoch: 1, Batch: 730, Loss: 0.07971975952386856\n",
      "Epoch: 1, Batch: 731, Loss: 0.07939497381448746\n",
      "Epoch: 1, Batch: 732, Loss: 0.07260801643133163\n",
      "Epoch: 1, Batch: 733, Loss: 0.04615151882171631\n",
      "Epoch: 1, Batch: 734, Loss: 0.02476959116756916\n",
      "Epoch: 1, Batch: 735, Loss: 0.11082319915294647\n",
      "Epoch: 1, Batch: 736, Loss: 0.1556636542081833\n",
      "Epoch: 1, Batch: 737, Loss: 0.040810566395521164\n",
      "Epoch: 1, Batch: 738, Loss: 0.093895822763443\n",
      "Epoch: 1, Batch: 739, Loss: 0.018286416307091713\n",
      "Epoch: 1, Batch: 740, Loss: 0.00957130640745163\n",
      "Epoch: 1, Batch: 741, Loss: 0.12582258880138397\n",
      "Epoch: 1, Batch: 742, Loss: 0.0622384175658226\n",
      "Epoch: 1, Batch: 743, Loss: 0.08873454481363297\n",
      "Epoch: 1, Batch: 744, Loss: 0.20232447981834412\n",
      "Epoch: 1, Batch: 745, Loss: 0.04108259826898575\n",
      "Epoch: 1, Batch: 746, Loss: 0.0617300420999527\n",
      "Epoch: 1, Batch: 747, Loss: 0.03829142451286316\n",
      "Epoch: 1, Batch: 748, Loss: 0.008101836778223515\n",
      "Epoch: 1, Batch: 749, Loss: 0.04299263656139374\n",
      "Epoch: 1, Batch: 750, Loss: 0.15179957449436188\n",
      "Epoch: 1, Batch: 751, Loss: 0.09210757166147232\n",
      "Epoch: 1, Batch: 752, Loss: 0.03158595412969589\n",
      "Epoch: 1, Batch: 753, Loss: 0.021758412942290306\n",
      "Epoch: 1, Batch: 754, Loss: 0.005055703222751617\n",
      "Epoch: 1, Batch: 755, Loss: 0.02739216759800911\n",
      "Epoch: 1, Batch: 756, Loss: 0.020221896469593048\n",
      "Epoch: 1, Batch: 757, Loss: 0.04509348422288895\n",
      "Epoch: 1, Batch: 758, Loss: 0.05944342911243439\n",
      "Epoch: 1, Batch: 759, Loss: 0.013118098489940166\n",
      "Epoch: 1, Batch: 760, Loss: 0.030137119814753532\n",
      "Epoch: 1, Batch: 761, Loss: 0.010415383614599705\n",
      "Epoch: 1, Batch: 762, Loss: 0.22102786600589752\n",
      "Epoch: 1, Batch: 763, Loss: 0.0644754022359848\n",
      "Epoch: 1, Batch: 764, Loss: 0.06460314989089966\n",
      "Epoch: 1, Batch: 765, Loss: 0.011270025745034218\n",
      "Epoch: 1, Batch: 766, Loss: 0.01064571738243103\n",
      "Epoch: 1, Batch: 767, Loss: 0.11916495114564896\n",
      "Epoch: 1, Batch: 768, Loss: 0.003910595551133156\n",
      "Epoch: 1, Batch: 769, Loss: 0.0305060725659132\n",
      "Epoch: 1, Batch: 770, Loss: 0.10142453014850616\n",
      "Epoch: 1, Batch: 771, Loss: 0.04290579631924629\n",
      "Epoch: 1, Batch: 772, Loss: 0.00270020286552608\n",
      "Epoch: 1, Batch: 773, Loss: 0.028664126992225647\n",
      "Epoch: 1, Batch: 774, Loss: 0.049151208251714706\n",
      "Epoch: 1, Batch: 775, Loss: 0.11086699366569519\n",
      "Epoch: 1, Batch: 776, Loss: 0.012840339913964272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 777, Loss: 0.011405966244637966\n",
      "Epoch: 1, Batch: 778, Loss: 0.01919533498585224\n",
      "Epoch: 1, Batch: 779, Loss: 0.005183277651667595\n",
      "Epoch: 1, Batch: 780, Loss: 0.026852412149310112\n",
      "Epoch: 1, Batch: 781, Loss: 0.018375111743807793\n",
      "Epoch: 1, Batch: 782, Loss: 0.02795417420566082\n",
      "Epoch: 1, Batch: 783, Loss: 0.019082017242908478\n",
      "Epoch: 1, Batch: 784, Loss: 0.025677870959043503\n",
      "Epoch: 1, Batch: 785, Loss: 0.012134520336985588\n",
      "Epoch: 1, Batch: 786, Loss: 0.00964272953569889\n",
      "Epoch: 1, Batch: 787, Loss: 0.022789545357227325\n",
      "Epoch: 1, Batch: 788, Loss: 0.06978721916675568\n",
      "Epoch: 1, Batch: 789, Loss: 0.14569951593875885\n",
      "Epoch: 1, Batch: 790, Loss: 0.015667933970689774\n",
      "Epoch: 1, Batch: 791, Loss: 0.019437352195382118\n",
      "Epoch: 1, Batch: 792, Loss: 0.034270405769348145\n",
      "Epoch: 1, Batch: 793, Loss: 0.007916025817394257\n",
      "Epoch: 1, Batch: 794, Loss: 0.016439633443951607\n",
      "Epoch: 1, Batch: 795, Loss: 0.04764215275645256\n",
      "Epoch: 1, Batch: 796, Loss: 0.057714033871889114\n",
      "Epoch: 1, Batch: 797, Loss: 0.01916392892599106\n",
      "Epoch: 1, Batch: 798, Loss: 0.07298766821622849\n",
      "Epoch: 1, Batch: 799, Loss: 0.015301411040127277\n",
      "Epoch: 1, Batch: 800, Loss: 0.08493854105472565\n",
      "Epoch: 1, Batch: 801, Loss: 0.1874336153268814\n",
      "Epoch: 1, Batch: 802, Loss: 0.010093504562973976\n",
      "Epoch: 1, Batch: 803, Loss: 0.03039477951824665\n",
      "Epoch: 1, Batch: 804, Loss: 0.06185728684067726\n",
      "Epoch: 1, Batch: 805, Loss: 0.08216212689876556\n",
      "Epoch: 1, Batch: 806, Loss: 0.022517235949635506\n",
      "Epoch: 1, Batch: 807, Loss: 0.02815767377614975\n",
      "Epoch: 1, Batch: 808, Loss: 0.058534976094961166\n",
      "Epoch: 1, Batch: 809, Loss: 0.008418013341724873\n",
      "Epoch: 1, Batch: 810, Loss: 0.01031124871224165\n",
      "Epoch: 1, Batch: 811, Loss: 0.08794368803501129\n",
      "Epoch: 1, Batch: 812, Loss: 0.11802981793880463\n",
      "Epoch: 1, Batch: 813, Loss: 0.10690663754940033\n",
      "Epoch: 1, Batch: 814, Loss: 0.08575884997844696\n",
      "Epoch: 1, Batch: 815, Loss: 0.1388397216796875\n",
      "Epoch: 1, Batch: 816, Loss: 0.10844328254461288\n",
      "Epoch: 1, Batch: 817, Loss: 0.12375182658433914\n",
      "Epoch: 1, Batch: 818, Loss: 0.05067577585577965\n",
      "Epoch: 1, Batch: 819, Loss: 0.011013814248144627\n",
      "Epoch: 1, Batch: 820, Loss: 0.004341161344200373\n",
      "Epoch: 1, Batch: 821, Loss: 0.025074921548366547\n",
      "Epoch: 1, Batch: 822, Loss: 0.008769317530095577\n",
      "Epoch: 1, Batch: 823, Loss: 0.03754325583577156\n",
      "Epoch: 1, Batch: 824, Loss: 0.1285017430782318\n",
      "Epoch: 1, Batch: 825, Loss: 0.018711553886532784\n",
      "Epoch: 1, Batch: 826, Loss: 0.06782077252864838\n",
      "Epoch: 1, Batch: 827, Loss: 0.09071270376443863\n",
      "Epoch: 1, Batch: 828, Loss: 0.14414192736148834\n",
      "Epoch: 1, Batch: 829, Loss: 0.12996576726436615\n",
      "Epoch: 1, Batch: 830, Loss: 0.04538305848836899\n",
      "Epoch: 1, Batch: 831, Loss: 0.034350212663412094\n",
      "Epoch: 1, Batch: 832, Loss: 0.07504455745220184\n",
      "Epoch: 1, Batch: 833, Loss: 0.0634317398071289\n",
      "Epoch: 1, Batch: 834, Loss: 0.018165286630392075\n",
      "Epoch: 1, Batch: 835, Loss: 0.036185890436172485\n",
      "Epoch: 1, Batch: 836, Loss: 0.018255366012454033\n",
      "Epoch: 1, Batch: 837, Loss: 0.023871688172221184\n",
      "Epoch: 1, Batch: 838, Loss: 0.04747762903571129\n",
      "Epoch: 1, Batch: 839, Loss: 0.04038180038332939\n",
      "Epoch: 1, Batch: 840, Loss: 0.048177313059568405\n",
      "Epoch: 1, Batch: 841, Loss: 0.03734566271305084\n",
      "Epoch: 1, Batch: 842, Loss: 0.11679535359144211\n",
      "Epoch: 1, Batch: 843, Loss: 0.08554309606552124\n",
      "Epoch: 1, Batch: 844, Loss: 0.15130062401294708\n",
      "Epoch: 1, Batch: 845, Loss: 0.02019880898296833\n",
      "Epoch: 1, Batch: 846, Loss: 0.048235028982162476\n",
      "Epoch: 1, Batch: 847, Loss: 0.023720968514680862\n",
      "Epoch: 1, Batch: 848, Loss: 0.025826331228017807\n",
      "Epoch: 1, Batch: 849, Loss: 0.02118157222867012\n",
      "Epoch: 1, Batch: 850, Loss: 0.030247515067458153\n",
      "Epoch: 1, Batch: 851, Loss: 0.021745389327406883\n",
      "Epoch: 1, Batch: 852, Loss: 0.02716563642024994\n",
      "Epoch: 1, Batch: 853, Loss: 0.1426468789577484\n",
      "Epoch: 1, Batch: 854, Loss: 0.0016447799280285835\n",
      "Epoch: 1, Batch: 855, Loss: 0.053996145725250244\n",
      "Epoch: 1, Batch: 856, Loss: 0.027655595913529396\n",
      "Epoch: 1, Batch: 857, Loss: 0.04924372211098671\n",
      "Epoch: 1, Batch: 858, Loss: 0.051372986286878586\n",
      "Epoch: 1, Batch: 859, Loss: 0.08121711015701294\n",
      "Epoch: 1, Batch: 860, Loss: 0.0318768285214901\n",
      "Epoch: 1, Batch: 861, Loss: 0.004374656826257706\n",
      "Epoch: 1, Batch: 862, Loss: 0.10362883657217026\n",
      "Epoch: 1, Batch: 863, Loss: 0.03677469491958618\n",
      "Epoch: 1, Batch: 864, Loss: 0.07142739742994308\n",
      "Epoch: 1, Batch: 865, Loss: 0.0024044092278927565\n",
      "Epoch: 1, Batch: 866, Loss: 0.020150305703282356\n",
      "Epoch: 1, Batch: 867, Loss: 0.003220119047909975\n",
      "Epoch: 1, Batch: 868, Loss: 0.00512530654668808\n",
      "Epoch: 1, Batch: 869, Loss: 0.02473418042063713\n",
      "Epoch: 1, Batch: 870, Loss: 0.1016015037894249\n",
      "Epoch: 1, Batch: 871, Loss: 0.1298893839120865\n",
      "Epoch: 1, Batch: 872, Loss: 0.004642120096832514\n",
      "Epoch: 1, Batch: 873, Loss: 0.006167526822537184\n",
      "Epoch: 1, Batch: 874, Loss: 0.008735436014831066\n",
      "Epoch: 1, Batch: 875, Loss: 0.04742095246911049\n",
      "Epoch: 1, Batch: 876, Loss: 0.09252463281154633\n",
      "Epoch: 1, Batch: 877, Loss: 0.022600796073675156\n",
      "Epoch: 1, Batch: 878, Loss: 0.11712659150362015\n",
      "Epoch: 1, Batch: 879, Loss: 0.08544716984033585\n",
      "Epoch: 1, Batch: 880, Loss: 0.014620908536016941\n",
      "Epoch: 1, Batch: 881, Loss: 0.056497592478990555\n",
      "Epoch: 1, Batch: 882, Loss: 0.024030419066548347\n",
      "Epoch: 1, Batch: 883, Loss: 0.08139197528362274\n",
      "Epoch: 1, Batch: 884, Loss: 0.05961206182837486\n",
      "Epoch: 1, Batch: 885, Loss: 0.1552325040102005\n",
      "Epoch: 1, Batch: 886, Loss: 0.017643287777900696\n",
      "Epoch: 1, Batch: 887, Loss: 0.08216537535190582\n",
      "Epoch: 1, Batch: 888, Loss: 0.030842795968055725\n",
      "Epoch: 1, Batch: 889, Loss: 0.009952699765563011\n",
      "Epoch: 1, Batch: 890, Loss: 0.03935001790523529\n",
      "Epoch: 1, Batch: 891, Loss: 0.020368065685033798\n",
      "Epoch: 1, Batch: 892, Loss: 0.028156578540802002\n",
      "Epoch: 1, Batch: 893, Loss: 0.11161038279533386\n",
      "Epoch: 1, Batch: 894, Loss: 0.1173849031329155\n",
      "Epoch: 1, Batch: 895, Loss: 0.049914486706256866\n",
      "Epoch: 1, Batch: 896, Loss: 0.020059220492839813\n",
      "Epoch: 1, Batch: 897, Loss: 0.08352258056402206\n",
      "Epoch: 1, Batch: 898, Loss: 0.03139851987361908\n",
      "Epoch: 1, Batch: 899, Loss: 0.06298930197954178\n",
      "Epoch: 1, Batch: 900, Loss: 0.09836602210998535\n",
      "Epoch: 1, Batch: 901, Loss: 0.024563664570450783\n",
      "Epoch: 1, Batch: 902, Loss: 0.12245453149080276\n",
      "Epoch: 1, Batch: 903, Loss: 0.0206137727946043\n",
      "Epoch: 1, Batch: 904, Loss: 0.030893035233020782\n",
      "Epoch: 1, Batch: 905, Loss: 0.008945616893470287\n",
      "Epoch: 1, Batch: 906, Loss: 0.011991110630333424\n",
      "Epoch: 1, Batch: 907, Loss: 0.030237969011068344\n",
      "Epoch: 1, Batch: 908, Loss: 0.022424064576625824\n",
      "Epoch: 1, Batch: 909, Loss: 0.0038965772837400436\n",
      "Epoch: 1, Batch: 910, Loss: 0.0726141557097435\n",
      "Epoch: 1, Batch: 911, Loss: 0.011555629782378674\n",
      "Epoch: 1, Batch: 912, Loss: 0.016548290848731995\n",
      "Epoch: 1, Batch: 913, Loss: 0.01326138898730278\n",
      "Epoch: 1, Batch: 914, Loss: 0.007597802206873894\n",
      "Epoch: 1, Batch: 915, Loss: 0.004461114294826984\n",
      "Epoch: 1, Batch: 916, Loss: 0.007072183769196272\n",
      "Epoch: 1, Batch: 917, Loss: 0.025183888152241707\n",
      "Epoch: 1, Batch: 918, Loss: 0.14677287638187408\n",
      "Epoch: 1, Batch: 919, Loss: 0.03226396068930626\n",
      "Epoch: 1, Batch: 920, Loss: 0.029539484530687332\n",
      "Epoch: 1, Batch: 921, Loss: 0.041431356221437454\n",
      "Epoch: 1, Batch: 922, Loss: 0.005035410635173321\n",
      "Epoch: 1, Batch: 923, Loss: 0.0018062141025438905\n",
      "Epoch: 1, Batch: 924, Loss: 0.003578194184228778\n",
      "Epoch: 1, Batch: 925, Loss: 0.04162350296974182\n",
      "Epoch: 1, Batch: 926, Loss: 0.012074809521436691\n",
      "Epoch: 1, Batch: 927, Loss: 0.053479231894016266\n",
      "Epoch: 1, Batch: 928, Loss: 0.016241243109107018\n",
      "Epoch: 1, Batch: 929, Loss: 0.08011660724878311\n",
      "Epoch: 1, Batch: 930, Loss: 0.16586269438266754\n",
      "Epoch: 1, Batch: 931, Loss: 0.04794378578662872\n",
      "Epoch: 1, Batch: 932, Loss: 0.028933502733707428\n",
      "Epoch: 1, Batch: 933, Loss: 0.05588190257549286\n",
      "Epoch: 1, Batch: 934, Loss: 0.08475019037723541\n",
      "Epoch: 1, Batch: 935, Loss: 0.10914712399244308\n",
      "Epoch: 1, Batch: 936, Loss: 0.05556735768914223\n",
      "Epoch: 1, Batch: 937, Loss: 0.014096575789153576\n",
      "Epoch: 2, Batch: 0, Loss: 0.013326216489076614\n",
      "Epoch: 2, Batch: 1, Loss: 0.0044601052068173885\n",
      "Epoch: 2, Batch: 2, Loss: 0.11861702799797058\n",
      "Epoch: 2, Batch: 3, Loss: 0.04885098338127136\n",
      "Epoch: 2, Batch: 4, Loss: 0.05908524990081787\n",
      "Epoch: 2, Batch: 5, Loss: 0.006949711125344038\n",
      "Epoch: 2, Batch: 6, Loss: 0.011984104290604591\n",
      "Epoch: 2, Batch: 7, Loss: 0.09707802534103394\n",
      "Epoch: 2, Batch: 8, Loss: 0.04117411747574806\n",
      "Epoch: 2, Batch: 9, Loss: 0.09720609337091446\n",
      "Epoch: 2, Batch: 10, Loss: 0.043425772339105606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch: 11, Loss: 0.003997826017439365\n",
      "Epoch: 2, Batch: 12, Loss: 0.015065069310367107\n",
      "Epoch: 2, Batch: 13, Loss: 0.017392821609973907\n",
      "Epoch: 2, Batch: 14, Loss: 0.005056121852248907\n",
      "Epoch: 2, Batch: 15, Loss: 0.10228609293699265\n",
      "Epoch: 2, Batch: 16, Loss: 0.055978402495384216\n",
      "Epoch: 2, Batch: 17, Loss: 0.05065825954079628\n",
      "Epoch: 2, Batch: 18, Loss: 0.034972988069057465\n",
      "Epoch: 2, Batch: 19, Loss: 0.04376237839460373\n",
      "Epoch: 2, Batch: 20, Loss: 0.02868635393679142\n",
      "Epoch: 2, Batch: 21, Loss: 0.06743907928466797\n",
      "Epoch: 2, Batch: 22, Loss: 0.07341647148132324\n",
      "Epoch: 2, Batch: 23, Loss: 0.02521040290594101\n",
      "Epoch: 2, Batch: 24, Loss: 0.02559906803071499\n",
      "Epoch: 2, Batch: 25, Loss: 0.01463788840919733\n",
      "Epoch: 2, Batch: 26, Loss: 0.010171583853662014\n",
      "Epoch: 2, Batch: 27, Loss: 0.015210424549877644\n",
      "Epoch: 2, Batch: 28, Loss: 0.03737016022205353\n",
      "Epoch: 2, Batch: 29, Loss: 0.003359735244885087\n",
      "Epoch: 2, Batch: 30, Loss: 0.05492754280567169\n",
      "Epoch: 2, Batch: 31, Loss: 0.0043634213507175446\n",
      "Epoch: 2, Batch: 32, Loss: 0.035417333245277405\n",
      "Epoch: 2, Batch: 33, Loss: 0.05970848351716995\n",
      "Epoch: 2, Batch: 34, Loss: 0.044555678963661194\n",
      "Epoch: 2, Batch: 35, Loss: 0.018633762374520302\n",
      "Epoch: 2, Batch: 36, Loss: 0.05907813459634781\n",
      "Epoch: 2, Batch: 37, Loss: 0.03940916433930397\n",
      "Epoch: 2, Batch: 38, Loss: 0.00952870398759842\n",
      "Epoch: 2, Batch: 39, Loss: 0.011559977196156979\n",
      "Epoch: 2, Batch: 40, Loss: 0.02676890417933464\n",
      "Epoch: 2, Batch: 41, Loss: 0.015904679894447327\n",
      "Epoch: 2, Batch: 42, Loss: 0.016217518597841263\n",
      "Epoch: 2, Batch: 43, Loss: 0.0015097353607416153\n",
      "Epoch: 2, Batch: 44, Loss: 0.10052366554737091\n",
      "Epoch: 2, Batch: 45, Loss: 0.12898080050945282\n",
      "Epoch: 2, Batch: 46, Loss: 0.04705356806516647\n",
      "Epoch: 2, Batch: 47, Loss: 0.05589909106492996\n",
      "Epoch: 2, Batch: 48, Loss: 0.0702383890748024\n",
      "Epoch: 2, Batch: 49, Loss: 0.08737435936927795\n",
      "Epoch: 2, Batch: 50, Loss: 0.023269226774573326\n",
      "Epoch: 2, Batch: 51, Loss: 0.11352913081645966\n",
      "Epoch: 2, Batch: 52, Loss: 0.031439218670129776\n",
      "Epoch: 2, Batch: 53, Loss: 0.02820422127842903\n",
      "Epoch: 2, Batch: 54, Loss: 0.030027024447917938\n",
      "Epoch: 2, Batch: 55, Loss: 0.01613798551261425\n",
      "Epoch: 2, Batch: 56, Loss: 0.014973118901252747\n",
      "Epoch: 2, Batch: 57, Loss: 0.15538479387760162\n",
      "Epoch: 2, Batch: 58, Loss: 0.011679830960929394\n",
      "Epoch: 2, Batch: 59, Loss: 0.014771128073334694\n",
      "Epoch: 2, Batch: 60, Loss: 0.01909872516989708\n",
      "Epoch: 2, Batch: 61, Loss: 0.09255238622426987\n",
      "Epoch: 2, Batch: 62, Loss: 0.002971467562019825\n",
      "Epoch: 2, Batch: 63, Loss: 0.1471775770187378\n",
      "Epoch: 2, Batch: 64, Loss: 0.006324711721390486\n",
      "Epoch: 2, Batch: 65, Loss: 0.0991671234369278\n",
      "Epoch: 2, Batch: 66, Loss: 0.05385950580239296\n",
      "Epoch: 2, Batch: 67, Loss: 0.06108550354838371\n",
      "Epoch: 2, Batch: 68, Loss: 0.006838327273726463\n",
      "Epoch: 2, Batch: 69, Loss: 0.08077831566333771\n",
      "Epoch: 2, Batch: 70, Loss: 0.060276105999946594\n",
      "Epoch: 2, Batch: 71, Loss: 0.009516923688352108\n",
      "Epoch: 2, Batch: 72, Loss: 0.04698924347758293\n",
      "Epoch: 2, Batch: 73, Loss: 0.001872604712843895\n",
      "Epoch: 2, Batch: 74, Loss: 0.0555914007127285\n",
      "Epoch: 2, Batch: 75, Loss: 0.03777849301695824\n",
      "Epoch: 2, Batch: 76, Loss: 0.026156475767493248\n",
      "Epoch: 2, Batch: 77, Loss: 0.0029275717679411173\n",
      "Epoch: 2, Batch: 78, Loss: 0.012936193495988846\n",
      "Epoch: 2, Batch: 79, Loss: 0.043866854161024094\n",
      "Epoch: 2, Batch: 80, Loss: 0.13247233629226685\n",
      "Epoch: 2, Batch: 81, Loss: 0.010176311247050762\n",
      "Epoch: 2, Batch: 82, Loss: 0.020804613828659058\n",
      "Epoch: 2, Batch: 83, Loss: 0.02311744913458824\n",
      "Epoch: 2, Batch: 84, Loss: 0.013540375046432018\n",
      "Epoch: 2, Batch: 85, Loss: 0.04381725937128067\n",
      "Epoch: 2, Batch: 86, Loss: 0.030565384775400162\n",
      "Epoch: 2, Batch: 87, Loss: 0.17892862856388092\n",
      "Epoch: 2, Batch: 88, Loss: 0.07398892939090729\n",
      "Epoch: 2, Batch: 89, Loss: 0.029097644612193108\n",
      "Epoch: 2, Batch: 90, Loss: 0.006134015507996082\n",
      "Epoch: 2, Batch: 91, Loss: 0.040622759610414505\n",
      "Epoch: 2, Batch: 92, Loss: 0.045805610716342926\n",
      "Epoch: 2, Batch: 93, Loss: 0.010491397231817245\n",
      "Epoch: 2, Batch: 94, Loss: 0.1277574747800827\n",
      "Epoch: 2, Batch: 95, Loss: 0.023337237536907196\n",
      "Epoch: 2, Batch: 96, Loss: 0.026316825300455093\n",
      "Epoch: 2, Batch: 97, Loss: 0.04748070240020752\n",
      "Epoch: 2, Batch: 98, Loss: 0.00227734399959445\n",
      "Epoch: 2, Batch: 99, Loss: 0.006991902366280556\n",
      "Epoch: 2, Batch: 100, Loss: 0.006420961581170559\n",
      "Epoch: 2, Batch: 101, Loss: 0.042315900325775146\n",
      "Epoch: 2, Batch: 102, Loss: 0.020731372758746147\n",
      "Epoch: 2, Batch: 103, Loss: 0.06936942040920258\n",
      "Epoch: 2, Batch: 104, Loss: 0.0031218768563121557\n",
      "Epoch: 2, Batch: 105, Loss: 0.00980470422655344\n",
      "Epoch: 2, Batch: 106, Loss: 0.028277361765503883\n",
      "Epoch: 2, Batch: 107, Loss: 0.038286518305540085\n",
      "Epoch: 2, Batch: 108, Loss: 0.02756679058074951\n",
      "Epoch: 2, Batch: 109, Loss: 0.004560785833746195\n",
      "Epoch: 2, Batch: 110, Loss: 0.07958367466926575\n",
      "Epoch: 2, Batch: 111, Loss: 0.03294594585895538\n",
      "Epoch: 2, Batch: 112, Loss: 0.037415869534015656\n",
      "Epoch: 2, Batch: 113, Loss: 0.08518378436565399\n",
      "Epoch: 2, Batch: 114, Loss: 0.04331519454717636\n",
      "Epoch: 2, Batch: 115, Loss: 0.022784244269132614\n",
      "Epoch: 2, Batch: 116, Loss: 0.002890689531341195\n",
      "Epoch: 2, Batch: 117, Loss: 0.02825995162129402\n",
      "Epoch: 2, Batch: 118, Loss: 0.06476214528083801\n",
      "Epoch: 2, Batch: 119, Loss: 0.004789539612829685\n",
      "Epoch: 2, Batch: 120, Loss: 0.12355566024780273\n",
      "Epoch: 2, Batch: 121, Loss: 0.05653095617890358\n",
      "Epoch: 2, Batch: 122, Loss: 0.01798238791525364\n",
      "Epoch: 2, Batch: 123, Loss: 0.04317428916692734\n",
      "Epoch: 2, Batch: 124, Loss: 0.005252169910818338\n",
      "Epoch: 2, Batch: 125, Loss: 0.0009625353268347681\n",
      "Epoch: 2, Batch: 126, Loss: 0.019099799916148186\n",
      "Epoch: 2, Batch: 127, Loss: 0.04411697015166283\n",
      "Epoch: 2, Batch: 128, Loss: 0.00907185673713684\n",
      "Epoch: 2, Batch: 129, Loss: 0.07794016599655151\n",
      "Epoch: 2, Batch: 130, Loss: 0.014329828321933746\n",
      "Epoch: 2, Batch: 131, Loss: 0.06158367544412613\n",
      "Epoch: 2, Batch: 132, Loss: 0.03401247411966324\n",
      "Epoch: 2, Batch: 133, Loss: 0.010618435218930244\n",
      "Epoch: 2, Batch: 134, Loss: 0.002314079785719514\n",
      "Epoch: 2, Batch: 135, Loss: 0.003676576539874077\n",
      "Epoch: 2, Batch: 136, Loss: 0.06497126072645187\n",
      "Epoch: 2, Batch: 137, Loss: 0.04377613589167595\n",
      "Epoch: 2, Batch: 138, Loss: 0.1828695684671402\n",
      "Epoch: 2, Batch: 139, Loss: 0.0038785480428487062\n",
      "Epoch: 2, Batch: 140, Loss: 0.04649805650115013\n",
      "Epoch: 2, Batch: 141, Loss: 0.09592355787754059\n",
      "Epoch: 2, Batch: 142, Loss: 0.05576233193278313\n",
      "Epoch: 2, Batch: 143, Loss: 0.0350210964679718\n",
      "Epoch: 2, Batch: 144, Loss: 0.008222627453505993\n",
      "Epoch: 2, Batch: 145, Loss: 0.015150053426623344\n",
      "Epoch: 2, Batch: 146, Loss: 0.0019867494702339172\n",
      "Epoch: 2, Batch: 147, Loss: 0.013563277199864388\n",
      "Epoch: 2, Batch: 148, Loss: 0.037620894610881805\n",
      "Epoch: 2, Batch: 149, Loss: 0.009762190282344818\n",
      "Epoch: 2, Batch: 150, Loss: 0.05056125670671463\n",
      "Epoch: 2, Batch: 151, Loss: 0.0029070493765175343\n",
      "Epoch: 2, Batch: 152, Loss: 0.11905501782894135\n",
      "Epoch: 2, Batch: 153, Loss: 0.04582056403160095\n",
      "Epoch: 2, Batch: 154, Loss: 0.11273074150085449\n",
      "Epoch: 2, Batch: 155, Loss: 0.01502123661339283\n",
      "Epoch: 2, Batch: 156, Loss: 0.022799406200647354\n",
      "Epoch: 2, Batch: 157, Loss: 0.006317342631518841\n",
      "Epoch: 2, Batch: 158, Loss: 0.10623577237129211\n",
      "Epoch: 2, Batch: 159, Loss: 0.03328951448202133\n",
      "Epoch: 2, Batch: 160, Loss: 0.05110872909426689\n",
      "Epoch: 2, Batch: 161, Loss: 0.005012881010770798\n",
      "Epoch: 2, Batch: 162, Loss: 0.0037464830093085766\n",
      "Epoch: 2, Batch: 163, Loss: 0.16059866547584534\n",
      "Epoch: 2, Batch: 164, Loss: 0.015524228103458881\n",
      "Epoch: 2, Batch: 165, Loss: 0.05184676870703697\n",
      "Epoch: 2, Batch: 166, Loss: 0.003196831326931715\n",
      "Epoch: 2, Batch: 167, Loss: 0.0037735714577138424\n",
      "Epoch: 2, Batch: 168, Loss: 0.0463964119553566\n",
      "Epoch: 2, Batch: 169, Loss: 0.03855764865875244\n",
      "Epoch: 2, Batch: 170, Loss: 0.014150944538414478\n",
      "Epoch: 2, Batch: 171, Loss: 0.012809686362743378\n",
      "Epoch: 2, Batch: 172, Loss: 0.014285235665738583\n",
      "Epoch: 2, Batch: 173, Loss: 0.08622638881206512\n",
      "Epoch: 2, Batch: 174, Loss: 0.007793355733156204\n",
      "Epoch: 2, Batch: 175, Loss: 0.01767614297568798\n",
      "Epoch: 2, Batch: 176, Loss: 0.13023631274700165\n",
      "Epoch: 2, Batch: 177, Loss: 0.05808858945965767\n",
      "Epoch: 2, Batch: 178, Loss: 0.05970580503344536\n",
      "Epoch: 2, Batch: 179, Loss: 0.021225247532129288\n",
      "Epoch: 2, Batch: 180, Loss: 0.02057267725467682\n",
      "Epoch: 2, Batch: 181, Loss: 0.07917381078004837\n",
      "Epoch: 2, Batch: 182, Loss: 0.06139543280005455\n",
      "Epoch: 2, Batch: 183, Loss: 0.08437825739383698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch: 184, Loss: 0.032417044043540955\n",
      "Epoch: 2, Batch: 185, Loss: 0.07152564823627472\n",
      "Epoch: 2, Batch: 186, Loss: 0.006186936050653458\n",
      "Epoch: 2, Batch: 187, Loss: 0.01619628258049488\n",
      "Epoch: 2, Batch: 188, Loss: 0.0505952388048172\n",
      "Epoch: 2, Batch: 189, Loss: 0.007359557785093784\n",
      "Epoch: 2, Batch: 190, Loss: 0.024958031252026558\n",
      "Epoch: 2, Batch: 191, Loss: 0.023788372054696083\n",
      "Epoch: 2, Batch: 192, Loss: 0.02193029411137104\n",
      "Epoch: 2, Batch: 193, Loss: 0.06484919786453247\n",
      "Epoch: 2, Batch: 194, Loss: 0.05432966351509094\n",
      "Epoch: 2, Batch: 195, Loss: 0.015344841405749321\n",
      "Epoch: 2, Batch: 196, Loss: 0.002815890358760953\n",
      "Epoch: 2, Batch: 197, Loss: 0.05290723592042923\n",
      "Epoch: 2, Batch: 198, Loss: 0.07855405658483505\n",
      "Epoch: 2, Batch: 199, Loss: 0.1232132613658905\n",
      "Epoch: 2, Batch: 200, Loss: 0.012798653915524483\n",
      "Epoch: 2, Batch: 201, Loss: 0.02460324391722679\n",
      "Epoch: 2, Batch: 202, Loss: 0.013950641267001629\n",
      "Epoch: 2, Batch: 203, Loss: 0.006693270988762379\n",
      "Epoch: 2, Batch: 204, Loss: 0.01168335136026144\n",
      "Epoch: 2, Batch: 205, Loss: 0.009331762790679932\n",
      "Epoch: 2, Batch: 206, Loss: 0.07788971811532974\n",
      "Epoch: 2, Batch: 207, Loss: 0.05070457607507706\n",
      "Epoch: 2, Batch: 208, Loss: 0.02388177439570427\n",
      "Epoch: 2, Batch: 209, Loss: 0.012455863878130913\n",
      "Epoch: 2, Batch: 210, Loss: 0.010529186576604843\n",
      "Epoch: 2, Batch: 211, Loss: 0.031082743778824806\n",
      "Epoch: 2, Batch: 212, Loss: 0.013105582445859909\n",
      "Epoch: 2, Batch: 213, Loss: 0.03722073882818222\n",
      "Epoch: 2, Batch: 214, Loss: 0.020846212282776833\n",
      "Epoch: 2, Batch: 215, Loss: 0.06771156936883926\n",
      "Epoch: 2, Batch: 216, Loss: 0.09704786539077759\n",
      "Epoch: 2, Batch: 217, Loss: 0.15595054626464844\n",
      "Epoch: 2, Batch: 218, Loss: 0.02822396345436573\n",
      "Epoch: 2, Batch: 219, Loss: 0.009799633175134659\n",
      "Epoch: 2, Batch: 220, Loss: 0.028652852401137352\n",
      "Epoch: 2, Batch: 221, Loss: 0.03339139372110367\n",
      "Epoch: 2, Batch: 222, Loss: 0.10840306431055069\n",
      "Epoch: 2, Batch: 223, Loss: 0.003041869029402733\n",
      "Epoch: 2, Batch: 224, Loss: 0.06972343474626541\n",
      "Epoch: 2, Batch: 225, Loss: 0.017628110945224762\n",
      "Epoch: 2, Batch: 226, Loss: 0.034753330051898956\n",
      "Epoch: 2, Batch: 227, Loss: 0.06488154828548431\n",
      "Epoch: 2, Batch: 228, Loss: 0.002487785881385207\n",
      "Epoch: 2, Batch: 229, Loss: 0.03837212547659874\n",
      "Epoch: 2, Batch: 230, Loss: 0.003968956880271435\n",
      "Epoch: 2, Batch: 231, Loss: 0.021883348003029823\n",
      "Epoch: 2, Batch: 232, Loss: 0.011070283129811287\n",
      "Epoch: 2, Batch: 233, Loss: 0.005141054280102253\n",
      "Epoch: 2, Batch: 234, Loss: 0.12104037404060364\n",
      "Epoch: 2, Batch: 235, Loss: 0.041779279708862305\n",
      "Epoch: 2, Batch: 236, Loss: 0.05272926762700081\n",
      "Epoch: 2, Batch: 237, Loss: 0.046788834035396576\n",
      "Epoch: 2, Batch: 238, Loss: 0.07798060774803162\n",
      "Epoch: 2, Batch: 239, Loss: 0.015040593221783638\n",
      "Epoch: 2, Batch: 240, Loss: 0.03585520386695862\n",
      "Epoch: 2, Batch: 241, Loss: 0.036490049213171005\n",
      "Epoch: 2, Batch: 242, Loss: 0.03853409364819527\n",
      "Epoch: 2, Batch: 243, Loss: 0.040296588093042374\n",
      "Epoch: 2, Batch: 244, Loss: 0.007360189221799374\n",
      "Epoch: 2, Batch: 245, Loss: 0.0051088882610201836\n",
      "Epoch: 2, Batch: 246, Loss: 0.007583697326481342\n",
      "Epoch: 2, Batch: 247, Loss: 0.04901561141014099\n",
      "Epoch: 2, Batch: 248, Loss: 0.016664421185851097\n",
      "Epoch: 2, Batch: 249, Loss: 0.004154426045715809\n",
      "Epoch: 2, Batch: 250, Loss: 0.0018834607908502221\n",
      "Epoch: 2, Batch: 251, Loss: 0.0319308340549469\n",
      "Epoch: 2, Batch: 252, Loss: 0.008502686396241188\n",
      "Epoch: 2, Batch: 253, Loss: 0.01911354996263981\n",
      "Epoch: 2, Batch: 254, Loss: 0.016393909230828285\n",
      "Epoch: 2, Batch: 255, Loss: 0.17938396334648132\n",
      "Epoch: 2, Batch: 256, Loss: 0.09793633222579956\n",
      "Epoch: 2, Batch: 257, Loss: 0.0225511621683836\n",
      "Epoch: 2, Batch: 258, Loss: 0.15214693546295166\n",
      "Epoch: 2, Batch: 259, Loss: 0.27108919620513916\n",
      "Epoch: 2, Batch: 260, Loss: 0.031769994646310806\n",
      "Epoch: 2, Batch: 261, Loss: 0.0033387523144483566\n",
      "Epoch: 2, Batch: 262, Loss: 0.0077762296423316\n",
      "Epoch: 2, Batch: 263, Loss: 0.042960572987794876\n",
      "Epoch: 2, Batch: 264, Loss: 0.016949016600847244\n",
      "Epoch: 2, Batch: 265, Loss: 0.004411621019244194\n",
      "Epoch: 2, Batch: 266, Loss: 0.037246402353048325\n",
      "Epoch: 2, Batch: 267, Loss: 0.02928493544459343\n",
      "Epoch: 2, Batch: 268, Loss: 0.03332133591175079\n",
      "Epoch: 2, Batch: 269, Loss: 0.011284815147519112\n",
      "Epoch: 2, Batch: 270, Loss: 0.005125537980347872\n",
      "Epoch: 2, Batch: 271, Loss: 0.06939096003770828\n",
      "Epoch: 2, Batch: 272, Loss: 0.016615141183137894\n",
      "Epoch: 2, Batch: 273, Loss: 0.0032955205533653498\n",
      "Epoch: 2, Batch: 274, Loss: 0.006834819447249174\n",
      "Epoch: 2, Batch: 275, Loss: 0.030176309868693352\n",
      "Epoch: 2, Batch: 276, Loss: 0.02266944944858551\n",
      "Epoch: 2, Batch: 277, Loss: 0.012897230684757233\n",
      "Epoch: 2, Batch: 278, Loss: 0.005484684370458126\n",
      "Epoch: 2, Batch: 279, Loss: 0.031054722145199776\n",
      "Epoch: 2, Batch: 280, Loss: 0.0063901254907250404\n",
      "Epoch: 2, Batch: 281, Loss: 0.05391067638993263\n",
      "Epoch: 2, Batch: 282, Loss: 0.017878683283925056\n",
      "Epoch: 2, Batch: 283, Loss: 0.02101345919072628\n",
      "Epoch: 2, Batch: 284, Loss: 0.008339393883943558\n",
      "Epoch: 2, Batch: 285, Loss: 0.005875864066183567\n",
      "Epoch: 2, Batch: 286, Loss: 0.1670287549495697\n",
      "Epoch: 2, Batch: 287, Loss: 0.013083869591355324\n",
      "Epoch: 2, Batch: 288, Loss: 0.003040893469005823\n",
      "Epoch: 2, Batch: 289, Loss: 0.12029411643743515\n",
      "Epoch: 2, Batch: 290, Loss: 0.011403296142816544\n",
      "Epoch: 2, Batch: 291, Loss: 0.007988600991666317\n",
      "Epoch: 2, Batch: 292, Loss: 0.025352710857987404\n",
      "Epoch: 2, Batch: 293, Loss: 0.015353776514530182\n",
      "Epoch: 2, Batch: 294, Loss: 0.03353158384561539\n",
      "Epoch: 2, Batch: 295, Loss: 0.017584457993507385\n",
      "Epoch: 2, Batch: 296, Loss: 0.05864677205681801\n",
      "Epoch: 2, Batch: 297, Loss: 0.007877279072999954\n",
      "Epoch: 2, Batch: 298, Loss: 0.0021405955776572227\n",
      "Epoch: 2, Batch: 299, Loss: 0.011657186783850193\n",
      "Epoch: 2, Batch: 300, Loss: 0.018396783620119095\n",
      "Epoch: 2, Batch: 301, Loss: 0.07817987352609634\n",
      "Epoch: 2, Batch: 302, Loss: 0.04336653649806976\n",
      "Epoch: 2, Batch: 303, Loss: 0.0523160956799984\n",
      "Epoch: 2, Batch: 304, Loss: 0.011323705315589905\n",
      "Epoch: 2, Batch: 305, Loss: 0.03430505469441414\n",
      "Epoch: 2, Batch: 306, Loss: 0.057715509086847305\n",
      "Epoch: 2, Batch: 307, Loss: 0.07093252241611481\n",
      "Epoch: 2, Batch: 308, Loss: 0.00902031920850277\n",
      "Epoch: 2, Batch: 309, Loss: 0.01634342037141323\n",
      "Epoch: 2, Batch: 310, Loss: 0.0312616191804409\n",
      "Epoch: 2, Batch: 311, Loss: 0.07663067430257797\n",
      "Epoch: 2, Batch: 312, Loss: 0.02787056192755699\n",
      "Epoch: 2, Batch: 313, Loss: 0.03218550235033035\n",
      "Epoch: 2, Batch: 314, Loss: 0.008088435977697372\n",
      "Epoch: 2, Batch: 315, Loss: 0.009955087676644325\n",
      "Epoch: 2, Batch: 316, Loss: 0.30884411931037903\n",
      "Epoch: 2, Batch: 317, Loss: 0.0016054706647992134\n",
      "Epoch: 2, Batch: 318, Loss: 0.0848318412899971\n",
      "Epoch: 2, Batch: 319, Loss: 0.04726637899875641\n",
      "Epoch: 2, Batch: 320, Loss: 0.016786709427833557\n",
      "Epoch: 2, Batch: 321, Loss: 0.02029983326792717\n",
      "Epoch: 2, Batch: 322, Loss: 0.06934434920549393\n",
      "Epoch: 2, Batch: 323, Loss: 0.07266942411661148\n",
      "Epoch: 2, Batch: 324, Loss: 0.10085627436637878\n",
      "Epoch: 2, Batch: 325, Loss: 0.03207706660032272\n",
      "Epoch: 2, Batch: 326, Loss: 0.020563092082738876\n",
      "Epoch: 2, Batch: 327, Loss: 0.011442894116044044\n",
      "Epoch: 2, Batch: 328, Loss: 0.030920540913939476\n",
      "Epoch: 2, Batch: 329, Loss: 0.016166988760232925\n",
      "Epoch: 2, Batch: 330, Loss: 0.006429753266274929\n",
      "Epoch: 2, Batch: 331, Loss: 0.04446951299905777\n",
      "Epoch: 2, Batch: 332, Loss: 0.066304512321949\n",
      "Epoch: 2, Batch: 333, Loss: 0.01600746624171734\n",
      "Epoch: 2, Batch: 334, Loss: 0.11440006643533707\n",
      "Epoch: 2, Batch: 335, Loss: 0.014295066706836224\n",
      "Epoch: 2, Batch: 336, Loss: 0.012223891913890839\n",
      "Epoch: 2, Batch: 337, Loss: 0.005707850679755211\n",
      "Epoch: 2, Batch: 338, Loss: 0.06443604826927185\n",
      "Epoch: 2, Batch: 339, Loss: 0.05238894000649452\n",
      "Epoch: 2, Batch: 340, Loss: 0.005763871595263481\n",
      "Epoch: 2, Batch: 341, Loss: 0.04166547954082489\n",
      "Epoch: 2, Batch: 342, Loss: 0.1316109597682953\n",
      "Epoch: 2, Batch: 343, Loss: 0.015598691068589687\n",
      "Epoch: 2, Batch: 344, Loss: 0.005105216056108475\n",
      "Epoch: 2, Batch: 345, Loss: 0.04834964871406555\n",
      "Epoch: 2, Batch: 346, Loss: 0.005075715482234955\n",
      "Epoch: 2, Batch: 347, Loss: 0.08174905180931091\n",
      "Epoch: 2, Batch: 348, Loss: 0.014196611009538174\n",
      "Epoch: 2, Batch: 349, Loss: 0.01643110252916813\n",
      "Epoch: 2, Batch: 350, Loss: 0.020969081670045853\n",
      "Epoch: 2, Batch: 351, Loss: 0.019787084311246872\n",
      "Epoch: 2, Batch: 352, Loss: 0.06901998817920685\n",
      "Epoch: 2, Batch: 353, Loss: 0.02459092251956463\n",
      "Epoch: 2, Batch: 354, Loss: 0.02647014893591404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch: 355, Loss: 0.04201105982065201\n",
      "Epoch: 2, Batch: 356, Loss: 0.023670479655265808\n",
      "Epoch: 2, Batch: 357, Loss: 0.03901474550366402\n",
      "Epoch: 2, Batch: 358, Loss: 0.04735129326581955\n",
      "Epoch: 2, Batch: 359, Loss: 0.0028149441350251436\n",
      "Epoch: 2, Batch: 360, Loss: 0.0465233139693737\n",
      "Epoch: 2, Batch: 361, Loss: 0.04047567397356033\n",
      "Epoch: 2, Batch: 362, Loss: 0.09309942275285721\n",
      "Epoch: 2, Batch: 363, Loss: 0.04669885337352753\n",
      "Epoch: 2, Batch: 364, Loss: 0.03581351414322853\n",
      "Epoch: 2, Batch: 365, Loss: 0.05186009407043457\n",
      "Epoch: 2, Batch: 366, Loss: 0.13195888698101044\n",
      "Epoch: 2, Batch: 367, Loss: 0.02639409713447094\n",
      "Epoch: 2, Batch: 368, Loss: 0.07017592340707779\n",
      "Epoch: 2, Batch: 369, Loss: 0.03305058553814888\n",
      "Epoch: 2, Batch: 370, Loss: 0.004220218397676945\n",
      "Epoch: 2, Batch: 371, Loss: 0.06303343921899796\n",
      "Epoch: 2, Batch: 372, Loss: 0.005810526665300131\n",
      "Epoch: 2, Batch: 373, Loss: 0.0011406801640987396\n",
      "Epoch: 2, Batch: 374, Loss: 0.007974697276949883\n",
      "Epoch: 2, Batch: 375, Loss: 0.007942627184092999\n",
      "Epoch: 2, Batch: 376, Loss: 0.0011059329845011234\n",
      "Epoch: 2, Batch: 377, Loss: 0.05239184573292732\n",
      "Epoch: 2, Batch: 378, Loss: 0.058929137885570526\n",
      "Epoch: 2, Batch: 379, Loss: 0.025080956518650055\n",
      "Epoch: 2, Batch: 380, Loss: 0.013058619573712349\n",
      "Epoch: 2, Batch: 381, Loss: 0.04381028935313225\n",
      "Epoch: 2, Batch: 382, Loss: 0.01601136475801468\n",
      "Epoch: 2, Batch: 383, Loss: 0.034609146416187286\n",
      "Epoch: 2, Batch: 384, Loss: 0.043449755758047104\n",
      "Epoch: 2, Batch: 385, Loss: 0.020560171455144882\n",
      "Epoch: 2, Batch: 386, Loss: 0.002271897392347455\n",
      "Epoch: 2, Batch: 387, Loss: 0.04499451443552971\n",
      "Epoch: 2, Batch: 388, Loss: 0.0323965884745121\n",
      "Epoch: 2, Batch: 389, Loss: 0.08156540989875793\n",
      "Epoch: 2, Batch: 390, Loss: 0.062347929924726486\n",
      "Epoch: 2, Batch: 391, Loss: 0.02290991134941578\n",
      "Epoch: 2, Batch: 392, Loss: 0.01076353807002306\n",
      "Epoch: 2, Batch: 393, Loss: 0.04078555107116699\n",
      "Epoch: 2, Batch: 394, Loss: 0.21385203301906586\n",
      "Epoch: 2, Batch: 395, Loss: 0.005208206828683615\n",
      "Epoch: 2, Batch: 396, Loss: 0.005991857498884201\n",
      "Epoch: 2, Batch: 397, Loss: 0.03293650969862938\n",
      "Epoch: 2, Batch: 398, Loss: 0.00554038118571043\n",
      "Epoch: 2, Batch: 399, Loss: 0.03436712548136711\n",
      "Epoch: 2, Batch: 400, Loss: 0.031452734023332596\n",
      "Epoch: 2, Batch: 401, Loss: 0.05204196646809578\n",
      "Epoch: 2, Batch: 402, Loss: 0.008761017583310604\n",
      "Epoch: 2, Batch: 403, Loss: 0.044444840401411057\n",
      "Epoch: 2, Batch: 404, Loss: 0.02384279854595661\n",
      "Epoch: 2, Batch: 405, Loss: 0.06255537271499634\n",
      "Epoch: 2, Batch: 406, Loss: 0.028555195778608322\n",
      "Epoch: 2, Batch: 407, Loss: 0.04361959546804428\n",
      "Epoch: 2, Batch: 408, Loss: 0.0021444247104227543\n",
      "Epoch: 2, Batch: 409, Loss: 0.04075125977396965\n",
      "Epoch: 2, Batch: 410, Loss: 0.04192795604467392\n",
      "Epoch: 2, Batch: 411, Loss: 0.017920760437846184\n",
      "Epoch: 2, Batch: 412, Loss: 0.010378044098615646\n",
      "Epoch: 2, Batch: 413, Loss: 0.012196599505841732\n",
      "Epoch: 2, Batch: 414, Loss: 0.007874419912695885\n",
      "Epoch: 2, Batch: 415, Loss: 0.02736392617225647\n",
      "Epoch: 2, Batch: 416, Loss: 0.0206951592117548\n",
      "Epoch: 2, Batch: 417, Loss: 0.027991507202386856\n",
      "Epoch: 2, Batch: 418, Loss: 0.03365056589245796\n",
      "Epoch: 2, Batch: 419, Loss: 0.049349453300237656\n",
      "Epoch: 2, Batch: 420, Loss: 0.002610498806461692\n",
      "Epoch: 2, Batch: 421, Loss: 0.029968736693263054\n",
      "Epoch: 2, Batch: 422, Loss: 0.017618365585803986\n",
      "Epoch: 2, Batch: 423, Loss: 0.0083316620439291\n",
      "Epoch: 2, Batch: 424, Loss: 0.07829651236534119\n",
      "Epoch: 2, Batch: 425, Loss: 0.04439682513475418\n",
      "Epoch: 2, Batch: 426, Loss: 0.034414440393447876\n",
      "Epoch: 2, Batch: 427, Loss: 0.05476098507642746\n",
      "Epoch: 2, Batch: 428, Loss: 0.018596144393086433\n",
      "Epoch: 2, Batch: 429, Loss: 0.024585705250501633\n",
      "Epoch: 2, Batch: 430, Loss: 0.18859894573688507\n",
      "Epoch: 2, Batch: 431, Loss: 0.05195433273911476\n",
      "Epoch: 2, Batch: 432, Loss: 0.008785799145698547\n",
      "Epoch: 2, Batch: 433, Loss: 0.026165861636400223\n",
      "Epoch: 2, Batch: 434, Loss: 0.011927799321711063\n",
      "Epoch: 2, Batch: 435, Loss: 0.00549216428771615\n",
      "Epoch: 2, Batch: 436, Loss: 0.004661199636757374\n",
      "Epoch: 2, Batch: 437, Loss: 0.010095402598381042\n",
      "Epoch: 2, Batch: 438, Loss: 0.03420552611351013\n",
      "Epoch: 2, Batch: 439, Loss: 0.1142861619591713\n",
      "Epoch: 2, Batch: 440, Loss: 0.0538153275847435\n",
      "Epoch: 2, Batch: 441, Loss: 0.022641368210315704\n",
      "Epoch: 2, Batch: 442, Loss: 0.005553655792027712\n",
      "Epoch: 2, Batch: 443, Loss: 0.006505416240543127\n",
      "Epoch: 2, Batch: 444, Loss: 0.020306484773755074\n",
      "Epoch: 2, Batch: 445, Loss: 0.1267600953578949\n",
      "Epoch: 2, Batch: 446, Loss: 0.07169662415981293\n",
      "Epoch: 2, Batch: 447, Loss: 0.012281986884772778\n",
      "Epoch: 2, Batch: 448, Loss: 0.014176182448863983\n",
      "Epoch: 2, Batch: 449, Loss: 0.08003219962120056\n",
      "Epoch: 2, Batch: 450, Loss: 0.010195189155638218\n",
      "Epoch: 2, Batch: 451, Loss: 0.038515605032444\n",
      "Epoch: 2, Batch: 452, Loss: 0.04728379845619202\n",
      "Epoch: 2, Batch: 453, Loss: 0.036314211785793304\n",
      "Epoch: 2, Batch: 454, Loss: 0.004130127374082804\n",
      "Epoch: 2, Batch: 455, Loss: 0.031400151550769806\n",
      "Epoch: 2, Batch: 456, Loss: 0.006711246911436319\n",
      "Epoch: 2, Batch: 457, Loss: 0.05513519421219826\n",
      "Epoch: 2, Batch: 458, Loss: 0.011575565673410892\n",
      "Epoch: 2, Batch: 459, Loss: 0.008316525258123875\n",
      "Epoch: 2, Batch: 460, Loss: 0.014324504882097244\n",
      "Epoch: 2, Batch: 461, Loss: 0.02760634571313858\n",
      "Epoch: 2, Batch: 462, Loss: 0.02653716877102852\n",
      "Epoch: 2, Batch: 463, Loss: 0.01366150937974453\n",
      "Epoch: 2, Batch: 464, Loss: 0.07741186022758484\n",
      "Epoch: 2, Batch: 465, Loss: 0.013735665939748287\n",
      "Epoch: 2, Batch: 466, Loss: 0.03375645726919174\n",
      "Epoch: 2, Batch: 467, Loss: 0.014066722244024277\n",
      "Epoch: 2, Batch: 468, Loss: 0.0023797224275767803\n",
      "Epoch: 2, Batch: 469, Loss: 0.011424928903579712\n",
      "Epoch: 2, Batch: 470, Loss: 0.08208169043064117\n",
      "Epoch: 2, Batch: 471, Loss: 0.0015106728533282876\n",
      "Epoch: 2, Batch: 472, Loss: 0.028343314304947853\n",
      "Epoch: 2, Batch: 473, Loss: 0.12272227555513382\n",
      "Epoch: 2, Batch: 474, Loss: 0.004485520534217358\n",
      "Epoch: 2, Batch: 475, Loss: 0.010776959359645844\n",
      "Epoch: 2, Batch: 476, Loss: 0.04244115948677063\n",
      "Epoch: 2, Batch: 477, Loss: 0.024273844435811043\n",
      "Epoch: 2, Batch: 478, Loss: 0.027797402814030647\n",
      "Epoch: 2, Batch: 479, Loss: 0.006744166370481253\n",
      "Epoch: 2, Batch: 480, Loss: 0.05579761043190956\n",
      "Epoch: 2, Batch: 481, Loss: 0.023900318890810013\n",
      "Epoch: 2, Batch: 482, Loss: 0.003685309085994959\n",
      "Epoch: 2, Batch: 483, Loss: 0.010972882620990276\n",
      "Epoch: 2, Batch: 484, Loss: 0.053943898528814316\n",
      "Epoch: 2, Batch: 485, Loss: 0.15017114579677582\n",
      "Epoch: 2, Batch: 486, Loss: 0.006518447306007147\n",
      "Epoch: 2, Batch: 487, Loss: 0.041468940675258636\n",
      "Epoch: 2, Batch: 488, Loss: 0.015562084503471851\n",
      "Epoch: 2, Batch: 489, Loss: 0.03557383269071579\n",
      "Epoch: 2, Batch: 490, Loss: 0.05293518677353859\n",
      "Epoch: 2, Batch: 491, Loss: 0.012586360797286034\n",
      "Epoch: 2, Batch: 492, Loss: 0.10016709566116333\n",
      "Epoch: 2, Batch: 493, Loss: 0.1389303356409073\n",
      "Epoch: 2, Batch: 494, Loss: 0.0012895966647192836\n",
      "Epoch: 2, Batch: 495, Loss: 0.029322775080800056\n",
      "Epoch: 2, Batch: 496, Loss: 0.02999410219490528\n",
      "Epoch: 2, Batch: 497, Loss: 0.10072094947099686\n",
      "Epoch: 2, Batch: 498, Loss: 0.01172828208655119\n",
      "Epoch: 2, Batch: 499, Loss: 0.014886541292071342\n",
      "Epoch: 2, Batch: 500, Loss: 0.05397900938987732\n",
      "Epoch: 2, Batch: 501, Loss: 0.059964369982481\n",
      "Epoch: 2, Batch: 502, Loss: 0.016684845089912415\n",
      "Epoch: 2, Batch: 503, Loss: 0.05852409452199936\n",
      "Epoch: 2, Batch: 504, Loss: 0.004592954181134701\n",
      "Epoch: 2, Batch: 505, Loss: 0.029266105964779854\n",
      "Epoch: 2, Batch: 506, Loss: 0.003961806185543537\n",
      "Epoch: 2, Batch: 507, Loss: 0.03350808098912239\n",
      "Epoch: 2, Batch: 508, Loss: 0.019098889082670212\n",
      "Epoch: 2, Batch: 509, Loss: 0.03904920816421509\n",
      "Epoch: 2, Batch: 510, Loss: 0.01055985875427723\n",
      "Epoch: 2, Batch: 511, Loss: 0.03901752457022667\n",
      "Epoch: 2, Batch: 512, Loss: 0.005850344896316528\n",
      "Epoch: 2, Batch: 513, Loss: 0.008348984643816948\n",
      "Epoch: 2, Batch: 514, Loss: 0.05950305983424187\n",
      "Epoch: 2, Batch: 515, Loss: 0.08652520179748535\n",
      "Epoch: 2, Batch: 516, Loss: 0.038668785244226456\n",
      "Epoch: 2, Batch: 517, Loss: 0.008750317618250847\n",
      "Epoch: 2, Batch: 518, Loss: 0.010364179499447346\n",
      "Epoch: 2, Batch: 519, Loss: 0.05680300295352936\n",
      "Epoch: 2, Batch: 520, Loss: 0.09122122079133987\n",
      "Epoch: 2, Batch: 521, Loss: 0.06155718117952347\n",
      "Epoch: 2, Batch: 522, Loss: 0.08570466190576553\n",
      "Epoch: 2, Batch: 523, Loss: 0.03390630707144737\n",
      "Epoch: 2, Batch: 524, Loss: 0.010921665467321873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch: 525, Loss: 0.08556470274925232\n",
      "Epoch: 2, Batch: 526, Loss: 0.09853392094373703\n",
      "Epoch: 2, Batch: 527, Loss: 0.02721298299729824\n",
      "Epoch: 2, Batch: 528, Loss: 0.1150427833199501\n",
      "Epoch: 2, Batch: 529, Loss: 0.024474583566188812\n",
      "Epoch: 2, Batch: 530, Loss: 0.09429270774126053\n",
      "Epoch: 2, Batch: 531, Loss: 0.00631303433328867\n",
      "Epoch: 2, Batch: 532, Loss: 0.18698778748512268\n",
      "Epoch: 2, Batch: 533, Loss: 0.044303957372903824\n",
      "Epoch: 2, Batch: 534, Loss: 0.066220223903656\n",
      "Epoch: 2, Batch: 535, Loss: 0.18647755682468414\n",
      "Epoch: 2, Batch: 536, Loss: 0.00654188496991992\n",
      "Epoch: 2, Batch: 537, Loss: 0.041289471089839935\n",
      "Epoch: 2, Batch: 538, Loss: 0.01597025990486145\n",
      "Epoch: 2, Batch: 539, Loss: 0.008422087877988815\n",
      "Epoch: 2, Batch: 540, Loss: 0.049718521535396576\n",
      "Epoch: 2, Batch: 541, Loss: 0.06619378179311752\n",
      "Epoch: 2, Batch: 542, Loss: 0.050980545580387115\n",
      "Epoch: 2, Batch: 543, Loss: 0.03892364725470543\n",
      "Epoch: 2, Batch: 544, Loss: 0.011025975458323956\n",
      "Epoch: 2, Batch: 545, Loss: 0.005751301068812609\n",
      "Epoch: 2, Batch: 546, Loss: 0.042293451726436615\n",
      "Epoch: 2, Batch: 547, Loss: 0.021151548251509666\n",
      "Epoch: 2, Batch: 548, Loss: 0.03117160126566887\n",
      "Epoch: 2, Batch: 549, Loss: 0.05927107855677605\n",
      "Epoch: 2, Batch: 550, Loss: 0.08854645490646362\n",
      "Epoch: 2, Batch: 551, Loss: 0.09584767371416092\n",
      "Epoch: 2, Batch: 552, Loss: 0.0034889911767095327\n",
      "Epoch: 2, Batch: 553, Loss: 0.04220111668109894\n",
      "Epoch: 2, Batch: 554, Loss: 0.015338891185820103\n",
      "Epoch: 2, Batch: 555, Loss: 0.10547269135713577\n",
      "Epoch: 2, Batch: 556, Loss: 0.06317935883998871\n",
      "Epoch: 2, Batch: 557, Loss: 0.0075362324714660645\n",
      "Epoch: 2, Batch: 558, Loss: 0.011350037530064583\n",
      "Epoch: 2, Batch: 559, Loss: 0.055644888430833817\n",
      "Epoch: 2, Batch: 560, Loss: 0.11488168686628342\n",
      "Epoch: 2, Batch: 561, Loss: 0.02468237653374672\n",
      "Epoch: 2, Batch: 562, Loss: 0.009831760078668594\n",
      "Epoch: 2, Batch: 563, Loss: 0.012890883721411228\n",
      "Epoch: 2, Batch: 564, Loss: 0.0030353569891303778\n",
      "Epoch: 2, Batch: 565, Loss: 0.049657322466373444\n",
      "Epoch: 2, Batch: 566, Loss: 0.009386413730680943\n",
      "Epoch: 2, Batch: 567, Loss: 0.031108001247048378\n",
      "Epoch: 2, Batch: 568, Loss: 0.09073159098625183\n",
      "Epoch: 2, Batch: 569, Loss: 0.023788725957274437\n",
      "Epoch: 2, Batch: 570, Loss: 0.011806819587945938\n",
      "Epoch: 2, Batch: 571, Loss: 0.005290386267006397\n",
      "Epoch: 2, Batch: 572, Loss: 0.01968870870769024\n",
      "Epoch: 2, Batch: 573, Loss: 0.031626250594854355\n",
      "Epoch: 2, Batch: 574, Loss: 0.032343748956918716\n",
      "Epoch: 2, Batch: 575, Loss: 0.028711991384625435\n",
      "Epoch: 2, Batch: 576, Loss: 0.10748421400785446\n",
      "Epoch: 2, Batch: 577, Loss: 0.089189812541008\n",
      "Epoch: 2, Batch: 578, Loss: 0.004951359238475561\n",
      "Epoch: 2, Batch: 579, Loss: 0.028976615518331528\n",
      "Epoch: 2, Batch: 580, Loss: 0.020102275535464287\n",
      "Epoch: 2, Batch: 581, Loss: 0.005529866553843021\n",
      "Epoch: 2, Batch: 582, Loss: 0.015134740620851517\n",
      "Epoch: 2, Batch: 583, Loss: 0.00424616876989603\n",
      "Epoch: 2, Batch: 584, Loss: 0.0063201612792909145\n",
      "Epoch: 2, Batch: 585, Loss: 0.02950776182115078\n",
      "Epoch: 2, Batch: 586, Loss: 0.07693016529083252\n",
      "Epoch: 2, Batch: 587, Loss: 0.06520815193653107\n",
      "Epoch: 2, Batch: 588, Loss: 0.019142644479870796\n",
      "Epoch: 2, Batch: 589, Loss: 0.09541729092597961\n",
      "Epoch: 2, Batch: 590, Loss: 0.013130742125213146\n",
      "Epoch: 2, Batch: 591, Loss: 0.05192181468009949\n",
      "Epoch: 2, Batch: 592, Loss: 0.04810358211398125\n",
      "Epoch: 2, Batch: 593, Loss: 0.003100906265899539\n",
      "Epoch: 2, Batch: 594, Loss: 0.034516096115112305\n",
      "Epoch: 2, Batch: 595, Loss: 0.004373022820800543\n",
      "Epoch: 2, Batch: 596, Loss: 0.009290667250752449\n",
      "Epoch: 2, Batch: 597, Loss: 0.060704901814460754\n",
      "Epoch: 2, Batch: 598, Loss: 0.0022368845529854298\n",
      "Epoch: 2, Batch: 599, Loss: 0.013182654976844788\n",
      "Epoch: 2, Batch: 600, Loss: 0.06873352825641632\n",
      "Epoch: 2, Batch: 601, Loss: 0.07206639647483826\n",
      "Epoch: 2, Batch: 602, Loss: 0.020382530987262726\n",
      "Epoch: 2, Batch: 603, Loss: 0.003927800804376602\n",
      "Epoch: 2, Batch: 604, Loss: 0.002382373670116067\n",
      "Epoch: 2, Batch: 605, Loss: 0.07572771608829498\n",
      "Epoch: 2, Batch: 606, Loss: 0.061387985944747925\n",
      "Epoch: 2, Batch: 607, Loss: 0.011192004196345806\n",
      "Epoch: 2, Batch: 608, Loss: 0.08577897399663925\n",
      "Epoch: 2, Batch: 609, Loss: 0.02755698561668396\n",
      "Epoch: 2, Batch: 610, Loss: 0.04904180392622948\n",
      "Epoch: 2, Batch: 611, Loss: 0.09925123304128647\n",
      "Epoch: 2, Batch: 612, Loss: 0.006477808579802513\n",
      "Epoch: 2, Batch: 613, Loss: 0.06573149561882019\n",
      "Epoch: 2, Batch: 614, Loss: 0.014176581986248493\n",
      "Epoch: 2, Batch: 615, Loss: 0.005228832364082336\n",
      "Epoch: 2, Batch: 616, Loss: 0.09088258445262909\n",
      "Epoch: 2, Batch: 617, Loss: 0.08080224692821503\n",
      "Epoch: 2, Batch: 618, Loss: 0.004065375309437513\n",
      "Epoch: 2, Batch: 619, Loss: 0.026869788765907288\n",
      "Epoch: 2, Batch: 620, Loss: 0.026657691225409508\n",
      "Epoch: 2, Batch: 621, Loss: 0.028013620525598526\n",
      "Epoch: 2, Batch: 622, Loss: 0.0023880910594016314\n",
      "Epoch: 2, Batch: 623, Loss: 0.023477349430322647\n",
      "Epoch: 2, Batch: 624, Loss: 0.05534258857369423\n",
      "Epoch: 2, Batch: 625, Loss: 0.11544506996870041\n",
      "Epoch: 2, Batch: 626, Loss: 0.031303245574235916\n",
      "Epoch: 2, Batch: 627, Loss: 0.05319754034280777\n",
      "Epoch: 2, Batch: 628, Loss: 0.03919395059347153\n",
      "Epoch: 2, Batch: 629, Loss: 0.004648188129067421\n",
      "Epoch: 2, Batch: 630, Loss: 0.01107705570757389\n",
      "Epoch: 2, Batch: 631, Loss: 0.016945527866482735\n",
      "Epoch: 2, Batch: 632, Loss: 0.006381336133927107\n",
      "Epoch: 2, Batch: 633, Loss: 0.017772704362869263\n",
      "Epoch: 2, Batch: 634, Loss: 0.009972188621759415\n",
      "Epoch: 2, Batch: 635, Loss: 0.11913758516311646\n",
      "Epoch: 2, Batch: 636, Loss: 0.07945846021175385\n",
      "Epoch: 2, Batch: 637, Loss: 0.00611486379057169\n",
      "Epoch: 2, Batch: 638, Loss: 0.01569976843893528\n",
      "Epoch: 2, Batch: 639, Loss: 0.12416666746139526\n",
      "Epoch: 2, Batch: 640, Loss: 0.04064086079597473\n",
      "Epoch: 2, Batch: 641, Loss: 0.009678643196821213\n",
      "Epoch: 2, Batch: 642, Loss: 0.008136861026287079\n",
      "Epoch: 2, Batch: 643, Loss: 0.003421780886128545\n",
      "Epoch: 2, Batch: 644, Loss: 0.010754288174211979\n",
      "Epoch: 2, Batch: 645, Loss: 0.001580872107297182\n",
      "Epoch: 2, Batch: 646, Loss: 0.1281721442937851\n",
      "Epoch: 2, Batch: 647, Loss: 0.04432472959160805\n",
      "Epoch: 2, Batch: 648, Loss: 0.005841796286404133\n",
      "Epoch: 2, Batch: 649, Loss: 0.10249493271112442\n",
      "Epoch: 2, Batch: 650, Loss: 0.016294226050376892\n",
      "Epoch: 2, Batch: 651, Loss: 0.003283647820353508\n",
      "Epoch: 2, Batch: 652, Loss: 0.03539896756410599\n",
      "Epoch: 2, Batch: 653, Loss: 0.0159883052110672\n",
      "Epoch: 2, Batch: 654, Loss: 0.10488967597484589\n",
      "Epoch: 2, Batch: 655, Loss: 0.006898198276758194\n",
      "Epoch: 2, Batch: 656, Loss: 0.03322886303067207\n",
      "Epoch: 2, Batch: 657, Loss: 0.002733563771471381\n",
      "Epoch: 2, Batch: 658, Loss: 0.06276271492242813\n",
      "Epoch: 2, Batch: 659, Loss: 0.006609800271689892\n",
      "Epoch: 2, Batch: 660, Loss: 0.03298354521393776\n",
      "Epoch: 2, Batch: 661, Loss: 0.005562703590840101\n",
      "Epoch: 2, Batch: 662, Loss: 0.011245743371546268\n",
      "Epoch: 2, Batch: 663, Loss: 0.04274962097406387\n",
      "Epoch: 2, Batch: 664, Loss: 0.03138856589794159\n",
      "Epoch: 2, Batch: 665, Loss: 0.011670759879052639\n",
      "Epoch: 2, Batch: 666, Loss: 0.027404092252254486\n",
      "Epoch: 2, Batch: 667, Loss: 0.07103962451219559\n",
      "Epoch: 2, Batch: 668, Loss: 0.02202761545777321\n",
      "Epoch: 2, Batch: 669, Loss: 0.038307998329401016\n",
      "Epoch: 2, Batch: 670, Loss: 0.10738568007946014\n",
      "Epoch: 2, Batch: 671, Loss: 0.01686674915254116\n",
      "Epoch: 2, Batch: 672, Loss: 0.03206043317914009\n",
      "Epoch: 2, Batch: 673, Loss: 0.11392570286989212\n",
      "Epoch: 2, Batch: 674, Loss: 0.023576848208904266\n",
      "Epoch: 2, Batch: 675, Loss: 0.003210885915905237\n",
      "Epoch: 2, Batch: 676, Loss: 0.001238204655237496\n",
      "Epoch: 2, Batch: 677, Loss: 0.07347135990858078\n",
      "Epoch: 2, Batch: 678, Loss: 0.025812864303588867\n",
      "Epoch: 2, Batch: 679, Loss: 0.024134885519742966\n",
      "Epoch: 2, Batch: 680, Loss: 0.05389499291777611\n",
      "Epoch: 2, Batch: 681, Loss: 0.03596976026892662\n",
      "Epoch: 2, Batch: 682, Loss: 0.08815093338489532\n",
      "Epoch: 2, Batch: 683, Loss: 0.08962040394544601\n",
      "Epoch: 2, Batch: 684, Loss: 0.08329438418149948\n",
      "Epoch: 2, Batch: 685, Loss: 0.006952469237148762\n",
      "Epoch: 2, Batch: 686, Loss: 0.10599318146705627\n",
      "Epoch: 2, Batch: 687, Loss: 0.0019843587651848793\n",
      "Epoch: 2, Batch: 688, Loss: 0.011081215925514698\n",
      "Epoch: 2, Batch: 689, Loss: 0.030172673985362053\n",
      "Epoch: 2, Batch: 690, Loss: 0.028471408411860466\n",
      "Epoch: 2, Batch: 691, Loss: 0.05062178522348404\n",
      "Epoch: 2, Batch: 692, Loss: 0.006355081684887409\n",
      "Epoch: 2, Batch: 693, Loss: 0.013334586285054684\n",
      "Epoch: 2, Batch: 694, Loss: 0.016689617186784744\n",
      "Epoch: 2, Batch: 695, Loss: 0.01980714127421379\n",
      "Epoch: 2, Batch: 696, Loss: 0.005220515187829733\n",
      "Epoch: 2, Batch: 697, Loss: 0.08435917645692825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch: 698, Loss: 0.00737308245152235\n",
      "Epoch: 2, Batch: 699, Loss: 0.016292216256260872\n",
      "Epoch: 2, Batch: 700, Loss: 0.047147370874881744\n",
      "Epoch: 2, Batch: 701, Loss: 0.010519384406507015\n",
      "Epoch: 2, Batch: 702, Loss: 0.04958280175924301\n",
      "Epoch: 2, Batch: 703, Loss: 0.0194108746945858\n",
      "Epoch: 2, Batch: 704, Loss: 0.01364857703447342\n",
      "Epoch: 2, Batch: 705, Loss: 0.09058386087417603\n",
      "Epoch: 2, Batch: 706, Loss: 0.13217699527740479\n",
      "Epoch: 2, Batch: 707, Loss: 0.039615828543901443\n",
      "Epoch: 2, Batch: 708, Loss: 0.03546028211712837\n",
      "Epoch: 2, Batch: 709, Loss: 0.025179428979754448\n",
      "Epoch: 2, Batch: 710, Loss: 0.10010193288326263\n",
      "Epoch: 2, Batch: 711, Loss: 0.004179139621555805\n",
      "Epoch: 2, Batch: 712, Loss: 0.0037376792170107365\n",
      "Epoch: 2, Batch: 713, Loss: 0.005865279585123062\n",
      "Epoch: 2, Batch: 714, Loss: 0.0210874080657959\n",
      "Epoch: 2, Batch: 715, Loss: 0.059571895748376846\n",
      "Epoch: 2, Batch: 716, Loss: 0.013739166781306267\n",
      "Epoch: 2, Batch: 717, Loss: 0.03891082853078842\n",
      "Epoch: 2, Batch: 718, Loss: 0.09798498451709747\n",
      "Epoch: 2, Batch: 719, Loss: 0.05858435109257698\n",
      "Epoch: 2, Batch: 720, Loss: 0.006255511660128832\n",
      "Epoch: 2, Batch: 721, Loss: 0.0020435478072613478\n",
      "Epoch: 2, Batch: 722, Loss: 0.10255853086709976\n",
      "Epoch: 2, Batch: 723, Loss: 0.014528443105518818\n",
      "Epoch: 2, Batch: 724, Loss: 0.008501310832798481\n",
      "Epoch: 2, Batch: 725, Loss: 0.050968725234270096\n",
      "Epoch: 2, Batch: 726, Loss: 0.0529525987803936\n",
      "Epoch: 2, Batch: 727, Loss: 0.1100248396396637\n",
      "Epoch: 2, Batch: 728, Loss: 0.022110534831881523\n",
      "Epoch: 2, Batch: 729, Loss: 0.005534359719604254\n",
      "Epoch: 2, Batch: 730, Loss: 0.021464236080646515\n",
      "Epoch: 2, Batch: 731, Loss: 0.11037616431713104\n",
      "Epoch: 2, Batch: 732, Loss: 0.016686879098415375\n",
      "Epoch: 2, Batch: 733, Loss: 0.06587348878383636\n",
      "Epoch: 2, Batch: 734, Loss: 0.047184791415929794\n",
      "Epoch: 2, Batch: 735, Loss: 0.018130039796233177\n",
      "Epoch: 2, Batch: 736, Loss: 0.17534688115119934\n",
      "Epoch: 2, Batch: 737, Loss: 0.02374422363936901\n",
      "Epoch: 2, Batch: 738, Loss: 0.003063086187466979\n",
      "Epoch: 2, Batch: 739, Loss: 0.046812549233436584\n",
      "Epoch: 2, Batch: 740, Loss: 0.007155092433094978\n",
      "Epoch: 2, Batch: 741, Loss: 0.009406652301549911\n",
      "Epoch: 2, Batch: 742, Loss: 0.0026934316847473383\n",
      "Epoch: 2, Batch: 743, Loss: 0.04092204198241234\n",
      "Epoch: 2, Batch: 744, Loss: 0.02385428361594677\n",
      "Epoch: 2, Batch: 745, Loss: 0.044690847396850586\n",
      "Epoch: 2, Batch: 746, Loss: 0.07119500637054443\n",
      "Epoch: 2, Batch: 747, Loss: 0.0028639589436352253\n",
      "Epoch: 2, Batch: 748, Loss: 0.02992246299982071\n",
      "Epoch: 2, Batch: 749, Loss: 0.01293458417057991\n",
      "Epoch: 2, Batch: 750, Loss: 0.020101895555853844\n",
      "Epoch: 2, Batch: 751, Loss: 0.1804332286119461\n",
      "Epoch: 2, Batch: 752, Loss: 0.0034104716032743454\n",
      "Epoch: 2, Batch: 753, Loss: 0.21238240599632263\n",
      "Epoch: 2, Batch: 754, Loss: 0.004142210818827152\n",
      "Epoch: 2, Batch: 755, Loss: 0.03163517639040947\n",
      "Epoch: 2, Batch: 756, Loss: 0.0386526919901371\n",
      "Epoch: 2, Batch: 757, Loss: 0.0281375665217638\n",
      "Epoch: 2, Batch: 758, Loss: 0.004104120656847954\n",
      "Epoch: 2, Batch: 759, Loss: 0.011896275915205479\n",
      "Epoch: 2, Batch: 760, Loss: 0.015924638137221336\n",
      "Epoch: 2, Batch: 761, Loss: 0.17395815253257751\n",
      "Epoch: 2, Batch: 762, Loss: 0.01077575795352459\n",
      "Epoch: 2, Batch: 763, Loss: 0.012045968323946\n",
      "Epoch: 2, Batch: 764, Loss: 0.007379494607448578\n",
      "Epoch: 2, Batch: 765, Loss: 0.009843705222010612\n",
      "Epoch: 2, Batch: 766, Loss: 0.02872447669506073\n",
      "Epoch: 2, Batch: 767, Loss: 0.10530578345060349\n",
      "Epoch: 2, Batch: 768, Loss: 0.004292341880500317\n",
      "Epoch: 2, Batch: 769, Loss: 0.12905851006507874\n",
      "Epoch: 2, Batch: 770, Loss: 0.008577662520110607\n",
      "Epoch: 2, Batch: 771, Loss: 0.16192638874053955\n",
      "Epoch: 2, Batch: 772, Loss: 0.018106471747159958\n",
      "Epoch: 2, Batch: 773, Loss: 0.18161383271217346\n",
      "Epoch: 2, Batch: 774, Loss: 0.06907153129577637\n",
      "Epoch: 2, Batch: 775, Loss: 0.016148965805768967\n",
      "Epoch: 2, Batch: 776, Loss: 0.01578659936785698\n",
      "Epoch: 2, Batch: 777, Loss: 0.01562417671084404\n",
      "Epoch: 2, Batch: 778, Loss: 0.019458098337054253\n",
      "Epoch: 2, Batch: 779, Loss: 0.0258196871727705\n",
      "Epoch: 2, Batch: 780, Loss: 0.09220286458730698\n",
      "Epoch: 2, Batch: 781, Loss: 0.044773731380701065\n",
      "Epoch: 2, Batch: 782, Loss: 0.0178550872951746\n",
      "Epoch: 2, Batch: 783, Loss: 0.05514432117342949\n",
      "Epoch: 2, Batch: 784, Loss: 0.01935582049190998\n",
      "Epoch: 2, Batch: 785, Loss: 0.016606776043772697\n",
      "Epoch: 2, Batch: 786, Loss: 0.11130999773740768\n",
      "Epoch: 2, Batch: 787, Loss: 0.0022854660637676716\n",
      "Epoch: 2, Batch: 788, Loss: 0.012520013377070427\n",
      "Epoch: 2, Batch: 789, Loss: 0.009404766373336315\n",
      "Epoch: 2, Batch: 790, Loss: 0.01840725727379322\n",
      "Epoch: 2, Batch: 791, Loss: 0.01879686303436756\n",
      "Epoch: 2, Batch: 792, Loss: 0.05534645542502403\n",
      "Epoch: 2, Batch: 793, Loss: 0.006097004748880863\n",
      "Epoch: 2, Batch: 794, Loss: 0.09534232318401337\n",
      "Epoch: 2, Batch: 795, Loss: 0.0195402093231678\n",
      "Epoch: 2, Batch: 796, Loss: 0.029438281431794167\n",
      "Epoch: 2, Batch: 797, Loss: 0.012812964618206024\n",
      "Epoch: 2, Batch: 798, Loss: 0.052330005913972855\n",
      "Epoch: 2, Batch: 799, Loss: 0.12440252304077148\n",
      "Epoch: 2, Batch: 800, Loss: 0.12046784907579422\n",
      "Epoch: 2, Batch: 801, Loss: 0.0417572483420372\n",
      "Epoch: 2, Batch: 802, Loss: 0.00422580074518919\n",
      "Epoch: 2, Batch: 803, Loss: 0.03872465714812279\n",
      "Epoch: 2, Batch: 804, Loss: 0.06096220389008522\n",
      "Epoch: 2, Batch: 805, Loss: 0.023819217458367348\n",
      "Epoch: 2, Batch: 806, Loss: 0.05783820152282715\n",
      "Epoch: 2, Batch: 807, Loss: 0.003637250978499651\n",
      "Epoch: 2, Batch: 808, Loss: 0.0019276485545560718\n",
      "Epoch: 2, Batch: 809, Loss: 0.0061293975450098515\n",
      "Epoch: 2, Batch: 810, Loss: 0.014100342988967896\n",
      "Epoch: 2, Batch: 811, Loss: 0.007942402735352516\n",
      "Epoch: 2, Batch: 812, Loss: 0.002095273230224848\n",
      "Epoch: 2, Batch: 813, Loss: 0.009672489948570728\n",
      "Epoch: 2, Batch: 814, Loss: 0.03282546624541283\n",
      "Epoch: 2, Batch: 815, Loss: 0.037825386971235275\n",
      "Epoch: 2, Batch: 816, Loss: 0.04989076405763626\n",
      "Epoch: 2, Batch: 817, Loss: 0.011842110194265842\n",
      "Epoch: 2, Batch: 818, Loss: 0.02487051673233509\n",
      "Epoch: 2, Batch: 819, Loss: 0.10647161304950714\n",
      "Epoch: 2, Batch: 820, Loss: 0.07556029409170151\n",
      "Epoch: 2, Batch: 821, Loss: 0.014035817235708237\n",
      "Epoch: 2, Batch: 822, Loss: 0.02143457531929016\n",
      "Epoch: 2, Batch: 823, Loss: 0.13306015729904175\n",
      "Epoch: 2, Batch: 824, Loss: 0.02331162989139557\n",
      "Epoch: 2, Batch: 825, Loss: 0.07557890564203262\n",
      "Epoch: 2, Batch: 826, Loss: 0.09225182980298996\n",
      "Epoch: 2, Batch: 827, Loss: 0.0033759220968931913\n",
      "Epoch: 2, Batch: 828, Loss: 0.01886727102100849\n",
      "Epoch: 2, Batch: 829, Loss: 0.08781135827302933\n",
      "Epoch: 2, Batch: 830, Loss: 0.029691793024539948\n",
      "Epoch: 2, Batch: 831, Loss: 0.027699606493115425\n",
      "Epoch: 2, Batch: 832, Loss: 0.001991914352402091\n",
      "Epoch: 2, Batch: 833, Loss: 0.010620605200529099\n",
      "Epoch: 2, Batch: 834, Loss: 0.0045126876793801785\n",
      "Epoch: 2, Batch: 835, Loss: 0.023290472105145454\n",
      "Epoch: 2, Batch: 836, Loss: 0.01720220223069191\n",
      "Epoch: 2, Batch: 837, Loss: 0.040579941123723984\n",
      "Epoch: 2, Batch: 838, Loss: 0.02843562513589859\n",
      "Epoch: 2, Batch: 839, Loss: 0.09940110892057419\n",
      "Epoch: 2, Batch: 840, Loss: 0.15187299251556396\n",
      "Epoch: 2, Batch: 841, Loss: 0.010037544183433056\n",
      "Epoch: 2, Batch: 842, Loss: 0.0019259126856923103\n",
      "Epoch: 2, Batch: 843, Loss: 0.03917597234249115\n",
      "Epoch: 2, Batch: 844, Loss: 0.09631791710853577\n",
      "Epoch: 2, Batch: 845, Loss: 0.07865991443395615\n",
      "Epoch: 2, Batch: 846, Loss: 0.009787865914404392\n",
      "Epoch: 2, Batch: 847, Loss: 0.07836024463176727\n",
      "Epoch: 2, Batch: 848, Loss: 0.02101081982254982\n",
      "Epoch: 2, Batch: 849, Loss: 0.049972157925367355\n",
      "Epoch: 2, Batch: 850, Loss: 0.028550175949931145\n",
      "Epoch: 2, Batch: 851, Loss: 0.01707630231976509\n",
      "Epoch: 2, Batch: 852, Loss: 0.004447925835847855\n",
      "Epoch: 2, Batch: 853, Loss: 0.018015721812844276\n",
      "Epoch: 2, Batch: 854, Loss: 0.007821209728717804\n",
      "Epoch: 2, Batch: 855, Loss: 0.015486206859350204\n",
      "Epoch: 2, Batch: 856, Loss: 0.002796499291434884\n",
      "Epoch: 2, Batch: 857, Loss: 0.021125132218003273\n",
      "Epoch: 2, Batch: 858, Loss: 0.07315074652433395\n",
      "Epoch: 2, Batch: 859, Loss: 0.02105371095240116\n",
      "Epoch: 2, Batch: 860, Loss: 0.04401777312159538\n",
      "Epoch: 2, Batch: 861, Loss: 0.011183904483914375\n",
      "Epoch: 2, Batch: 862, Loss: 0.04023224115371704\n",
      "Epoch: 2, Batch: 863, Loss: 0.07508246600627899\n",
      "Epoch: 2, Batch: 864, Loss: 0.00582960806787014\n",
      "Epoch: 2, Batch: 865, Loss: 0.024757158011198044\n",
      "Epoch: 2, Batch: 866, Loss: 0.042680058628320694\n",
      "Epoch: 2, Batch: 867, Loss: 0.06343043595552444\n",
      "Epoch: 2, Batch: 868, Loss: 0.00993568915873766\n",
      "Epoch: 2, Batch: 869, Loss: 0.02082369290292263\n",
      "Epoch: 2, Batch: 870, Loss: 0.01511425618082285\n",
      "Epoch: 2, Batch: 871, Loss: 0.04317371919751167\n",
      "Epoch: 2, Batch: 872, Loss: 0.0019506142707541585\n",
      "Epoch: 2, Batch: 873, Loss: 0.14735765755176544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Batch: 874, Loss: 0.023960929363965988\n",
      "Epoch: 2, Batch: 875, Loss: 0.0485948845744133\n",
      "Epoch: 2, Batch: 876, Loss: 0.004123937338590622\n",
      "Epoch: 2, Batch: 877, Loss: 0.003870892571285367\n",
      "Epoch: 2, Batch: 878, Loss: 0.0013311553047969937\n",
      "Epoch: 2, Batch: 879, Loss: 0.01644761487841606\n",
      "Epoch: 2, Batch: 880, Loss: 0.0028637584764510393\n",
      "Epoch: 2, Batch: 881, Loss: 0.16050583124160767\n",
      "Epoch: 2, Batch: 882, Loss: 0.024195756763219833\n",
      "Epoch: 2, Batch: 883, Loss: 0.020096812397241592\n",
      "Epoch: 2, Batch: 884, Loss: 0.0178173016756773\n",
      "Epoch: 2, Batch: 885, Loss: 0.027377525344491005\n",
      "Epoch: 2, Batch: 886, Loss: 0.03732311353087425\n",
      "Epoch: 2, Batch: 887, Loss: 0.11713367700576782\n",
      "Epoch: 2, Batch: 888, Loss: 0.0070761991664767265\n",
      "Epoch: 2, Batch: 889, Loss: 0.029599258676171303\n",
      "Epoch: 2, Batch: 890, Loss: 0.022738302126526833\n",
      "Epoch: 2, Batch: 891, Loss: 0.014998242259025574\n",
      "Epoch: 2, Batch: 892, Loss: 0.010770161636173725\n",
      "Epoch: 2, Batch: 893, Loss: 0.011480498127639294\n",
      "Epoch: 2, Batch: 894, Loss: 0.1157756820321083\n",
      "Epoch: 2, Batch: 895, Loss: 0.10263419896364212\n",
      "Epoch: 2, Batch: 896, Loss: 0.04269687458872795\n",
      "Epoch: 2, Batch: 897, Loss: 0.01653028465807438\n",
      "Epoch: 2, Batch: 898, Loss: 0.004553088918328285\n",
      "Epoch: 2, Batch: 899, Loss: 0.32772356271743774\n",
      "Epoch: 2, Batch: 900, Loss: 0.14431747794151306\n",
      "Epoch: 2, Batch: 901, Loss: 0.024056436493992805\n",
      "Epoch: 2, Batch: 902, Loss: 0.03881286457180977\n",
      "Epoch: 2, Batch: 903, Loss: 0.02476421557366848\n",
      "Epoch: 2, Batch: 904, Loss: 0.020364675670862198\n",
      "Epoch: 2, Batch: 905, Loss: 0.05567959323525429\n",
      "Epoch: 2, Batch: 906, Loss: 0.02742554247379303\n",
      "Epoch: 2, Batch: 907, Loss: 0.053531464189291\n",
      "Epoch: 2, Batch: 908, Loss: 0.1231020838022232\n",
      "Epoch: 2, Batch: 909, Loss: 0.018380818888545036\n",
      "Epoch: 2, Batch: 910, Loss: 0.0595381073653698\n",
      "Epoch: 2, Batch: 911, Loss: 0.0026437013875693083\n",
      "Epoch: 2, Batch: 912, Loss: 0.02205680124461651\n",
      "Epoch: 2, Batch: 913, Loss: 0.03673429787158966\n",
      "Epoch: 2, Batch: 914, Loss: 0.07431909441947937\n",
      "Epoch: 2, Batch: 915, Loss: 0.010200896300375462\n",
      "Epoch: 2, Batch: 916, Loss: 0.04147367179393768\n",
      "Epoch: 2, Batch: 917, Loss: 0.0025511884596198797\n",
      "Epoch: 2, Batch: 918, Loss: 0.04611726850271225\n",
      "Epoch: 2, Batch: 919, Loss: 0.02279338613152504\n",
      "Epoch: 2, Batch: 920, Loss: 0.010542457923293114\n",
      "Epoch: 2, Batch: 921, Loss: 0.024436740204691887\n",
      "Epoch: 2, Batch: 922, Loss: 0.1550265997648239\n",
      "Epoch: 2, Batch: 923, Loss: 0.037032775580883026\n",
      "Epoch: 2, Batch: 924, Loss: 0.10322578996419907\n",
      "Epoch: 2, Batch: 925, Loss: 0.0036322553642094135\n",
      "Epoch: 2, Batch: 926, Loss: 0.014201618731021881\n",
      "Epoch: 2, Batch: 927, Loss: 0.02938876301050186\n",
      "Epoch: 2, Batch: 928, Loss: 0.11408955603837967\n",
      "Epoch: 2, Batch: 929, Loss: 0.11521793156862259\n",
      "Epoch: 2, Batch: 930, Loss: 0.0068317316472530365\n",
      "Epoch: 2, Batch: 931, Loss: 0.0748092383146286\n",
      "Epoch: 2, Batch: 932, Loss: 0.007262454833835363\n",
      "Epoch: 2, Batch: 933, Loss: 0.01617104560136795\n",
      "Epoch: 2, Batch: 934, Loss: 0.05947351083159447\n",
      "Epoch: 2, Batch: 935, Loss: 0.014308998361229897\n",
      "Epoch: 2, Batch: 936, Loss: 0.015286114066839218\n",
      "Epoch: 2, Batch: 937, Loss: 0.009831980802118778\n",
      "Epoch: 3, Batch: 0, Loss: 0.08490095287561417\n",
      "Epoch: 3, Batch: 1, Loss: 0.007269208785146475\n",
      "Epoch: 3, Batch: 2, Loss: 0.02684210054576397\n",
      "Epoch: 3, Batch: 3, Loss: 0.061436787247657776\n",
      "Epoch: 3, Batch: 4, Loss: 0.16306640207767487\n",
      "Epoch: 3, Batch: 5, Loss: 0.034799106419086456\n",
      "Epoch: 3, Batch: 6, Loss: 0.012027311138808727\n",
      "Epoch: 3, Batch: 7, Loss: 0.010500837117433548\n",
      "Epoch: 3, Batch: 8, Loss: 0.06595153361558914\n",
      "Epoch: 3, Batch: 9, Loss: 0.02188846655189991\n",
      "Epoch: 3, Batch: 10, Loss: 0.010182509198784828\n",
      "Epoch: 3, Batch: 11, Loss: 0.01646300218999386\n",
      "Epoch: 3, Batch: 12, Loss: 0.02747602015733719\n",
      "Epoch: 3, Batch: 13, Loss: 0.009905602782964706\n",
      "Epoch: 3, Batch: 14, Loss: 0.04993694648146629\n",
      "Epoch: 3, Batch: 15, Loss: 0.010611440986394882\n",
      "Epoch: 3, Batch: 16, Loss: 0.04809590429067612\n",
      "Epoch: 3, Batch: 17, Loss: 0.024136602878570557\n",
      "Epoch: 3, Batch: 18, Loss: 0.1326049566268921\n",
      "Epoch: 3, Batch: 19, Loss: 0.03734922781586647\n",
      "Epoch: 3, Batch: 20, Loss: 0.026193680241703987\n",
      "Epoch: 3, Batch: 21, Loss: 0.005448712036013603\n",
      "Epoch: 3, Batch: 22, Loss: 0.014958903193473816\n",
      "Epoch: 3, Batch: 23, Loss: 0.019660258665680885\n",
      "Epoch: 3, Batch: 24, Loss: 0.016459563747048378\n",
      "Epoch: 3, Batch: 25, Loss: 0.005498708691447973\n",
      "Epoch: 3, Batch: 26, Loss: 0.05189560726284981\n",
      "Epoch: 3, Batch: 27, Loss: 0.011171415448188782\n",
      "Epoch: 3, Batch: 28, Loss: 0.01814567856490612\n",
      "Epoch: 3, Batch: 29, Loss: 0.007571753580123186\n",
      "Epoch: 3, Batch: 30, Loss: 0.005494819022715092\n",
      "Epoch: 3, Batch: 31, Loss: 0.017233753576874733\n",
      "Epoch: 3, Batch: 32, Loss: 0.06596150249242783\n",
      "Epoch: 3, Batch: 33, Loss: 0.12489863485097885\n",
      "Epoch: 3, Batch: 34, Loss: 0.01633566804230213\n",
      "Epoch: 3, Batch: 35, Loss: 0.04506528750061989\n",
      "Epoch: 3, Batch: 36, Loss: 0.03444850817322731\n",
      "Epoch: 3, Batch: 37, Loss: 0.10901833325624466\n",
      "Epoch: 3, Batch: 38, Loss: 0.0015082720201462507\n",
      "Epoch: 3, Batch: 39, Loss: 0.02257792465388775\n",
      "Epoch: 3, Batch: 40, Loss: 0.01875465363264084\n",
      "Epoch: 3, Batch: 41, Loss: 0.03567337244749069\n",
      "Epoch: 3, Batch: 42, Loss: 0.03220970183610916\n",
      "Epoch: 3, Batch: 43, Loss: 0.0007572757313027978\n",
      "Epoch: 3, Batch: 44, Loss: 0.04580753669142723\n",
      "Epoch: 3, Batch: 45, Loss: 0.03712467476725578\n",
      "Epoch: 3, Batch: 46, Loss: 0.030965857207775116\n",
      "Epoch: 3, Batch: 47, Loss: 0.009624752216041088\n",
      "Epoch: 3, Batch: 48, Loss: 0.05360348895192146\n",
      "Epoch: 3, Batch: 49, Loss: 0.021111229434609413\n",
      "Epoch: 3, Batch: 50, Loss: 0.018369438126683235\n",
      "Epoch: 3, Batch: 51, Loss: 0.005553009919822216\n",
      "Epoch: 3, Batch: 52, Loss: 0.008002207614481449\n",
      "Epoch: 3, Batch: 53, Loss: 0.0020289465319365263\n",
      "Epoch: 3, Batch: 54, Loss: 0.0012436631368473172\n",
      "Epoch: 3, Batch: 55, Loss: 0.009973251260817051\n",
      "Epoch: 3, Batch: 56, Loss: 0.011690860614180565\n",
      "Epoch: 3, Batch: 57, Loss: 0.006109722889959812\n",
      "Epoch: 3, Batch: 58, Loss: 0.01391670759767294\n",
      "Epoch: 3, Batch: 59, Loss: 0.02663409523665905\n",
      "Epoch: 3, Batch: 60, Loss: 0.022821545600891113\n",
      "Epoch: 3, Batch: 61, Loss: 0.0020227963104844093\n",
      "Epoch: 3, Batch: 62, Loss: 0.018986262381076813\n",
      "Epoch: 3, Batch: 63, Loss: 0.029946252703666687\n",
      "Epoch: 3, Batch: 64, Loss: 0.006070705130696297\n",
      "Epoch: 3, Batch: 65, Loss: 0.00048752990551292896\n",
      "Epoch: 3, Batch: 66, Loss: 0.002428010106086731\n",
      "Epoch: 3, Batch: 67, Loss: 0.0068433755077421665\n",
      "Epoch: 3, Batch: 68, Loss: 0.00731685571372509\n",
      "Epoch: 3, Batch: 69, Loss: 0.01279864739626646\n",
      "Epoch: 3, Batch: 70, Loss: 0.007906001061201096\n",
      "Epoch: 3, Batch: 71, Loss: 0.012511743232607841\n",
      "Epoch: 3, Batch: 72, Loss: 0.007065589539706707\n",
      "Epoch: 3, Batch: 73, Loss: 0.007943859323859215\n",
      "Epoch: 3, Batch: 74, Loss: 0.029683176428079605\n",
      "Epoch: 3, Batch: 75, Loss: 0.02732071280479431\n",
      "Epoch: 3, Batch: 76, Loss: 0.06166798993945122\n",
      "Epoch: 3, Batch: 77, Loss: 0.008085845038294792\n",
      "Epoch: 3, Batch: 78, Loss: 0.0026001909282058477\n",
      "Epoch: 3, Batch: 79, Loss: 0.0033666363451629877\n",
      "Epoch: 3, Batch: 80, Loss: 0.006703159771859646\n",
      "Epoch: 3, Batch: 81, Loss: 0.006370948161929846\n",
      "Epoch: 3, Batch: 82, Loss: 0.005849433597177267\n",
      "Epoch: 3, Batch: 83, Loss: 0.02757362648844719\n",
      "Epoch: 3, Batch: 84, Loss: 0.004838618915528059\n",
      "Epoch: 3, Batch: 85, Loss: 0.06535009294748306\n",
      "Epoch: 3, Batch: 86, Loss: 0.004659351427108049\n",
      "Epoch: 3, Batch: 87, Loss: 0.007201224099844694\n",
      "Epoch: 3, Batch: 88, Loss: 0.031575508415699005\n",
      "Epoch: 3, Batch: 89, Loss: 0.005838420707732439\n",
      "Epoch: 3, Batch: 90, Loss: 0.000908098416402936\n",
      "Epoch: 3, Batch: 91, Loss: 0.0018368916353210807\n",
      "Epoch: 3, Batch: 92, Loss: 0.013687076978385448\n",
      "Epoch: 3, Batch: 93, Loss: 0.05595330521464348\n",
      "Epoch: 3, Batch: 94, Loss: 0.005527572240680456\n",
      "Epoch: 3, Batch: 95, Loss: 0.0020643831230700016\n",
      "Epoch: 3, Batch: 96, Loss: 0.01774882711470127\n",
      "Epoch: 3, Batch: 97, Loss: 0.002502577845007181\n",
      "Epoch: 3, Batch: 98, Loss: 0.00241607497446239\n",
      "Epoch: 3, Batch: 99, Loss: 0.003980566281825304\n",
      "Epoch: 3, Batch: 100, Loss: 0.008607747964560986\n",
      "Epoch: 3, Batch: 101, Loss: 0.02561849169433117\n",
      "Epoch: 3, Batch: 102, Loss: 0.015017736703157425\n",
      "Epoch: 3, Batch: 103, Loss: 0.00041901407530531287\n",
      "Epoch: 3, Batch: 104, Loss: 0.08225474506616592\n",
      "Epoch: 3, Batch: 105, Loss: 0.04118036851286888\n",
      "Epoch: 3, Batch: 106, Loss: 0.011868695728480816\n",
      "Epoch: 3, Batch: 107, Loss: 0.07492709159851074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Batch: 108, Loss: 0.002281079301610589\n",
      "Epoch: 3, Batch: 109, Loss: 0.0002620822924654931\n",
      "Epoch: 3, Batch: 110, Loss: 0.007775641046464443\n",
      "Epoch: 3, Batch: 111, Loss: 0.012689348310232162\n",
      "Epoch: 3, Batch: 112, Loss: 0.016125984489917755\n",
      "Epoch: 3, Batch: 113, Loss: 0.0021300858352333307\n",
      "Epoch: 3, Batch: 114, Loss: 0.01038945559412241\n",
      "Epoch: 3, Batch: 115, Loss: 0.04656572639942169\n",
      "Epoch: 3, Batch: 116, Loss: 0.04561566561460495\n",
      "Epoch: 3, Batch: 117, Loss: 0.00296274246647954\n",
      "Epoch: 3, Batch: 118, Loss: 0.010790782049298286\n",
      "Epoch: 3, Batch: 119, Loss: 0.0026274463161826134\n",
      "Epoch: 3, Batch: 120, Loss: 0.022234458476305008\n",
      "Epoch: 3, Batch: 121, Loss: 0.06026298180222511\n",
      "Epoch: 3, Batch: 122, Loss: 0.0025667010340839624\n",
      "Epoch: 3, Batch: 123, Loss: 0.05629633739590645\n",
      "Epoch: 3, Batch: 124, Loss: 0.08389479666948318\n",
      "Epoch: 3, Batch: 125, Loss: 0.01376393809914589\n",
      "Epoch: 3, Batch: 126, Loss: 0.004558974411338568\n",
      "Epoch: 3, Batch: 127, Loss: 0.030319320037961006\n",
      "Epoch: 3, Batch: 128, Loss: 0.0023817848414182663\n",
      "Epoch: 3, Batch: 129, Loss: 0.001024578232318163\n",
      "Epoch: 3, Batch: 130, Loss: 0.004101430997252464\n",
      "Epoch: 3, Batch: 131, Loss: 0.0052306209690868855\n",
      "Epoch: 3, Batch: 132, Loss: 0.06056863069534302\n",
      "Epoch: 3, Batch: 133, Loss: 0.060013897716999054\n",
      "Epoch: 3, Batch: 134, Loss: 0.17305943369865417\n",
      "Epoch: 3, Batch: 135, Loss: 0.002956611104309559\n",
      "Epoch: 3, Batch: 136, Loss: 0.025328340008854866\n",
      "Epoch: 3, Batch: 137, Loss: 0.0013836064608767629\n",
      "Epoch: 3, Batch: 138, Loss: 0.016027383506298065\n",
      "Epoch: 3, Batch: 139, Loss: 0.0072234696708619595\n",
      "Epoch: 3, Batch: 140, Loss: 0.006753150839358568\n",
      "Epoch: 3, Batch: 141, Loss: 0.012031948193907738\n",
      "Epoch: 3, Batch: 142, Loss: 0.06448862701654434\n",
      "Epoch: 3, Batch: 143, Loss: 0.032055024057626724\n",
      "Epoch: 3, Batch: 144, Loss: 0.006585448049008846\n",
      "Epoch: 3, Batch: 145, Loss: 0.005517325829714537\n",
      "Epoch: 3, Batch: 146, Loss: 0.001263639540411532\n",
      "Epoch: 3, Batch: 147, Loss: 0.061312485486269\n",
      "Epoch: 3, Batch: 148, Loss: 0.02585661970078945\n",
      "Epoch: 3, Batch: 149, Loss: 0.04725759103894234\n",
      "Epoch: 3, Batch: 150, Loss: 0.09695705771446228\n",
      "Epoch: 3, Batch: 151, Loss: 0.0016198536613956094\n",
      "Epoch: 3, Batch: 152, Loss: 0.08246344327926636\n",
      "Epoch: 3, Batch: 153, Loss: 0.035848863422870636\n",
      "Epoch: 3, Batch: 154, Loss: 0.011518362909555435\n",
      "Epoch: 3, Batch: 155, Loss: 0.20998816192150116\n",
      "Epoch: 3, Batch: 156, Loss: 0.01374340895563364\n",
      "Epoch: 3, Batch: 157, Loss: 0.022098485380411148\n",
      "Epoch: 3, Batch: 158, Loss: 0.0019078250043094158\n",
      "Epoch: 3, Batch: 159, Loss: 0.02647182159125805\n",
      "Epoch: 3, Batch: 160, Loss: 0.026557765901088715\n",
      "Epoch: 3, Batch: 161, Loss: 0.0016613162588328123\n",
      "Epoch: 3, Batch: 162, Loss: 0.004257652908563614\n",
      "Epoch: 3, Batch: 163, Loss: 0.019922222942113876\n",
      "Epoch: 3, Batch: 164, Loss: 0.03239905834197998\n",
      "Epoch: 3, Batch: 165, Loss: 0.020419452339410782\n",
      "Epoch: 3, Batch: 166, Loss: 0.0033820054959505796\n",
      "Epoch: 3, Batch: 167, Loss: 0.0028520249761641026\n",
      "Epoch: 3, Batch: 168, Loss: 0.010007906705141068\n",
      "Epoch: 3, Batch: 169, Loss: 0.023031724616885185\n",
      "Epoch: 3, Batch: 170, Loss: 0.004156049806624651\n",
      "Epoch: 3, Batch: 171, Loss: 0.07327232509851456\n",
      "Epoch: 3, Batch: 172, Loss: 0.046976882964372635\n",
      "Epoch: 3, Batch: 173, Loss: 0.004978060256689787\n",
      "Epoch: 3, Batch: 174, Loss: 0.08067832142114639\n",
      "Epoch: 3, Batch: 175, Loss: 0.029289428144693375\n",
      "Epoch: 3, Batch: 176, Loss: 0.002771181520074606\n",
      "Epoch: 3, Batch: 177, Loss: 0.01948159746825695\n",
      "Epoch: 3, Batch: 178, Loss: 0.0666343942284584\n",
      "Epoch: 3, Batch: 179, Loss: 0.015160811133682728\n",
      "Epoch: 3, Batch: 180, Loss: 0.004320474341511726\n",
      "Epoch: 3, Batch: 181, Loss: 0.003665260737761855\n",
      "Epoch: 3, Batch: 182, Loss: 0.020927544683218002\n",
      "Epoch: 3, Batch: 183, Loss: 0.011910892091691494\n",
      "Epoch: 3, Batch: 184, Loss: 0.009897757321596146\n",
      "Epoch: 3, Batch: 185, Loss: 0.031785737723112106\n",
      "Epoch: 3, Batch: 186, Loss: 0.057587817311286926\n",
      "Epoch: 3, Batch: 187, Loss: 0.008398514240980148\n",
      "Epoch: 3, Batch: 188, Loss: 0.06655767560005188\n",
      "Epoch: 3, Batch: 189, Loss: 0.008312166668474674\n",
      "Epoch: 3, Batch: 190, Loss: 0.04730668291449547\n",
      "Epoch: 3, Batch: 191, Loss: 0.05033034086227417\n",
      "Epoch: 3, Batch: 192, Loss: 0.03850124031305313\n",
      "Epoch: 3, Batch: 193, Loss: 0.06831148266792297\n",
      "Epoch: 3, Batch: 194, Loss: 0.03979191929101944\n",
      "Epoch: 3, Batch: 195, Loss: 0.010035259649157524\n",
      "Epoch: 3, Batch: 196, Loss: 0.004638242535293102\n",
      "Epoch: 3, Batch: 197, Loss: 0.06445952504873276\n",
      "Epoch: 3, Batch: 198, Loss: 0.004976785276085138\n",
      "Epoch: 3, Batch: 199, Loss: 0.011404302902519703\n",
      "Epoch: 3, Batch: 200, Loss: 0.02602141723036766\n",
      "Epoch: 3, Batch: 201, Loss: 0.06839433312416077\n",
      "Epoch: 3, Batch: 202, Loss: 0.0026802867650985718\n",
      "Epoch: 3, Batch: 203, Loss: 0.018082506954669952\n",
      "Epoch: 3, Batch: 204, Loss: 0.004448571242392063\n",
      "Epoch: 3, Batch: 205, Loss: 0.024296902120113373\n",
      "Epoch: 3, Batch: 206, Loss: 0.050407782196998596\n",
      "Epoch: 3, Batch: 207, Loss: 0.009069221094250679\n",
      "Epoch: 3, Batch: 208, Loss: 0.05081450194120407\n",
      "Epoch: 3, Batch: 209, Loss: 0.006594293285161257\n",
      "Epoch: 3, Batch: 210, Loss: 0.18533560633659363\n",
      "Epoch: 3, Batch: 211, Loss: 0.003221123246476054\n",
      "Epoch: 3, Batch: 212, Loss: 0.006811187602579594\n",
      "Epoch: 3, Batch: 213, Loss: 0.025462334975600243\n",
      "Epoch: 3, Batch: 214, Loss: 0.02653595805168152\n",
      "Epoch: 3, Batch: 215, Loss: 0.0070500448346138\n",
      "Epoch: 3, Batch: 216, Loss: 0.007039888296276331\n",
      "Epoch: 3, Batch: 217, Loss: 0.023372283205389977\n",
      "Epoch: 3, Batch: 218, Loss: 0.009202041663229465\n",
      "Epoch: 3, Batch: 219, Loss: 0.04773639142513275\n",
      "Epoch: 3, Batch: 220, Loss: 0.07794726639986038\n",
      "Epoch: 3, Batch: 221, Loss: 0.09111012518405914\n",
      "Epoch: 3, Batch: 222, Loss: 0.09224378317594528\n",
      "Epoch: 3, Batch: 223, Loss: 0.015710124745965004\n",
      "Epoch: 3, Batch: 224, Loss: 0.01704702526330948\n",
      "Epoch: 3, Batch: 225, Loss: 0.04054698348045349\n",
      "Epoch: 3, Batch: 226, Loss: 0.0019586600828915834\n",
      "Epoch: 3, Batch: 227, Loss: 0.038969919085502625\n",
      "Epoch: 3, Batch: 228, Loss: 0.011751745827496052\n",
      "Epoch: 3, Batch: 229, Loss: 0.014227339066565037\n",
      "Epoch: 3, Batch: 230, Loss: 0.007680011913180351\n",
      "Epoch: 3, Batch: 231, Loss: 0.2070402354001999\n",
      "Epoch: 3, Batch: 232, Loss: 0.003578844713047147\n",
      "Epoch: 3, Batch: 233, Loss: 0.015137461945414543\n",
      "Epoch: 3, Batch: 234, Loss: 0.023690614849328995\n",
      "Epoch: 3, Batch: 235, Loss: 0.005493295378983021\n",
      "Epoch: 3, Batch: 236, Loss: 0.0012859324924647808\n",
      "Epoch: 3, Batch: 237, Loss: 0.0018114256672561169\n",
      "Epoch: 3, Batch: 238, Loss: 0.05142425745725632\n",
      "Epoch: 3, Batch: 239, Loss: 0.014705470763146877\n",
      "Epoch: 3, Batch: 240, Loss: 0.05278836563229561\n",
      "Epoch: 3, Batch: 241, Loss: 0.023969830945134163\n",
      "Epoch: 3, Batch: 242, Loss: 0.026021473109722137\n",
      "Epoch: 3, Batch: 243, Loss: 0.01097471360117197\n",
      "Epoch: 3, Batch: 244, Loss: 0.007082614582031965\n",
      "Epoch: 3, Batch: 245, Loss: 0.006851771380752325\n",
      "Epoch: 3, Batch: 246, Loss: 0.03337064012885094\n",
      "Epoch: 3, Batch: 247, Loss: 0.002015627920627594\n",
      "Epoch: 3, Batch: 248, Loss: 0.05928903445601463\n",
      "Epoch: 3, Batch: 249, Loss: 0.024658391252160072\n",
      "Epoch: 3, Batch: 250, Loss: 0.007447872776538134\n",
      "Epoch: 3, Batch: 251, Loss: 0.07102106511592865\n",
      "Epoch: 3, Batch: 252, Loss: 0.023516494780778885\n",
      "Epoch: 3, Batch: 253, Loss: 0.013949359767138958\n",
      "Epoch: 3, Batch: 254, Loss: 0.0084255151450634\n",
      "Epoch: 3, Batch: 255, Loss: 0.020704181864857674\n",
      "Epoch: 3, Batch: 256, Loss: 0.00676657073199749\n",
      "Epoch: 3, Batch: 257, Loss: 0.006302744150161743\n",
      "Epoch: 3, Batch: 258, Loss: 0.012448984198272228\n",
      "Epoch: 3, Batch: 259, Loss: 0.11655157059431076\n",
      "Epoch: 3, Batch: 260, Loss: 0.006965247448533773\n",
      "Epoch: 3, Batch: 261, Loss: 0.002035489771515131\n",
      "Epoch: 3, Batch: 262, Loss: 0.02205568365752697\n",
      "Epoch: 3, Batch: 263, Loss: 0.03462516516447067\n",
      "Epoch: 3, Batch: 264, Loss: 0.024772988632321358\n",
      "Epoch: 3, Batch: 265, Loss: 0.01768048107624054\n",
      "Epoch: 3, Batch: 266, Loss: 0.01165011152625084\n",
      "Epoch: 3, Batch: 267, Loss: 0.02203533425927162\n",
      "Epoch: 3, Batch: 268, Loss: 0.018181713297963142\n",
      "Epoch: 3, Batch: 269, Loss: 0.1011042594909668\n",
      "Epoch: 3, Batch: 270, Loss: 0.037404607981443405\n",
      "Epoch: 3, Batch: 271, Loss: 0.003215913427993655\n",
      "Epoch: 3, Batch: 272, Loss: 0.018969977274537086\n",
      "Epoch: 3, Batch: 273, Loss: 0.006871486082673073\n",
      "Epoch: 3, Batch: 274, Loss: 0.018932566046714783\n",
      "Epoch: 3, Batch: 275, Loss: 0.04491265490651131\n",
      "Epoch: 3, Batch: 276, Loss: 0.07495513558387756\n",
      "Epoch: 3, Batch: 277, Loss: 0.007043169811367989\n",
      "Epoch: 3, Batch: 278, Loss: 0.03183683380484581\n",
      "Epoch: 3, Batch: 279, Loss: 0.1551816463470459\n",
      "Epoch: 3, Batch: 280, Loss: 0.01628854125738144\n",
      "Epoch: 3, Batch: 281, Loss: 0.03663456439971924\n",
      "Epoch: 3, Batch: 282, Loss: 0.0631086528301239\n",
      "Epoch: 3, Batch: 283, Loss: 0.02387646585702896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Batch: 284, Loss: 0.004442324861884117\n",
      "Epoch: 3, Batch: 285, Loss: 0.0037822043523192406\n",
      "Epoch: 3, Batch: 286, Loss: 0.05832745134830475\n",
      "Epoch: 3, Batch: 287, Loss: 0.07849469035863876\n",
      "Epoch: 3, Batch: 288, Loss: 0.005183683708310127\n",
      "Epoch: 3, Batch: 289, Loss: 0.0019461414776742458\n",
      "Epoch: 3, Batch: 290, Loss: 0.006828796584159136\n",
      "Epoch: 3, Batch: 291, Loss: 0.0024345708079636097\n",
      "Epoch: 3, Batch: 292, Loss: 0.0833270400762558\n",
      "Epoch: 3, Batch: 293, Loss: 0.029842255637049675\n",
      "Epoch: 3, Batch: 294, Loss: 0.014126467518508434\n",
      "Epoch: 3, Batch: 295, Loss: 0.010687320493161678\n",
      "Epoch: 3, Batch: 296, Loss: 0.008142786100506783\n",
      "Epoch: 3, Batch: 297, Loss: 0.09274895489215851\n",
      "Epoch: 3, Batch: 298, Loss: 0.00511580053716898\n",
      "Epoch: 3, Batch: 299, Loss: 0.029945921152830124\n",
      "Epoch: 3, Batch: 300, Loss: 0.010843775235116482\n",
      "Epoch: 3, Batch: 301, Loss: 0.07603094726800919\n",
      "Epoch: 3, Batch: 302, Loss: 0.01027126144617796\n",
      "Epoch: 3, Batch: 303, Loss: 0.04939143359661102\n",
      "Epoch: 3, Batch: 304, Loss: 0.0016026641242206097\n",
      "Epoch: 3, Batch: 305, Loss: 0.0619548037648201\n",
      "Epoch: 3, Batch: 306, Loss: 0.0037409511860460043\n",
      "Epoch: 3, Batch: 307, Loss: 0.010567559860646725\n",
      "Epoch: 3, Batch: 308, Loss: 0.045971598476171494\n",
      "Epoch: 3, Batch: 309, Loss: 0.02393379993736744\n",
      "Epoch: 3, Batch: 310, Loss: 0.10124560445547104\n",
      "Epoch: 3, Batch: 311, Loss: 0.01250306237488985\n",
      "Epoch: 3, Batch: 312, Loss: 0.008504778146743774\n",
      "Epoch: 3, Batch: 313, Loss: 0.08567415922880173\n",
      "Epoch: 3, Batch: 314, Loss: 0.0140859205275774\n",
      "Epoch: 3, Batch: 315, Loss: 0.004388060420751572\n",
      "Epoch: 3, Batch: 316, Loss: 0.005246606655418873\n",
      "Epoch: 3, Batch: 317, Loss: 0.013535147532820702\n",
      "Epoch: 3, Batch: 318, Loss: 0.08858369290828705\n",
      "Epoch: 3, Batch: 319, Loss: 0.04261288046836853\n",
      "Epoch: 3, Batch: 320, Loss: 0.02234884724020958\n",
      "Epoch: 3, Batch: 321, Loss: 0.013513538055121899\n",
      "Epoch: 3, Batch: 322, Loss: 0.05132118985056877\n",
      "Epoch: 3, Batch: 323, Loss: 0.012602289207279682\n",
      "Epoch: 3, Batch: 324, Loss: 0.06423625349998474\n",
      "Epoch: 3, Batch: 325, Loss: 0.010058658197522163\n",
      "Epoch: 3, Batch: 326, Loss: 0.005248397123068571\n",
      "Epoch: 3, Batch: 327, Loss: 0.14497029781341553\n",
      "Epoch: 3, Batch: 328, Loss: 0.030831228941679\n",
      "Epoch: 3, Batch: 329, Loss: 0.017289698123931885\n",
      "Epoch: 3, Batch: 330, Loss: 0.0416482649743557\n",
      "Epoch: 3, Batch: 331, Loss: 0.02831391990184784\n",
      "Epoch: 3, Batch: 332, Loss: 0.003380774287506938\n",
      "Epoch: 3, Batch: 333, Loss: 0.016387799754738808\n",
      "Epoch: 3, Batch: 334, Loss: 0.05495026707649231\n",
      "Epoch: 3, Batch: 335, Loss: 0.060607802122831345\n",
      "Epoch: 3, Batch: 336, Loss: 0.09521994739770889\n",
      "Epoch: 3, Batch: 337, Loss: 0.00246482715010643\n",
      "Epoch: 3, Batch: 338, Loss: 0.07338909804821014\n",
      "Epoch: 3, Batch: 339, Loss: 0.008287505246698856\n",
      "Epoch: 3, Batch: 340, Loss: 0.02892553247511387\n",
      "Epoch: 3, Batch: 341, Loss: 0.016614556312561035\n",
      "Epoch: 3, Batch: 342, Loss: 0.02252514474093914\n",
      "Epoch: 3, Batch: 343, Loss: 0.006343684159219265\n",
      "Epoch: 3, Batch: 344, Loss: 0.0010093343444168568\n",
      "Epoch: 3, Batch: 345, Loss: 0.0014677116414532065\n",
      "Epoch: 3, Batch: 346, Loss: 0.002868716837838292\n",
      "Epoch: 3, Batch: 347, Loss: 0.04708190634846687\n",
      "Epoch: 3, Batch: 348, Loss: 0.03161565959453583\n",
      "Epoch: 3, Batch: 349, Loss: 0.04691237956285477\n",
      "Epoch: 3, Batch: 350, Loss: 0.0051046437583863735\n",
      "Epoch: 3, Batch: 351, Loss: 0.004104081075638533\n",
      "Epoch: 3, Batch: 352, Loss: 0.005029769614338875\n",
      "Epoch: 3, Batch: 353, Loss: 0.0490761362016201\n",
      "Epoch: 3, Batch: 354, Loss: 0.006106880493462086\n",
      "Epoch: 3, Batch: 355, Loss: 0.012298265472054482\n",
      "Epoch: 3, Batch: 356, Loss: 0.005223066080361605\n",
      "Epoch: 3, Batch: 357, Loss: 0.006349679548293352\n",
      "Epoch: 3, Batch: 358, Loss: 0.04772153124213219\n",
      "Epoch: 3, Batch: 359, Loss: 0.0022180660162121058\n",
      "Epoch: 3, Batch: 360, Loss: 0.013902194797992706\n",
      "Epoch: 3, Batch: 361, Loss: 0.01953715644776821\n",
      "Epoch: 3, Batch: 362, Loss: 0.001152514829300344\n",
      "Epoch: 3, Batch: 363, Loss: 0.024760184809565544\n",
      "Epoch: 3, Batch: 364, Loss: 0.02103268727660179\n",
      "Epoch: 3, Batch: 365, Loss: 0.0060962652787566185\n",
      "Epoch: 3, Batch: 366, Loss: 0.012135530821979046\n",
      "Epoch: 3, Batch: 367, Loss: 0.005769859068095684\n",
      "Epoch: 3, Batch: 368, Loss: 0.02595960907638073\n",
      "Epoch: 3, Batch: 369, Loss: 0.01320041436702013\n",
      "Epoch: 3, Batch: 370, Loss: 0.023126348853111267\n",
      "Epoch: 3, Batch: 371, Loss: 0.07996512204408646\n",
      "Epoch: 3, Batch: 372, Loss: 0.024173704907298088\n",
      "Epoch: 3, Batch: 373, Loss: 0.018503570929169655\n",
      "Epoch: 3, Batch: 374, Loss: 0.019715841859579086\n",
      "Epoch: 3, Batch: 375, Loss: 0.0041888924315571785\n",
      "Epoch: 3, Batch: 376, Loss: 0.013153214007616043\n",
      "Epoch: 3, Batch: 377, Loss: 0.031138859689235687\n",
      "Epoch: 3, Batch: 378, Loss: 0.00108967418782413\n",
      "Epoch: 3, Batch: 379, Loss: 0.0010837506270036101\n",
      "Epoch: 3, Batch: 380, Loss: 0.031045537441968918\n",
      "Epoch: 3, Batch: 381, Loss: 0.003143692621961236\n",
      "Epoch: 3, Batch: 382, Loss: 0.03721325471997261\n",
      "Epoch: 3, Batch: 383, Loss: 0.013556999154388905\n",
      "Epoch: 3, Batch: 384, Loss: 0.0006053810939192772\n",
      "Epoch: 3, Batch: 385, Loss: 0.0009243562235496938\n",
      "Epoch: 3, Batch: 386, Loss: 0.005897208582609892\n",
      "Epoch: 3, Batch: 387, Loss: 0.007232288829982281\n",
      "Epoch: 3, Batch: 388, Loss: 0.016010655090212822\n",
      "Epoch: 3, Batch: 389, Loss: 0.010404277592897415\n",
      "Epoch: 3, Batch: 390, Loss: 0.0065081059001386166\n",
      "Epoch: 3, Batch: 391, Loss: 0.008197981864213943\n",
      "Epoch: 3, Batch: 392, Loss: 0.14281074702739716\n",
      "Epoch: 3, Batch: 393, Loss: 0.0011417322093620896\n",
      "Epoch: 3, Batch: 394, Loss: 0.021764324977993965\n",
      "Epoch: 3, Batch: 395, Loss: 0.03547865152359009\n",
      "Epoch: 3, Batch: 396, Loss: 0.04575590416789055\n",
      "Epoch: 3, Batch: 397, Loss: 0.03475476801395416\n",
      "Epoch: 3, Batch: 398, Loss: 0.024450020864605904\n",
      "Epoch: 3, Batch: 399, Loss: 0.006592273712158203\n",
      "Epoch: 3, Batch: 400, Loss: 0.0005539592821151018\n",
      "Epoch: 3, Batch: 401, Loss: 0.09329795837402344\n",
      "Epoch: 3, Batch: 402, Loss: 0.03838669881224632\n",
      "Epoch: 3, Batch: 403, Loss: 0.008656742051243782\n",
      "Epoch: 3, Batch: 404, Loss: 0.09729374200105667\n",
      "Epoch: 3, Batch: 405, Loss: 0.022811712697148323\n",
      "Epoch: 3, Batch: 406, Loss: 0.1311669796705246\n",
      "Epoch: 3, Batch: 407, Loss: 0.031035056337714195\n",
      "Epoch: 3, Batch: 408, Loss: 0.011193675920367241\n",
      "Epoch: 3, Batch: 409, Loss: 0.003459880594164133\n",
      "Epoch: 3, Batch: 410, Loss: 0.046503547579050064\n",
      "Epoch: 3, Batch: 411, Loss: 0.008305602706968784\n",
      "Epoch: 3, Batch: 412, Loss: 0.1160762757062912\n",
      "Epoch: 3, Batch: 413, Loss: 0.0035022941883653402\n",
      "Epoch: 3, Batch: 414, Loss: 0.255275696516037\n",
      "Epoch: 3, Batch: 415, Loss: 0.010380038060247898\n",
      "Epoch: 3, Batch: 416, Loss: 0.01585417240858078\n",
      "Epoch: 3, Batch: 417, Loss: 0.07705483585596085\n",
      "Epoch: 3, Batch: 418, Loss: 0.009112371131777763\n",
      "Epoch: 3, Batch: 419, Loss: 0.06427866965532303\n",
      "Epoch: 3, Batch: 420, Loss: 0.0026266558561474085\n",
      "Epoch: 3, Batch: 421, Loss: 0.05559606850147247\n",
      "Epoch: 3, Batch: 422, Loss: 0.11618870496749878\n",
      "Epoch: 3, Batch: 423, Loss: 0.018162338063120842\n",
      "Epoch: 3, Batch: 424, Loss: 0.001050095888786018\n",
      "Epoch: 3, Batch: 425, Loss: 0.011742995120584965\n",
      "Epoch: 3, Batch: 426, Loss: 0.0023606184404343367\n",
      "Epoch: 3, Batch: 427, Loss: 0.009653436951339245\n",
      "Epoch: 3, Batch: 428, Loss: 0.018762346357107162\n",
      "Epoch: 3, Batch: 429, Loss: 0.055016644299030304\n",
      "Epoch: 3, Batch: 430, Loss: 0.09655024856328964\n",
      "Epoch: 3, Batch: 431, Loss: 0.0849466323852539\n",
      "Epoch: 3, Batch: 432, Loss: 0.002247100928798318\n",
      "Epoch: 3, Batch: 433, Loss: 0.015981871634721756\n",
      "Epoch: 3, Batch: 434, Loss: 0.01146480068564415\n",
      "Epoch: 3, Batch: 435, Loss: 0.0024981729220598936\n",
      "Epoch: 3, Batch: 436, Loss: 0.0020535162184387445\n",
      "Epoch: 3, Batch: 437, Loss: 0.009944147430360317\n",
      "Epoch: 3, Batch: 438, Loss: 0.005737280938774347\n",
      "Epoch: 3, Batch: 439, Loss: 0.0478467121720314\n",
      "Epoch: 3, Batch: 440, Loss: 0.21034228801727295\n",
      "Epoch: 3, Batch: 441, Loss: 0.012113991193473339\n",
      "Epoch: 3, Batch: 442, Loss: 0.012280689552426338\n",
      "Epoch: 3, Batch: 443, Loss: 0.02891305647790432\n",
      "Epoch: 3, Batch: 444, Loss: 0.0042471918277442455\n",
      "Epoch: 3, Batch: 445, Loss: 0.008033137768507004\n",
      "Epoch: 3, Batch: 446, Loss: 0.019044656306505203\n",
      "Epoch: 3, Batch: 447, Loss: 0.021660948172211647\n",
      "Epoch: 3, Batch: 448, Loss: 0.005224910099059343\n",
      "Epoch: 3, Batch: 449, Loss: 0.03551911562681198\n",
      "Epoch: 3, Batch: 450, Loss: 0.002915394026786089\n",
      "Epoch: 3, Batch: 451, Loss: 0.005584798287600279\n",
      "Epoch: 3, Batch: 452, Loss: 0.03425198420882225\n",
      "Epoch: 3, Batch: 453, Loss: 0.03537194803357124\n",
      "Epoch: 3, Batch: 454, Loss: 0.004985484294593334\n",
      "Epoch: 3, Batch: 455, Loss: 0.04443088918924332\n",
      "Epoch: 3, Batch: 456, Loss: 0.01751331239938736\n",
      "Epoch: 3, Batch: 457, Loss: 0.0020948208402842283\n",
      "Epoch: 3, Batch: 458, Loss: 0.03515077382326126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Batch: 459, Loss: 0.03511572256684303\n",
      "Epoch: 3, Batch: 460, Loss: 0.0029042381793260574\n",
      "Epoch: 3, Batch: 461, Loss: 0.004976428579539061\n",
      "Epoch: 3, Batch: 462, Loss: 0.11869992315769196\n",
      "Epoch: 3, Batch: 463, Loss: 0.007491203956305981\n",
      "Epoch: 3, Batch: 464, Loss: 0.009875212796032429\n",
      "Epoch: 3, Batch: 465, Loss: 0.047977153211832047\n",
      "Epoch: 3, Batch: 466, Loss: 0.020806076005101204\n",
      "Epoch: 3, Batch: 467, Loss: 0.003705997485667467\n",
      "Epoch: 3, Batch: 468, Loss: 0.017887648195028305\n",
      "Epoch: 3, Batch: 469, Loss: 0.02637317031621933\n",
      "Epoch: 3, Batch: 470, Loss: 0.003684990806505084\n",
      "Epoch: 3, Batch: 471, Loss: 0.059980615973472595\n",
      "Epoch: 3, Batch: 472, Loss: 0.05278079956769943\n",
      "Epoch: 3, Batch: 473, Loss: 0.006827818229794502\n",
      "Epoch: 3, Batch: 474, Loss: 0.06459855288267136\n",
      "Epoch: 3, Batch: 475, Loss: 0.13501307368278503\n",
      "Epoch: 3, Batch: 476, Loss: 0.0036618823651224375\n",
      "Epoch: 3, Batch: 477, Loss: 0.0018433169461786747\n",
      "Epoch: 3, Batch: 478, Loss: 0.010775752365589142\n",
      "Epoch: 3, Batch: 479, Loss: 0.06681375950574875\n",
      "Epoch: 3, Batch: 480, Loss: 0.09384334087371826\n",
      "Epoch: 3, Batch: 481, Loss: 0.008116425015032291\n",
      "Epoch: 3, Batch: 482, Loss: 0.07783932983875275\n",
      "Epoch: 3, Batch: 483, Loss: 0.0161249041557312\n",
      "Epoch: 3, Batch: 484, Loss: 0.02925814874470234\n",
      "Epoch: 3, Batch: 485, Loss: 0.031342871487140656\n",
      "Epoch: 3, Batch: 486, Loss: 0.04788830876350403\n",
      "Epoch: 3, Batch: 487, Loss: 0.056407105177640915\n",
      "Epoch: 3, Batch: 488, Loss: 0.010708690620958805\n",
      "Epoch: 3, Batch: 489, Loss: 0.034815724939107895\n",
      "Epoch: 3, Batch: 490, Loss: 0.06950372457504272\n",
      "Epoch: 3, Batch: 491, Loss: 0.06757698208093643\n",
      "Epoch: 3, Batch: 492, Loss: 0.0322941318154335\n",
      "Epoch: 3, Batch: 493, Loss: 0.011692972853779793\n",
      "Epoch: 3, Batch: 494, Loss: 0.017235219478607178\n",
      "Epoch: 3, Batch: 495, Loss: 0.1401854008436203\n",
      "Epoch: 3, Batch: 496, Loss: 0.00077058095484972\n",
      "Epoch: 3, Batch: 497, Loss: 0.0039163194596767426\n",
      "Epoch: 3, Batch: 498, Loss: 0.005149962846189737\n",
      "Epoch: 3, Batch: 499, Loss: 0.019724860787391663\n",
      "Epoch: 3, Batch: 500, Loss: 0.01435135118663311\n",
      "Epoch: 3, Batch: 501, Loss: 0.03287862241268158\n",
      "Epoch: 3, Batch: 502, Loss: 0.026088517159223557\n",
      "Epoch: 3, Batch: 503, Loss: 0.006001772824674845\n",
      "Epoch: 3, Batch: 504, Loss: 0.11978768557310104\n",
      "Epoch: 3, Batch: 505, Loss: 0.002685392275452614\n",
      "Epoch: 3, Batch: 506, Loss: 0.08693721890449524\n",
      "Epoch: 3, Batch: 507, Loss: 0.021835144609212875\n",
      "Epoch: 3, Batch: 508, Loss: 0.10496120154857635\n",
      "Epoch: 3, Batch: 509, Loss: 0.08803267776966095\n",
      "Epoch: 3, Batch: 510, Loss: 0.08477699011564255\n",
      "Epoch: 3, Batch: 511, Loss: 0.08428981900215149\n",
      "Epoch: 3, Batch: 512, Loss: 0.004926500841975212\n",
      "Epoch: 3, Batch: 513, Loss: 0.03350942209362984\n",
      "Epoch: 3, Batch: 514, Loss: 0.08364250510931015\n",
      "Epoch: 3, Batch: 515, Loss: 0.003077863249927759\n",
      "Epoch: 3, Batch: 516, Loss: 0.014837059192359447\n",
      "Epoch: 3, Batch: 517, Loss: 0.020556559786200523\n",
      "Epoch: 3, Batch: 518, Loss: 0.07153027504682541\n",
      "Epoch: 3, Batch: 519, Loss: 0.03866466507315636\n",
      "Epoch: 3, Batch: 520, Loss: 0.008807222358882427\n",
      "Epoch: 3, Batch: 521, Loss: 0.07082873582839966\n",
      "Epoch: 3, Batch: 522, Loss: 0.026158299297094345\n",
      "Epoch: 3, Batch: 523, Loss: 0.05149310082197189\n",
      "Epoch: 3, Batch: 524, Loss: 0.011065224185585976\n",
      "Epoch: 3, Batch: 525, Loss: 0.023620253428816795\n",
      "Epoch: 3, Batch: 526, Loss: 0.013192607089877129\n",
      "Epoch: 3, Batch: 527, Loss: 0.009481111541390419\n",
      "Epoch: 3, Batch: 528, Loss: 0.023847365751862526\n",
      "Epoch: 3, Batch: 529, Loss: 0.016262352466583252\n",
      "Epoch: 3, Batch: 530, Loss: 0.03407071530818939\n",
      "Epoch: 3, Batch: 531, Loss: 0.06076040863990784\n",
      "Epoch: 3, Batch: 532, Loss: 0.009018853306770325\n",
      "Epoch: 3, Batch: 533, Loss: 0.009075512178242207\n",
      "Epoch: 3, Batch: 534, Loss: 0.10108523815870285\n",
      "Epoch: 3, Batch: 535, Loss: 0.024565594270825386\n",
      "Epoch: 3, Batch: 536, Loss: 0.011613281443715096\n",
      "Epoch: 3, Batch: 537, Loss: 0.007216112222522497\n",
      "Epoch: 3, Batch: 538, Loss: 0.004234029911458492\n",
      "Epoch: 3, Batch: 539, Loss: 0.0060483552515506744\n",
      "Epoch: 3, Batch: 540, Loss: 0.014737953431904316\n",
      "Epoch: 3, Batch: 541, Loss: 0.02447451837360859\n",
      "Epoch: 3, Batch: 542, Loss: 0.06824667006731033\n",
      "Epoch: 3, Batch: 543, Loss: 0.019389845430850983\n",
      "Epoch: 3, Batch: 544, Loss: 0.0040798853151500225\n",
      "Epoch: 3, Batch: 545, Loss: 0.025375043973326683\n",
      "Epoch: 3, Batch: 546, Loss: 0.07686086744070053\n",
      "Epoch: 3, Batch: 547, Loss: 0.04058986157178879\n",
      "Epoch: 3, Batch: 548, Loss: 0.012147221714258194\n",
      "Epoch: 3, Batch: 549, Loss: 0.021482886746525764\n",
      "Epoch: 3, Batch: 550, Loss: 0.016598179936408997\n",
      "Epoch: 3, Batch: 551, Loss: 0.07034210860729218\n",
      "Epoch: 3, Batch: 552, Loss: 0.005805859807878733\n",
      "Epoch: 3, Batch: 553, Loss: 0.009321722202003002\n",
      "Epoch: 3, Batch: 554, Loss: 0.016919853165745735\n",
      "Epoch: 3, Batch: 555, Loss: 0.00679029431194067\n",
      "Epoch: 3, Batch: 556, Loss: 0.14075225591659546\n",
      "Epoch: 3, Batch: 557, Loss: 0.00236244173720479\n",
      "Epoch: 3, Batch: 558, Loss: 0.006237852852791548\n",
      "Epoch: 3, Batch: 559, Loss: 0.001513050519861281\n",
      "Epoch: 3, Batch: 560, Loss: 0.011587483808398247\n",
      "Epoch: 3, Batch: 561, Loss: 0.009146621450781822\n",
      "Epoch: 3, Batch: 562, Loss: 0.01680038496851921\n",
      "Epoch: 3, Batch: 563, Loss: 0.005991076119244099\n",
      "Epoch: 3, Batch: 564, Loss: 0.07222743332386017\n",
      "Epoch: 3, Batch: 565, Loss: 0.030936356633901596\n",
      "Epoch: 3, Batch: 566, Loss: 0.00899395253509283\n",
      "Epoch: 3, Batch: 567, Loss: 0.010481404140591621\n",
      "Epoch: 3, Batch: 568, Loss: 0.017599575221538544\n",
      "Epoch: 3, Batch: 569, Loss: 0.01690247282385826\n",
      "Epoch: 3, Batch: 570, Loss: 0.013904559426009655\n",
      "Epoch: 3, Batch: 571, Loss: 0.012036245316267014\n",
      "Epoch: 3, Batch: 572, Loss: 0.0027563765179365873\n",
      "Epoch: 3, Batch: 573, Loss: 0.01183726079761982\n",
      "Epoch: 3, Batch: 574, Loss: 0.004041150212287903\n",
      "Epoch: 3, Batch: 575, Loss: 0.03675364702939987\n",
      "Epoch: 3, Batch: 576, Loss: 0.16921351850032806\n",
      "Epoch: 3, Batch: 577, Loss: 0.013321379199624062\n",
      "Epoch: 3, Batch: 578, Loss: 0.003594981273636222\n",
      "Epoch: 3, Batch: 579, Loss: 0.06584006547927856\n",
      "Epoch: 3, Batch: 580, Loss: 0.033737219870090485\n",
      "Epoch: 3, Batch: 581, Loss: 0.05760187283158302\n",
      "Epoch: 3, Batch: 582, Loss: 0.026388151571154594\n",
      "Epoch: 3, Batch: 583, Loss: 0.06945765018463135\n",
      "Epoch: 3, Batch: 584, Loss: 0.03423251956701279\n",
      "Epoch: 3, Batch: 585, Loss: 0.0428185909986496\n",
      "Epoch: 3, Batch: 586, Loss: 0.020977303385734558\n",
      "Epoch: 3, Batch: 587, Loss: 0.018189696595072746\n",
      "Epoch: 3, Batch: 588, Loss: 0.01436955202370882\n",
      "Epoch: 3, Batch: 589, Loss: 0.016220249235630035\n",
      "Epoch: 3, Batch: 590, Loss: 0.013846001587808132\n",
      "Epoch: 3, Batch: 591, Loss: 0.03499994054436684\n",
      "Epoch: 3, Batch: 592, Loss: 0.03686533123254776\n",
      "Epoch: 3, Batch: 593, Loss: 0.005635865498334169\n",
      "Epoch: 3, Batch: 594, Loss: 0.01088221836835146\n",
      "Epoch: 3, Batch: 595, Loss: 0.025935877114534378\n",
      "Epoch: 3, Batch: 596, Loss: 0.06649739295244217\n",
      "Epoch: 3, Batch: 597, Loss: 0.042445108294487\n",
      "Epoch: 3, Batch: 598, Loss: 0.011029842309653759\n",
      "Epoch: 3, Batch: 599, Loss: 0.02213437482714653\n",
      "Epoch: 3, Batch: 600, Loss: 0.002812259830534458\n",
      "Epoch: 3, Batch: 601, Loss: 0.022012483328580856\n",
      "Epoch: 3, Batch: 602, Loss: 0.01776067726314068\n",
      "Epoch: 3, Batch: 603, Loss: 0.007001857273280621\n",
      "Epoch: 3, Batch: 604, Loss: 0.05799265205860138\n",
      "Epoch: 3, Batch: 605, Loss: 0.011682526208460331\n",
      "Epoch: 3, Batch: 606, Loss: 0.0010273930383846164\n",
      "Epoch: 3, Batch: 607, Loss: 0.013395337387919426\n",
      "Epoch: 3, Batch: 608, Loss: 0.050464827567338943\n",
      "Epoch: 3, Batch: 609, Loss: 0.13865165412425995\n",
      "Epoch: 3, Batch: 610, Loss: 0.00605603214353323\n",
      "Epoch: 3, Batch: 611, Loss: 0.02295733243227005\n",
      "Epoch: 3, Batch: 612, Loss: 0.019003992900252342\n",
      "Epoch: 3, Batch: 613, Loss: 0.00629939790815115\n",
      "Epoch: 3, Batch: 614, Loss: 0.0127987340092659\n",
      "Epoch: 3, Batch: 615, Loss: 0.03926851972937584\n",
      "Epoch: 3, Batch: 616, Loss: 0.02449449524283409\n",
      "Epoch: 3, Batch: 617, Loss: 0.020753163844347\n",
      "Epoch: 3, Batch: 618, Loss: 0.012166212312877178\n",
      "Epoch: 3, Batch: 619, Loss: 0.004126980435103178\n",
      "Epoch: 3, Batch: 620, Loss: 0.015996327623724937\n",
      "Epoch: 3, Batch: 621, Loss: 0.010167112573981285\n",
      "Epoch: 3, Batch: 622, Loss: 0.08675862848758698\n",
      "Epoch: 3, Batch: 623, Loss: 0.059542883187532425\n",
      "Epoch: 3, Batch: 624, Loss: 0.02663680911064148\n",
      "Epoch: 3, Batch: 625, Loss: 0.008680174127221107\n",
      "Epoch: 3, Batch: 626, Loss: 0.016154078766703606\n",
      "Epoch: 3, Batch: 627, Loss: 0.0012573972344398499\n",
      "Epoch: 3, Batch: 628, Loss: 0.05462896078824997\n",
      "Epoch: 3, Batch: 629, Loss: 0.002467845566570759\n",
      "Epoch: 3, Batch: 630, Loss: 0.07536756992340088\n",
      "Epoch: 3, Batch: 631, Loss: 0.07188204675912857\n",
      "Epoch: 3, Batch: 632, Loss: 0.01277688518166542\n",
      "Epoch: 3, Batch: 633, Loss: 0.02543715201318264\n",
      "Epoch: 3, Batch: 634, Loss: 0.11360927671194077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Batch: 635, Loss: 0.049979958683252335\n",
      "Epoch: 3, Batch: 636, Loss: 0.0050297994166612625\n",
      "Epoch: 3, Batch: 637, Loss: 0.013877681456506252\n",
      "Epoch: 3, Batch: 638, Loss: 0.006494835019111633\n",
      "Epoch: 3, Batch: 639, Loss: 0.005352354142814875\n",
      "Epoch: 3, Batch: 640, Loss: 0.012795425951480865\n",
      "Epoch: 3, Batch: 641, Loss: 0.0729280635714531\n",
      "Epoch: 3, Batch: 642, Loss: 0.014665714465081692\n",
      "Epoch: 3, Batch: 643, Loss: 0.022092485800385475\n",
      "Epoch: 3, Batch: 644, Loss: 0.07551649957895279\n",
      "Epoch: 3, Batch: 645, Loss: 0.014051320031285286\n",
      "Epoch: 3, Batch: 646, Loss: 0.054148152470588684\n",
      "Epoch: 3, Batch: 647, Loss: 0.05318964272737503\n",
      "Epoch: 3, Batch: 648, Loss: 0.010598798282444477\n",
      "Epoch: 3, Batch: 649, Loss: 0.0051220194436609745\n",
      "Epoch: 3, Batch: 650, Loss: 0.006878764368593693\n",
      "Epoch: 3, Batch: 651, Loss: 0.05330231785774231\n",
      "Epoch: 3, Batch: 652, Loss: 0.002868993440642953\n",
      "Epoch: 3, Batch: 653, Loss: 0.0024731080047786236\n",
      "Epoch: 3, Batch: 654, Loss: 0.044825296849012375\n",
      "Epoch: 3, Batch: 655, Loss: 0.024253077805042267\n",
      "Epoch: 3, Batch: 656, Loss: 0.007828956469893456\n",
      "Epoch: 3, Batch: 657, Loss: 0.0008428023429587483\n",
      "Epoch: 3, Batch: 658, Loss: 0.01512135099619627\n",
      "Epoch: 3, Batch: 659, Loss: 0.014178823679685593\n",
      "Epoch: 3, Batch: 660, Loss: 0.010506809689104557\n",
      "Epoch: 3, Batch: 661, Loss: 0.024023471400141716\n",
      "Epoch: 3, Batch: 662, Loss: 0.03874194994568825\n",
      "Epoch: 3, Batch: 663, Loss: 0.04259679093956947\n",
      "Epoch: 3, Batch: 664, Loss: 0.026767859235405922\n",
      "Epoch: 3, Batch: 665, Loss: 0.020311811938881874\n",
      "Epoch: 3, Batch: 666, Loss: 0.08865774422883987\n",
      "Epoch: 3, Batch: 667, Loss: 0.0024191178381443024\n",
      "Epoch: 3, Batch: 668, Loss: 0.03253181278705597\n",
      "Epoch: 3, Batch: 669, Loss: 0.035544417798519135\n",
      "Epoch: 3, Batch: 670, Loss: 0.0030671011190861464\n",
      "Epoch: 3, Batch: 671, Loss: 0.00940561294555664\n",
      "Epoch: 3, Batch: 672, Loss: 0.05226251855492592\n",
      "Epoch: 3, Batch: 673, Loss: 0.025897393003106117\n",
      "Epoch: 3, Batch: 674, Loss: 0.07289581000804901\n",
      "Epoch: 3, Batch: 675, Loss: 0.08532959222793579\n",
      "Epoch: 3, Batch: 676, Loss: 0.08339866995811462\n",
      "Epoch: 3, Batch: 677, Loss: 0.0025656460784375668\n",
      "Epoch: 3, Batch: 678, Loss: 0.04239504039287567\n",
      "Epoch: 3, Batch: 679, Loss: 0.007743476890027523\n",
      "Epoch: 3, Batch: 680, Loss: 0.02297729067504406\n",
      "Epoch: 3, Batch: 681, Loss: 0.0026903527323156595\n",
      "Epoch: 3, Batch: 682, Loss: 0.004525258205831051\n",
      "Epoch: 3, Batch: 683, Loss: 0.0021361163817346096\n",
      "Epoch: 3, Batch: 684, Loss: 0.11874984204769135\n",
      "Epoch: 3, Batch: 685, Loss: 0.05283108353614807\n",
      "Epoch: 3, Batch: 686, Loss: 0.01775355264544487\n",
      "Epoch: 3, Batch: 687, Loss: 0.08344240486621857\n",
      "Epoch: 3, Batch: 688, Loss: 0.018344910815358162\n",
      "Epoch: 3, Batch: 689, Loss: 0.021036261692643166\n",
      "Epoch: 3, Batch: 690, Loss: 0.012952485121786594\n",
      "Epoch: 3, Batch: 691, Loss: 0.03859083354473114\n",
      "Epoch: 3, Batch: 692, Loss: 0.03323981910943985\n",
      "Epoch: 3, Batch: 693, Loss: 0.01152602769434452\n",
      "Epoch: 3, Batch: 694, Loss: 0.038544245064258575\n",
      "Epoch: 3, Batch: 695, Loss: 0.05566594377160072\n",
      "Epoch: 3, Batch: 696, Loss: 0.0017144427401944995\n",
      "Epoch: 3, Batch: 697, Loss: 0.016085991635918617\n",
      "Epoch: 3, Batch: 698, Loss: 0.04216144233942032\n",
      "Epoch: 3, Batch: 699, Loss: 0.05892588570713997\n",
      "Epoch: 3, Batch: 700, Loss: 0.0641639307141304\n",
      "Epoch: 3, Batch: 701, Loss: 0.05354226753115654\n",
      "Epoch: 3, Batch: 702, Loss: 0.002884675282984972\n",
      "Epoch: 3, Batch: 703, Loss: 0.18716874718666077\n",
      "Epoch: 3, Batch: 704, Loss: 0.045110952109098434\n",
      "Epoch: 3, Batch: 705, Loss: 0.09869754314422607\n",
      "Epoch: 3, Batch: 706, Loss: 0.010461072437465191\n",
      "Epoch: 3, Batch: 707, Loss: 0.017092052847146988\n",
      "Epoch: 3, Batch: 708, Loss: 0.08088398724794388\n",
      "Epoch: 3, Batch: 709, Loss: 0.024573499336838722\n",
      "Epoch: 3, Batch: 710, Loss: 0.031235314905643463\n",
      "Epoch: 3, Batch: 711, Loss: 0.020225005224347115\n",
      "Epoch: 3, Batch: 712, Loss: 0.04962265491485596\n",
      "Epoch: 3, Batch: 713, Loss: 0.013580180704593658\n",
      "Epoch: 3, Batch: 714, Loss: 0.015556124038994312\n",
      "Epoch: 3, Batch: 715, Loss: 0.004322750493884087\n",
      "Epoch: 3, Batch: 716, Loss: 0.06452428549528122\n",
      "Epoch: 3, Batch: 717, Loss: 0.017802830785512924\n",
      "Epoch: 3, Batch: 718, Loss: 0.015967998653650284\n",
      "Epoch: 3, Batch: 719, Loss: 0.0033165658824145794\n",
      "Epoch: 3, Batch: 720, Loss: 0.005265827756375074\n",
      "Epoch: 3, Batch: 721, Loss: 0.04512794688344002\n",
      "Epoch: 3, Batch: 722, Loss: 0.016474414616823196\n",
      "Epoch: 3, Batch: 723, Loss: 0.0029485372360795736\n",
      "Epoch: 3, Batch: 724, Loss: 0.015065108425915241\n",
      "Epoch: 3, Batch: 725, Loss: 0.029278839007019997\n",
      "Epoch: 3, Batch: 726, Loss: 0.03181459754705429\n",
      "Epoch: 3, Batch: 727, Loss: 0.014542166143655777\n",
      "Epoch: 3, Batch: 728, Loss: 0.049678657203912735\n",
      "Epoch: 3, Batch: 729, Loss: 0.005058129318058491\n",
      "Epoch: 3, Batch: 730, Loss: 0.009639188647270203\n",
      "Epoch: 3, Batch: 731, Loss: 0.029686780646443367\n",
      "Epoch: 3, Batch: 732, Loss: 0.005110376048833132\n",
      "Epoch: 3, Batch: 733, Loss: 0.026124456897377968\n",
      "Epoch: 3, Batch: 734, Loss: 0.02372240647673607\n",
      "Epoch: 3, Batch: 735, Loss: 0.026058662682771683\n",
      "Epoch: 3, Batch: 736, Loss: 0.008171213790774345\n",
      "Epoch: 3, Batch: 737, Loss: 0.004148923791944981\n",
      "Epoch: 3, Batch: 738, Loss: 0.15563525259494781\n",
      "Epoch: 3, Batch: 739, Loss: 0.11268000304698944\n",
      "Epoch: 3, Batch: 740, Loss: 0.00491681694984436\n",
      "Epoch: 3, Batch: 741, Loss: 0.008097443729639053\n",
      "Epoch: 3, Batch: 742, Loss: 0.2151692807674408\n",
      "Epoch: 3, Batch: 743, Loss: 0.04788273572921753\n",
      "Epoch: 3, Batch: 744, Loss: 0.10222728550434113\n",
      "Epoch: 3, Batch: 745, Loss: 0.0156182199716568\n",
      "Epoch: 3, Batch: 746, Loss: 0.028307851403951645\n",
      "Epoch: 3, Batch: 747, Loss: 0.042156316339969635\n",
      "Epoch: 3, Batch: 748, Loss: 0.030854834243655205\n",
      "Epoch: 3, Batch: 749, Loss: 0.02324303239583969\n",
      "Epoch: 3, Batch: 750, Loss: 0.002733251778408885\n",
      "Epoch: 3, Batch: 751, Loss: 0.020344547927379608\n",
      "Epoch: 3, Batch: 752, Loss: 0.05502011999487877\n",
      "Epoch: 3, Batch: 753, Loss: 0.03355761244893074\n",
      "Epoch: 3, Batch: 754, Loss: 0.12403116375207901\n",
      "Epoch: 3, Batch: 755, Loss: 0.0037966067902743816\n",
      "Epoch: 3, Batch: 756, Loss: 0.0010380635503679514\n",
      "Epoch: 3, Batch: 757, Loss: 0.0029056414496153593\n",
      "Epoch: 3, Batch: 758, Loss: 0.034127186983823776\n",
      "Epoch: 3, Batch: 759, Loss: 0.0075594354420900345\n",
      "Epoch: 3, Batch: 760, Loss: 0.034754183143377304\n",
      "Epoch: 3, Batch: 761, Loss: 0.03780386224389076\n",
      "Epoch: 3, Batch: 762, Loss: 0.019651243463158607\n",
      "Epoch: 3, Batch: 763, Loss: 0.02724447101354599\n",
      "Epoch: 3, Batch: 764, Loss: 0.014088042080402374\n",
      "Epoch: 3, Batch: 765, Loss: 0.011715511791408062\n",
      "Epoch: 3, Batch: 766, Loss: 0.03375162184238434\n",
      "Epoch: 3, Batch: 767, Loss: 0.012472502887248993\n",
      "Epoch: 3, Batch: 768, Loss: 0.05223573371767998\n",
      "Epoch: 3, Batch: 769, Loss: 0.020620644092559814\n",
      "Epoch: 3, Batch: 770, Loss: 0.004164845682680607\n",
      "Epoch: 3, Batch: 771, Loss: 0.010187479667365551\n",
      "Epoch: 3, Batch: 772, Loss: 0.0029742568731307983\n",
      "Epoch: 3, Batch: 773, Loss: 0.056124456226825714\n",
      "Epoch: 3, Batch: 774, Loss: 0.009985022246837616\n",
      "Epoch: 3, Batch: 775, Loss: 0.04716647043824196\n",
      "Epoch: 3, Batch: 776, Loss: 0.08205067366361618\n",
      "Epoch: 3, Batch: 777, Loss: 0.024190731346607208\n",
      "Epoch: 3, Batch: 778, Loss: 0.08748163282871246\n",
      "Epoch: 3, Batch: 779, Loss: 0.033548083156347275\n",
      "Epoch: 3, Batch: 780, Loss: 0.0014053303748369217\n",
      "Epoch: 3, Batch: 781, Loss: 0.04257398098707199\n",
      "Epoch: 3, Batch: 782, Loss: 0.11216624826192856\n",
      "Epoch: 3, Batch: 783, Loss: 0.03393549472093582\n",
      "Epoch: 3, Batch: 784, Loss: 0.018722888082265854\n",
      "Epoch: 3, Batch: 785, Loss: 0.006994030438363552\n",
      "Epoch: 3, Batch: 786, Loss: 0.08657161891460419\n",
      "Epoch: 3, Batch: 787, Loss: 0.005611110012978315\n",
      "Epoch: 3, Batch: 788, Loss: 0.006378373131155968\n",
      "Epoch: 3, Batch: 789, Loss: 0.009021632373332977\n",
      "Epoch: 3, Batch: 790, Loss: 0.0238775797188282\n",
      "Epoch: 3, Batch: 791, Loss: 0.03873232379555702\n",
      "Epoch: 3, Batch: 792, Loss: 0.10098276287317276\n",
      "Epoch: 3, Batch: 793, Loss: 0.06535498797893524\n",
      "Epoch: 3, Batch: 794, Loss: 0.01242486946284771\n",
      "Epoch: 3, Batch: 795, Loss: 0.057408321648836136\n",
      "Epoch: 3, Batch: 796, Loss: 0.05777223780751228\n",
      "Epoch: 3, Batch: 797, Loss: 0.03476482629776001\n",
      "Epoch: 3, Batch: 798, Loss: 0.013772664591670036\n",
      "Epoch: 3, Batch: 799, Loss: 0.004658031743019819\n",
      "Epoch: 3, Batch: 800, Loss: 0.08519798517227173\n",
      "Epoch: 3, Batch: 801, Loss: 0.011837834492325783\n",
      "Epoch: 3, Batch: 802, Loss: 0.0567576065659523\n",
      "Epoch: 3, Batch: 803, Loss: 0.0009171476121991873\n",
      "Epoch: 3, Batch: 804, Loss: 0.036035213619470596\n",
      "Epoch: 3, Batch: 805, Loss: 0.0009491993696428835\n",
      "Epoch: 3, Batch: 806, Loss: 0.05736205354332924\n",
      "Epoch: 3, Batch: 807, Loss: 0.011840539053082466\n",
      "Epoch: 3, Batch: 808, Loss: 0.0019303951412439346\n",
      "Epoch: 3, Batch: 809, Loss: 0.003179817460477352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Batch: 810, Loss: 0.035147473216056824\n",
      "Epoch: 3, Batch: 811, Loss: 0.009031007997691631\n",
      "Epoch: 3, Batch: 812, Loss: 0.02736373245716095\n",
      "Epoch: 3, Batch: 813, Loss: 0.054661042988300323\n",
      "Epoch: 3, Batch: 814, Loss: 0.01270008459687233\n",
      "Epoch: 3, Batch: 815, Loss: 0.025722643360495567\n",
      "Epoch: 3, Batch: 816, Loss: 0.001846311497502029\n",
      "Epoch: 3, Batch: 817, Loss: 0.03459353744983673\n",
      "Epoch: 3, Batch: 818, Loss: 0.015644947066903114\n",
      "Epoch: 3, Batch: 819, Loss: 0.00781930796802044\n",
      "Epoch: 3, Batch: 820, Loss: 0.0008868471486493945\n",
      "Epoch: 3, Batch: 821, Loss: 0.01335228607058525\n",
      "Epoch: 3, Batch: 822, Loss: 0.06785433739423752\n",
      "Epoch: 3, Batch: 823, Loss: 0.0007327870698645711\n",
      "Epoch: 3, Batch: 824, Loss: 0.07448311895132065\n",
      "Epoch: 3, Batch: 825, Loss: 0.044507745653390884\n",
      "Epoch: 3, Batch: 826, Loss: 0.030046215280890465\n",
      "Epoch: 3, Batch: 827, Loss: 0.08091229945421219\n",
      "Epoch: 3, Batch: 828, Loss: 0.0024331281892955303\n",
      "Epoch: 3, Batch: 829, Loss: 0.03047787770628929\n",
      "Epoch: 3, Batch: 830, Loss: 0.002899265382438898\n",
      "Epoch: 3, Batch: 831, Loss: 0.024625400081276894\n",
      "Epoch: 3, Batch: 832, Loss: 0.014312783256173134\n",
      "Epoch: 3, Batch: 833, Loss: 0.0026815813034772873\n",
      "Epoch: 3, Batch: 834, Loss: 0.0051111094653606415\n",
      "Epoch: 3, Batch: 835, Loss: 0.013461216352880001\n",
      "Epoch: 3, Batch: 836, Loss: 0.003329095197841525\n",
      "Epoch: 3, Batch: 837, Loss: 0.003228177782148123\n",
      "Epoch: 3, Batch: 838, Loss: 0.004653883166611195\n",
      "Epoch: 3, Batch: 839, Loss: 0.008103245869278908\n",
      "Epoch: 3, Batch: 840, Loss: 0.007799284998327494\n",
      "Epoch: 3, Batch: 841, Loss: 0.05591879040002823\n",
      "Epoch: 3, Batch: 842, Loss: 0.0017917591612786055\n",
      "Epoch: 3, Batch: 843, Loss: 0.009184250608086586\n",
      "Epoch: 3, Batch: 844, Loss: 0.015151563100516796\n",
      "Epoch: 3, Batch: 845, Loss: 0.017742881551384926\n",
      "Epoch: 3, Batch: 846, Loss: 0.0017248319927603006\n",
      "Epoch: 3, Batch: 847, Loss: 0.010650346986949444\n",
      "Epoch: 3, Batch: 848, Loss: 0.02913319505751133\n",
      "Epoch: 3, Batch: 849, Loss: 0.012230221182107925\n",
      "Epoch: 3, Batch: 850, Loss: 0.01887841522693634\n",
      "Epoch: 3, Batch: 851, Loss: 0.02099810168147087\n",
      "Epoch: 3, Batch: 852, Loss: 0.054601334035396576\n",
      "Epoch: 3, Batch: 853, Loss: 0.00576642993837595\n",
      "Epoch: 3, Batch: 854, Loss: 0.009251694194972515\n",
      "Epoch: 3, Batch: 855, Loss: 0.038543157279491425\n",
      "Epoch: 3, Batch: 856, Loss: 0.08754827827215195\n",
      "Epoch: 3, Batch: 857, Loss: 0.01005129236727953\n",
      "Epoch: 3, Batch: 858, Loss: 0.011007551103830338\n",
      "Epoch: 3, Batch: 859, Loss: 0.036394160240888596\n",
      "Epoch: 3, Batch: 860, Loss: 0.06899042427539825\n",
      "Epoch: 3, Batch: 861, Loss: 0.013833215460181236\n",
      "Epoch: 3, Batch: 862, Loss: 0.01051182858645916\n",
      "Epoch: 3, Batch: 863, Loss: 0.003368798876181245\n",
      "Epoch: 3, Batch: 864, Loss: 0.03888790309429169\n",
      "Epoch: 3, Batch: 865, Loss: 0.004917193204164505\n",
      "Epoch: 3, Batch: 866, Loss: 0.004605582915246487\n",
      "Epoch: 3, Batch: 867, Loss: 0.034662965685129166\n",
      "Epoch: 3, Batch: 868, Loss: 0.11210433393716812\n",
      "Epoch: 3, Batch: 869, Loss: 0.005508766043931246\n",
      "Epoch: 3, Batch: 870, Loss: 0.012242769822478294\n",
      "Epoch: 3, Batch: 871, Loss: 0.014241551980376244\n",
      "Epoch: 3, Batch: 872, Loss: 0.07812778651714325\n",
      "Epoch: 3, Batch: 873, Loss: 0.02137915976345539\n",
      "Epoch: 3, Batch: 874, Loss: 0.031112458556890488\n",
      "Epoch: 3, Batch: 875, Loss: 0.047185078263282776\n",
      "Epoch: 3, Batch: 876, Loss: 0.038943443447351456\n",
      "Epoch: 3, Batch: 877, Loss: 0.013334411196410656\n",
      "Epoch: 3, Batch: 878, Loss: 0.008600081317126751\n",
      "Epoch: 3, Batch: 879, Loss: 0.007258181925863028\n",
      "Epoch: 3, Batch: 880, Loss: 0.0023433517199009657\n",
      "Epoch: 3, Batch: 881, Loss: 0.11846593022346497\n",
      "Epoch: 3, Batch: 882, Loss: 0.007833962328732014\n",
      "Epoch: 3, Batch: 883, Loss: 0.012712973169982433\n",
      "Epoch: 3, Batch: 884, Loss: 0.0028067368548363447\n",
      "Epoch: 3, Batch: 885, Loss: 0.004328357055783272\n",
      "Epoch: 3, Batch: 886, Loss: 0.007464761845767498\n",
      "Epoch: 3, Batch: 887, Loss: 0.02785399928689003\n",
      "Epoch: 3, Batch: 888, Loss: 0.005373622290790081\n",
      "Epoch: 3, Batch: 889, Loss: 0.01406064536422491\n",
      "Epoch: 3, Batch: 890, Loss: 0.0037564507219940424\n",
      "Epoch: 3, Batch: 891, Loss: 0.004278230015188456\n",
      "Epoch: 3, Batch: 892, Loss: 0.018868470564484596\n",
      "Epoch: 3, Batch: 893, Loss: 0.017171230167150497\n",
      "Epoch: 3, Batch: 894, Loss: 0.014770502224564552\n",
      "Epoch: 3, Batch: 895, Loss: 0.02031187154352665\n",
      "Epoch: 3, Batch: 896, Loss: 0.05585401877760887\n",
      "Epoch: 3, Batch: 897, Loss: 0.008729438297450542\n",
      "Epoch: 3, Batch: 898, Loss: 0.0072251735255122185\n",
      "Epoch: 3, Batch: 899, Loss: 0.005931857042014599\n",
      "Epoch: 3, Batch: 900, Loss: 0.001793170697055757\n",
      "Epoch: 3, Batch: 901, Loss: 0.003688226453959942\n",
      "Epoch: 3, Batch: 902, Loss: 0.023878350853919983\n",
      "Epoch: 3, Batch: 903, Loss: 0.012316293083131313\n",
      "Epoch: 3, Batch: 904, Loss: 0.008428352884948254\n",
      "Epoch: 3, Batch: 905, Loss: 0.014728114008903503\n",
      "Epoch: 3, Batch: 906, Loss: 0.0012120559113100171\n",
      "Epoch: 3, Batch: 907, Loss: 0.01169748604297638\n",
      "Epoch: 3, Batch: 908, Loss: 0.04949465021491051\n",
      "Epoch: 3, Batch: 909, Loss: 0.029918143525719643\n",
      "Epoch: 3, Batch: 910, Loss: 0.07111809402704239\n",
      "Epoch: 3, Batch: 911, Loss: 0.0015734699554741383\n",
      "Epoch: 3, Batch: 912, Loss: 0.00971927959471941\n",
      "Epoch: 3, Batch: 913, Loss: 0.005775094032287598\n",
      "Epoch: 3, Batch: 914, Loss: 0.004901161417365074\n",
      "Epoch: 3, Batch: 915, Loss: 0.005355703644454479\n",
      "Epoch: 3, Batch: 916, Loss: 0.18590618669986725\n",
      "Epoch: 3, Batch: 917, Loss: 0.010244559496641159\n",
      "Epoch: 3, Batch: 918, Loss: 0.004398623015731573\n",
      "Epoch: 3, Batch: 919, Loss: 0.010606491938233376\n",
      "Epoch: 3, Batch: 920, Loss: 0.0042693112045526505\n",
      "Epoch: 3, Batch: 921, Loss: 0.003064689226448536\n",
      "Epoch: 3, Batch: 922, Loss: 0.04879520460963249\n",
      "Epoch: 3, Batch: 923, Loss: 0.032334066927433014\n",
      "Epoch: 3, Batch: 924, Loss: 0.0095853041857481\n",
      "Epoch: 3, Batch: 925, Loss: 0.007823253981769085\n",
      "Epoch: 3, Batch: 926, Loss: 0.010886088013648987\n",
      "Epoch: 3, Batch: 927, Loss: 0.05089399963617325\n",
      "Epoch: 3, Batch: 928, Loss: 0.005621030926704407\n",
      "Epoch: 3, Batch: 929, Loss: 0.007939748466014862\n",
      "Epoch: 3, Batch: 930, Loss: 0.061085525900125504\n",
      "Epoch: 3, Batch: 931, Loss: 0.0017825926188379526\n",
      "Epoch: 3, Batch: 932, Loss: 0.002774635562673211\n",
      "Epoch: 3, Batch: 933, Loss: 0.00188915035687387\n",
      "Epoch: 3, Batch: 934, Loss: 0.002725532278418541\n",
      "Epoch: 3, Batch: 935, Loss: 0.18926146626472473\n",
      "Epoch: 3, Batch: 936, Loss: 0.004011661279946566\n",
      "Epoch: 3, Batch: 937, Loss: 0.0006952266558073461\n",
      "Epoch: 4, Batch: 0, Loss: 0.017339805141091347\n",
      "Epoch: 4, Batch: 1, Loss: 0.017167318612337112\n",
      "Epoch: 4, Batch: 2, Loss: 0.04056058079004288\n",
      "Epoch: 4, Batch: 3, Loss: 0.001797057455405593\n",
      "Epoch: 4, Batch: 4, Loss: 0.050197526812553406\n",
      "Epoch: 4, Batch: 5, Loss: 0.007629706524312496\n",
      "Epoch: 4, Batch: 6, Loss: 0.003151013283059001\n",
      "Epoch: 4, Batch: 7, Loss: 0.001954701030626893\n",
      "Epoch: 4, Batch: 8, Loss: 0.011336520314216614\n",
      "Epoch: 4, Batch: 9, Loss: 0.02590176835656166\n",
      "Epoch: 4, Batch: 10, Loss: 0.02967076562345028\n",
      "Epoch: 4, Batch: 11, Loss: 0.0032551968470215797\n",
      "Epoch: 4, Batch: 12, Loss: 0.006776698864996433\n",
      "Epoch: 4, Batch: 13, Loss: 0.00986519642174244\n",
      "Epoch: 4, Batch: 14, Loss: 0.024571968242526054\n",
      "Epoch: 4, Batch: 15, Loss: 0.025837207213044167\n",
      "Epoch: 4, Batch: 16, Loss: 0.0011634179390966892\n",
      "Epoch: 4, Batch: 17, Loss: 0.014679042622447014\n",
      "Epoch: 4, Batch: 18, Loss: 0.010888010263442993\n",
      "Epoch: 4, Batch: 19, Loss: 0.0011401072843000293\n",
      "Epoch: 4, Batch: 20, Loss: 0.0026339474134147167\n",
      "Epoch: 4, Batch: 21, Loss: 0.0078160734847188\n",
      "Epoch: 4, Batch: 22, Loss: 0.00350461108610034\n",
      "Epoch: 4, Batch: 23, Loss: 0.0016682721907272935\n",
      "Epoch: 4, Batch: 24, Loss: 0.11567813158035278\n",
      "Epoch: 4, Batch: 25, Loss: 0.016143059358000755\n",
      "Epoch: 4, Batch: 26, Loss: 0.018409786745905876\n",
      "Epoch: 4, Batch: 27, Loss: 0.03723892569541931\n",
      "Epoch: 4, Batch: 28, Loss: 0.017290426418185234\n",
      "Epoch: 4, Batch: 29, Loss: 0.06810291111469269\n",
      "Epoch: 4, Batch: 30, Loss: 0.1269521862268448\n",
      "Epoch: 4, Batch: 31, Loss: 0.008310510776937008\n",
      "Epoch: 4, Batch: 32, Loss: 0.0017790899146348238\n",
      "Epoch: 4, Batch: 33, Loss: 0.0202957671135664\n",
      "Epoch: 4, Batch: 34, Loss: 0.0094103142619133\n",
      "Epoch: 4, Batch: 35, Loss: 0.02579565905034542\n",
      "Epoch: 4, Batch: 36, Loss: 0.012871265411376953\n",
      "Epoch: 4, Batch: 37, Loss: 0.021043365821242332\n",
      "Epoch: 4, Batch: 38, Loss: 0.08010802417993546\n",
      "Epoch: 4, Batch: 39, Loss: 0.026737621054053307\n",
      "Epoch: 4, Batch: 40, Loss: 0.030021853744983673\n",
      "Epoch: 4, Batch: 41, Loss: 0.033216625452041626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Batch: 42, Loss: 0.020513877272605896\n",
      "Epoch: 4, Batch: 43, Loss: 0.1660912185907364\n",
      "Epoch: 4, Batch: 44, Loss: 0.00037621535011567175\n",
      "Epoch: 4, Batch: 45, Loss: 0.04408705607056618\n",
      "Epoch: 4, Batch: 46, Loss: 0.003760998835787177\n",
      "Epoch: 4, Batch: 47, Loss: 0.12205331027507782\n",
      "Epoch: 4, Batch: 48, Loss: 0.004459608346223831\n",
      "Epoch: 4, Batch: 49, Loss: 0.010847841389477253\n",
      "Epoch: 4, Batch: 50, Loss: 0.011822741478681564\n",
      "Epoch: 4, Batch: 51, Loss: 0.0003263091202825308\n",
      "Epoch: 4, Batch: 52, Loss: 0.03719637915492058\n",
      "Epoch: 4, Batch: 53, Loss: 0.02022644318640232\n",
      "Epoch: 4, Batch: 54, Loss: 0.06509097665548325\n",
      "Epoch: 4, Batch: 55, Loss: 0.0527651347219944\n",
      "Epoch: 4, Batch: 56, Loss: 0.0015521133318543434\n",
      "Epoch: 4, Batch: 57, Loss: 0.0011858082143589854\n",
      "Epoch: 4, Batch: 58, Loss: 0.010423694737255573\n",
      "Epoch: 4, Batch: 59, Loss: 0.0900774598121643\n",
      "Epoch: 4, Batch: 60, Loss: 0.006715121679008007\n",
      "Epoch: 4, Batch: 61, Loss: 0.0416698232293129\n",
      "Epoch: 4, Batch: 62, Loss: 0.024618517607450485\n",
      "Epoch: 4, Batch: 63, Loss: 0.0007667235331609845\n",
      "Epoch: 4, Batch: 64, Loss: 0.003034251509234309\n",
      "Epoch: 4, Batch: 65, Loss: 0.006120824255049229\n",
      "Epoch: 4, Batch: 66, Loss: 0.002237107837572694\n",
      "Epoch: 4, Batch: 67, Loss: 0.01913059689104557\n",
      "Epoch: 4, Batch: 68, Loss: 0.0182091873139143\n",
      "Epoch: 4, Batch: 69, Loss: 0.008923609741032124\n",
      "Epoch: 4, Batch: 70, Loss: 0.05298902839422226\n",
      "Epoch: 4, Batch: 71, Loss: 0.01955089159309864\n",
      "Epoch: 4, Batch: 72, Loss: 0.004671563394367695\n",
      "Epoch: 4, Batch: 73, Loss: 0.008396421559154987\n",
      "Epoch: 4, Batch: 74, Loss: 0.021515654399991035\n",
      "Epoch: 4, Batch: 75, Loss: 0.018184078857302666\n",
      "Epoch: 4, Batch: 76, Loss: 0.028466198593378067\n",
      "Epoch: 4, Batch: 77, Loss: 0.06674019992351532\n",
      "Epoch: 4, Batch: 78, Loss: 0.0016052263090386987\n",
      "Epoch: 4, Batch: 79, Loss: 0.023700490593910217\n",
      "Epoch: 4, Batch: 80, Loss: 0.004467487800866365\n",
      "Epoch: 4, Batch: 81, Loss: 0.019840052351355553\n",
      "Epoch: 4, Batch: 82, Loss: 0.013831621035933495\n",
      "Epoch: 4, Batch: 83, Loss: 0.026947857812047005\n",
      "Epoch: 4, Batch: 84, Loss: 0.010806822218000889\n",
      "Epoch: 4, Batch: 85, Loss: 0.007159328553825617\n",
      "Epoch: 4, Batch: 86, Loss: 0.030336737632751465\n",
      "Epoch: 4, Batch: 87, Loss: 0.004019704647362232\n",
      "Epoch: 4, Batch: 88, Loss: 0.0018205868545919657\n",
      "Epoch: 4, Batch: 89, Loss: 0.04482172429561615\n",
      "Epoch: 4, Batch: 90, Loss: 0.005433793179690838\n",
      "Epoch: 4, Batch: 91, Loss: 0.0008375114994123578\n",
      "Epoch: 4, Batch: 92, Loss: 0.0001407612580806017\n",
      "Epoch: 4, Batch: 93, Loss: 0.03581260144710541\n",
      "Epoch: 4, Batch: 94, Loss: 0.020690931007266045\n",
      "Epoch: 4, Batch: 95, Loss: 0.03164181113243103\n",
      "Epoch: 4, Batch: 96, Loss: 0.00827899668365717\n",
      "Epoch: 4, Batch: 97, Loss: 0.0024565912317484617\n",
      "Epoch: 4, Batch: 98, Loss: 0.0002566722687333822\n",
      "Epoch: 4, Batch: 99, Loss: 0.04462771117687225\n",
      "Epoch: 4, Batch: 100, Loss: 0.0020407282281666994\n",
      "Epoch: 4, Batch: 101, Loss: 0.04712595418095589\n",
      "Epoch: 4, Batch: 102, Loss: 0.012285240925848484\n",
      "Epoch: 4, Batch: 103, Loss: 0.002799070905894041\n",
      "Epoch: 4, Batch: 104, Loss: 0.006812514737248421\n",
      "Epoch: 4, Batch: 105, Loss: 0.014975547790527344\n",
      "Epoch: 4, Batch: 106, Loss: 0.1410645693540573\n",
      "Epoch: 4, Batch: 107, Loss: 0.0020575299859046936\n",
      "Epoch: 4, Batch: 108, Loss: 0.009501258842647076\n",
      "Epoch: 4, Batch: 109, Loss: 0.0019220811082050204\n",
      "Epoch: 4, Batch: 110, Loss: 0.033828623592853546\n",
      "Epoch: 4, Batch: 111, Loss: 0.010525792837142944\n",
      "Epoch: 4, Batch: 112, Loss: 0.00251776073127985\n",
      "Epoch: 4, Batch: 113, Loss: 0.01965825818479061\n",
      "Epoch: 4, Batch: 114, Loss: 0.07491645216941833\n",
      "Epoch: 4, Batch: 115, Loss: 0.0459163673222065\n",
      "Epoch: 4, Batch: 116, Loss: 0.059987038373947144\n",
      "Epoch: 4, Batch: 117, Loss: 0.0019691982306540012\n",
      "Epoch: 4, Batch: 118, Loss: 0.005038261413574219\n",
      "Epoch: 4, Batch: 119, Loss: 0.0017750159604474902\n",
      "Epoch: 4, Batch: 120, Loss: 0.0009294598712585866\n",
      "Epoch: 4, Batch: 121, Loss: 0.01087107788771391\n",
      "Epoch: 4, Batch: 122, Loss: 0.008658071048557758\n",
      "Epoch: 4, Batch: 123, Loss: 0.006366163957864046\n",
      "Epoch: 4, Batch: 124, Loss: 0.036130186170339584\n",
      "Epoch: 4, Batch: 125, Loss: 0.05147174745798111\n",
      "Epoch: 4, Batch: 126, Loss: 0.0004541945818345994\n",
      "Epoch: 4, Batch: 127, Loss: 0.011615949682891369\n",
      "Epoch: 4, Batch: 128, Loss: 0.008002747781574726\n",
      "Epoch: 4, Batch: 129, Loss: 0.0020720825996249914\n",
      "Epoch: 4, Batch: 130, Loss: 0.02588821016252041\n",
      "Epoch: 4, Batch: 131, Loss: 0.10176365077495575\n",
      "Epoch: 4, Batch: 132, Loss: 0.0019519070629030466\n",
      "Epoch: 4, Batch: 133, Loss: 0.013342386111617088\n",
      "Epoch: 4, Batch: 134, Loss: 0.08147574961185455\n",
      "Epoch: 4, Batch: 135, Loss: 0.01271824724972248\n",
      "Epoch: 4, Batch: 136, Loss: 0.08830491453409195\n",
      "Epoch: 4, Batch: 137, Loss: 0.005057097412645817\n",
      "Epoch: 4, Batch: 138, Loss: 0.0011939620599150658\n",
      "Epoch: 4, Batch: 139, Loss: 0.040217842906713486\n",
      "Epoch: 4, Batch: 140, Loss: 0.00433428306132555\n",
      "Epoch: 4, Batch: 141, Loss: 0.003824901534244418\n",
      "Epoch: 4, Batch: 142, Loss: 0.004818616434931755\n",
      "Epoch: 4, Batch: 143, Loss: 0.1088721975684166\n",
      "Epoch: 4, Batch: 144, Loss: 0.027297183871269226\n",
      "Epoch: 4, Batch: 145, Loss: 0.005131281912326813\n",
      "Epoch: 4, Batch: 146, Loss: 0.031073138117790222\n",
      "Epoch: 4, Batch: 147, Loss: 0.004808991216123104\n",
      "Epoch: 4, Batch: 148, Loss: 0.014470823109149933\n",
      "Epoch: 4, Batch: 149, Loss: 0.10024584829807281\n",
      "Epoch: 4, Batch: 150, Loss: 0.06856721639633179\n",
      "Epoch: 4, Batch: 151, Loss: 0.0031782668083906174\n",
      "Epoch: 4, Batch: 152, Loss: 0.0033708843402564526\n",
      "Epoch: 4, Batch: 153, Loss: 0.011883677914738655\n",
      "Epoch: 4, Batch: 154, Loss: 0.04789161682128906\n",
      "Epoch: 4, Batch: 155, Loss: 0.004325906280428171\n",
      "Epoch: 4, Batch: 156, Loss: 0.0010104745160788298\n",
      "Epoch: 4, Batch: 157, Loss: 0.0011646316852420568\n",
      "Epoch: 4, Batch: 158, Loss: 0.0166634414345026\n",
      "Epoch: 4, Batch: 159, Loss: 0.0017000939697027206\n",
      "Epoch: 4, Batch: 160, Loss: 0.04120927304029465\n",
      "Epoch: 4, Batch: 161, Loss: 0.028264924883842468\n",
      "Epoch: 4, Batch: 162, Loss: 0.006772021297365427\n",
      "Epoch: 4, Batch: 163, Loss: 0.0009662691154517233\n",
      "Epoch: 4, Batch: 164, Loss: 0.04273371770977974\n",
      "Epoch: 4, Batch: 165, Loss: 0.05713273957371712\n",
      "Epoch: 4, Batch: 166, Loss: 0.0045728678815066814\n",
      "Epoch: 4, Batch: 167, Loss: 0.08392215520143509\n",
      "Epoch: 4, Batch: 168, Loss: 0.004743072669953108\n",
      "Epoch: 4, Batch: 169, Loss: 0.0025699292309582233\n",
      "Epoch: 4, Batch: 170, Loss: 0.0006597854662686586\n",
      "Epoch: 4, Batch: 171, Loss: 0.026644589379429817\n",
      "Epoch: 4, Batch: 172, Loss: 0.014912363141775131\n",
      "Epoch: 4, Batch: 173, Loss: 0.0037951769772917032\n",
      "Epoch: 4, Batch: 174, Loss: 0.0009369009640067816\n",
      "Epoch: 4, Batch: 175, Loss: 0.02207803539931774\n",
      "Epoch: 4, Batch: 176, Loss: 0.003375849686563015\n",
      "Epoch: 4, Batch: 177, Loss: 0.0005612992681562901\n",
      "Epoch: 4, Batch: 178, Loss: 0.026357309892773628\n",
      "Epoch: 4, Batch: 179, Loss: 0.006344572640955448\n",
      "Epoch: 4, Batch: 180, Loss: 0.07570046931505203\n",
      "Epoch: 4, Batch: 181, Loss: 0.006733734160661697\n",
      "Epoch: 4, Batch: 182, Loss: 0.004432164132595062\n",
      "Epoch: 4, Batch: 183, Loss: 0.0023366250097751617\n",
      "Epoch: 4, Batch: 184, Loss: 0.01315593533217907\n",
      "Epoch: 4, Batch: 185, Loss: 0.10761184245347977\n",
      "Epoch: 4, Batch: 186, Loss: 0.006062331609427929\n",
      "Epoch: 4, Batch: 187, Loss: 0.002836754312738776\n",
      "Epoch: 4, Batch: 188, Loss: 0.007157105021178722\n",
      "Epoch: 4, Batch: 189, Loss: 0.0034719910472631454\n",
      "Epoch: 4, Batch: 190, Loss: 0.0014589434722438455\n",
      "Epoch: 4, Batch: 191, Loss: 0.031697504222393036\n",
      "Epoch: 4, Batch: 192, Loss: 0.005648523569107056\n",
      "Epoch: 4, Batch: 193, Loss: 0.01931220106780529\n",
      "Epoch: 4, Batch: 194, Loss: 0.025517424568533897\n",
      "Epoch: 4, Batch: 195, Loss: 0.0014952188357710838\n",
      "Epoch: 4, Batch: 196, Loss: 0.0015181986382231116\n",
      "Epoch: 4, Batch: 197, Loss: 0.0012304350966587663\n",
      "Epoch: 4, Batch: 198, Loss: 0.0046219602227211\n",
      "Epoch: 4, Batch: 199, Loss: 0.008705126121640205\n",
      "Epoch: 4, Batch: 200, Loss: 0.06631030142307281\n",
      "Epoch: 4, Batch: 201, Loss: 0.004113074857741594\n",
      "Epoch: 4, Batch: 202, Loss: 0.000622057355940342\n",
      "Epoch: 4, Batch: 203, Loss: 0.0009286787244491279\n",
      "Epoch: 4, Batch: 204, Loss: 0.002501473994925618\n",
      "Epoch: 4, Batch: 205, Loss: 0.00244732154533267\n",
      "Epoch: 4, Batch: 206, Loss: 0.017482813447713852\n",
      "Epoch: 4, Batch: 207, Loss: 0.0005878907977603376\n",
      "Epoch: 4, Batch: 208, Loss: 0.0010711555369198322\n",
      "Epoch: 4, Batch: 209, Loss: 0.06100190803408623\n",
      "Epoch: 4, Batch: 210, Loss: 0.002726299222558737\n",
      "Epoch: 4, Batch: 211, Loss: 0.0557258203625679\n",
      "Epoch: 4, Batch: 212, Loss: 0.06127186119556427\n",
      "Epoch: 4, Batch: 213, Loss: 0.004589749965816736\n",
      "Epoch: 4, Batch: 214, Loss: 0.043378207832574844\n",
      "Epoch: 4, Batch: 215, Loss: 0.08704865723848343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Batch: 216, Loss: 0.0271849874407053\n",
      "Epoch: 4, Batch: 217, Loss: 0.0031456861179322004\n",
      "Epoch: 4, Batch: 218, Loss: 0.027861356735229492\n",
      "Epoch: 4, Batch: 219, Loss: 0.029474573209881783\n",
      "Epoch: 4, Batch: 220, Loss: 0.0040900553576648235\n",
      "Epoch: 4, Batch: 221, Loss: 0.0026190367061644793\n",
      "Epoch: 4, Batch: 222, Loss: 0.041534580290317535\n",
      "Epoch: 4, Batch: 223, Loss: 0.05425732582807541\n",
      "Epoch: 4, Batch: 224, Loss: 0.019510731101036072\n",
      "Epoch: 4, Batch: 225, Loss: 0.0029695159755647182\n",
      "Epoch: 4, Batch: 226, Loss: 0.09180651605129242\n",
      "Epoch: 4, Batch: 227, Loss: 0.003769912291318178\n",
      "Epoch: 4, Batch: 228, Loss: 0.01687113754451275\n",
      "Epoch: 4, Batch: 229, Loss: 0.0015748463338240981\n",
      "Epoch: 4, Batch: 230, Loss: 0.0268419086933136\n",
      "Epoch: 4, Batch: 231, Loss: 0.015333415009081364\n",
      "Epoch: 4, Batch: 232, Loss: 0.002160700038075447\n",
      "Epoch: 4, Batch: 233, Loss: 0.0031763208098709583\n",
      "Epoch: 4, Batch: 234, Loss: 0.06918373703956604\n",
      "Epoch: 4, Batch: 235, Loss: 0.006783489137887955\n",
      "Epoch: 4, Batch: 236, Loss: 0.00043198742787353694\n",
      "Epoch: 4, Batch: 237, Loss: 0.006505630910396576\n",
      "Epoch: 4, Batch: 238, Loss: 0.0006118349265307188\n",
      "Epoch: 4, Batch: 239, Loss: 0.07069279998540878\n",
      "Epoch: 4, Batch: 240, Loss: 0.034893810749053955\n",
      "Epoch: 4, Batch: 241, Loss: 0.06884001195430756\n",
      "Epoch: 4, Batch: 242, Loss: 0.012720407918095589\n",
      "Epoch: 4, Batch: 243, Loss: 0.0009590963018126786\n",
      "Epoch: 4, Batch: 244, Loss: 0.0363508015871048\n",
      "Epoch: 4, Batch: 245, Loss: 0.0025477437302470207\n",
      "Epoch: 4, Batch: 246, Loss: 0.0014687982620671391\n",
      "Epoch: 4, Batch: 247, Loss: 0.12102913111448288\n",
      "Epoch: 4, Batch: 248, Loss: 0.11650069802999496\n",
      "Epoch: 4, Batch: 249, Loss: 0.013761838898062706\n",
      "Epoch: 4, Batch: 250, Loss: 0.04776662960648537\n",
      "Epoch: 4, Batch: 251, Loss: 0.016349775716662407\n",
      "Epoch: 4, Batch: 252, Loss: 0.0022253815550357103\n",
      "Epoch: 4, Batch: 253, Loss: 0.006700518541038036\n",
      "Epoch: 4, Batch: 254, Loss: 0.20855076611042023\n",
      "Epoch: 4, Batch: 255, Loss: 0.023992011323571205\n",
      "Epoch: 4, Batch: 256, Loss: 0.08400870859622955\n",
      "Epoch: 4, Batch: 257, Loss: 0.01049000397324562\n",
      "Epoch: 4, Batch: 258, Loss: 0.017432743683457375\n",
      "Epoch: 4, Batch: 259, Loss: 0.08540918678045273\n",
      "Epoch: 4, Batch: 260, Loss: 0.06514894217252731\n",
      "Epoch: 4, Batch: 261, Loss: 0.03664640337228775\n",
      "Epoch: 4, Batch: 262, Loss: 0.008044777438044548\n",
      "Epoch: 4, Batch: 263, Loss: 0.07345285266637802\n",
      "Epoch: 4, Batch: 264, Loss: 0.0024107007775455713\n",
      "Epoch: 4, Batch: 265, Loss: 0.00833461619913578\n",
      "Epoch: 4, Batch: 266, Loss: 0.022048573940992355\n",
      "Epoch: 4, Batch: 267, Loss: 0.04677683487534523\n",
      "Epoch: 4, Batch: 268, Loss: 0.021054217591881752\n",
      "Epoch: 4, Batch: 269, Loss: 0.05607679858803749\n",
      "Epoch: 4, Batch: 270, Loss: 0.0013880396727472544\n",
      "Epoch: 4, Batch: 271, Loss: 0.009099769406020641\n",
      "Epoch: 4, Batch: 272, Loss: 0.004465604200959206\n",
      "Epoch: 4, Batch: 273, Loss: 0.16734683513641357\n",
      "Epoch: 4, Batch: 274, Loss: 0.012163990177214146\n",
      "Epoch: 4, Batch: 275, Loss: 0.16132330894470215\n",
      "Epoch: 4, Batch: 276, Loss: 0.03664463758468628\n",
      "Epoch: 4, Batch: 277, Loss: 0.0033487689215689898\n",
      "Epoch: 4, Batch: 278, Loss: 0.0008259047172032297\n",
      "Epoch: 4, Batch: 279, Loss: 0.06355515122413635\n",
      "Epoch: 4, Batch: 280, Loss: 0.009670563042163849\n",
      "Epoch: 4, Batch: 281, Loss: 0.017119811847805977\n",
      "Epoch: 4, Batch: 282, Loss: 0.008835586719214916\n",
      "Epoch: 4, Batch: 283, Loss: 0.06868185847997665\n",
      "Epoch: 4, Batch: 284, Loss: 0.032036613672971725\n",
      "Epoch: 4, Batch: 285, Loss: 0.0018679247004911304\n",
      "Epoch: 4, Batch: 286, Loss: 0.012848775833845139\n",
      "Epoch: 4, Batch: 287, Loss: 0.017422473058104515\n",
      "Epoch: 4, Batch: 288, Loss: 0.011906690895557404\n",
      "Epoch: 4, Batch: 289, Loss: 0.004687224514782429\n",
      "Epoch: 4, Batch: 290, Loss: 0.009637939743697643\n",
      "Epoch: 4, Batch: 291, Loss: 0.021886123344302177\n",
      "Epoch: 4, Batch: 292, Loss: 0.001741241430863738\n",
      "Epoch: 4, Batch: 293, Loss: 0.001348632387816906\n",
      "Epoch: 4, Batch: 294, Loss: 0.005049718543887138\n",
      "Epoch: 4, Batch: 295, Loss: 0.03068978153169155\n",
      "Epoch: 4, Batch: 296, Loss: 0.023093203082680702\n",
      "Epoch: 4, Batch: 297, Loss: 0.04085720330476761\n",
      "Epoch: 4, Batch: 298, Loss: 0.014994182623922825\n",
      "Epoch: 4, Batch: 299, Loss: 0.009243189357221127\n",
      "Epoch: 4, Batch: 300, Loss: 0.001911473460495472\n",
      "Epoch: 4, Batch: 301, Loss: 0.06261812150478363\n",
      "Epoch: 4, Batch: 302, Loss: 0.01012797374278307\n",
      "Epoch: 4, Batch: 303, Loss: 0.08545820415019989\n",
      "Epoch: 4, Batch: 304, Loss: 0.020058458670973778\n",
      "Epoch: 4, Batch: 305, Loss: 0.09647899866104126\n",
      "Epoch: 4, Batch: 306, Loss: 0.003091265680268407\n",
      "Epoch: 4, Batch: 307, Loss: 0.02042885683476925\n",
      "Epoch: 4, Batch: 308, Loss: 0.001973130274564028\n",
      "Epoch: 4, Batch: 309, Loss: 0.017299821600317955\n",
      "Epoch: 4, Batch: 310, Loss: 0.04685937985777855\n",
      "Epoch: 4, Batch: 311, Loss: 0.0126822330057621\n",
      "Epoch: 4, Batch: 312, Loss: 0.03786510229110718\n",
      "Epoch: 4, Batch: 313, Loss: 0.031651150435209274\n",
      "Epoch: 4, Batch: 314, Loss: 0.04821600392460823\n",
      "Epoch: 4, Batch: 315, Loss: 0.04907591640949249\n",
      "Epoch: 4, Batch: 316, Loss: 0.015415609814226627\n",
      "Epoch: 4, Batch: 317, Loss: 0.050705891102552414\n",
      "Epoch: 4, Batch: 318, Loss: 0.08203990757465363\n",
      "Epoch: 4, Batch: 319, Loss: 0.09793835878372192\n",
      "Epoch: 4, Batch: 320, Loss: 0.03814312443137169\n",
      "Epoch: 4, Batch: 321, Loss: 0.009488670155405998\n",
      "Epoch: 4, Batch: 322, Loss: 0.02484774962067604\n",
      "Epoch: 4, Batch: 323, Loss: 0.01861398108303547\n",
      "Epoch: 4, Batch: 324, Loss: 0.001832280308008194\n",
      "Epoch: 4, Batch: 325, Loss: 0.0027822633273899555\n",
      "Epoch: 4, Batch: 326, Loss: 0.0357213132083416\n",
      "Epoch: 4, Batch: 327, Loss: 0.08186114579439163\n",
      "Epoch: 4, Batch: 328, Loss: 0.004580534994602203\n",
      "Epoch: 4, Batch: 329, Loss: 0.007636386435478926\n",
      "Epoch: 4, Batch: 330, Loss: 0.04415316879749298\n",
      "Epoch: 4, Batch: 331, Loss: 0.001994393765926361\n",
      "Epoch: 4, Batch: 332, Loss: 0.007903209887444973\n",
      "Epoch: 4, Batch: 333, Loss: 0.0018131869146600366\n",
      "Epoch: 4, Batch: 334, Loss: 0.02408530004322529\n",
      "Epoch: 4, Batch: 335, Loss: 0.020201154053211212\n",
      "Epoch: 4, Batch: 336, Loss: 0.043253909796476364\n",
      "Epoch: 4, Batch: 337, Loss: 0.027632351964712143\n",
      "Epoch: 4, Batch: 338, Loss: 0.0012197811156511307\n",
      "Epoch: 4, Batch: 339, Loss: 0.00714175496250391\n",
      "Epoch: 4, Batch: 340, Loss: 0.018802454695105553\n",
      "Epoch: 4, Batch: 341, Loss: 0.02294231578707695\n",
      "Epoch: 4, Batch: 342, Loss: 0.018194228410720825\n",
      "Epoch: 4, Batch: 343, Loss: 0.01725439913570881\n",
      "Epoch: 4, Batch: 344, Loss: 0.013383639976382256\n",
      "Epoch: 4, Batch: 345, Loss: 0.006913910154253244\n",
      "Epoch: 4, Batch: 346, Loss: 0.03588179498910904\n",
      "Epoch: 4, Batch: 347, Loss: 0.11341346800327301\n",
      "Epoch: 4, Batch: 348, Loss: 0.027809714898467064\n",
      "Epoch: 4, Batch: 349, Loss: 0.0040283966809511185\n",
      "Epoch: 4, Batch: 350, Loss: 0.002817159751430154\n",
      "Epoch: 4, Batch: 351, Loss: 0.0020755957812070847\n",
      "Epoch: 4, Batch: 352, Loss: 0.012872930616140366\n",
      "Epoch: 4, Batch: 353, Loss: 0.04309232160449028\n",
      "Epoch: 4, Batch: 354, Loss: 0.041512392461299896\n",
      "Epoch: 4, Batch: 355, Loss: 0.008440221659839153\n",
      "Epoch: 4, Batch: 356, Loss: 0.012975570745766163\n",
      "Epoch: 4, Batch: 357, Loss: 0.00891686137765646\n",
      "Epoch: 4, Batch: 358, Loss: 0.05346860736608505\n",
      "Epoch: 4, Batch: 359, Loss: 0.010585568845272064\n",
      "Epoch: 4, Batch: 360, Loss: 0.023026565089821815\n",
      "Epoch: 4, Batch: 361, Loss: 0.022666042670607567\n",
      "Epoch: 4, Batch: 362, Loss: 0.004584184847772121\n",
      "Epoch: 4, Batch: 363, Loss: 0.10767257958650589\n",
      "Epoch: 4, Batch: 364, Loss: 0.0006178650655783713\n",
      "Epoch: 4, Batch: 365, Loss: 0.012773193418979645\n",
      "Epoch: 4, Batch: 366, Loss: 0.12775778770446777\n",
      "Epoch: 4, Batch: 367, Loss: 0.033420950174331665\n",
      "Epoch: 4, Batch: 368, Loss: 0.08715838938951492\n",
      "Epoch: 4, Batch: 369, Loss: 0.007613603491336107\n",
      "Epoch: 4, Batch: 370, Loss: 0.009997114539146423\n",
      "Epoch: 4, Batch: 371, Loss: 0.017680997028946877\n",
      "Epoch: 4, Batch: 372, Loss: 0.008144475519657135\n",
      "Epoch: 4, Batch: 373, Loss: 0.00275370292365551\n",
      "Epoch: 4, Batch: 374, Loss: 0.0034273320343345404\n",
      "Epoch: 4, Batch: 375, Loss: 0.020564541220664978\n",
      "Epoch: 4, Batch: 376, Loss: 0.006783558055758476\n",
      "Epoch: 4, Batch: 377, Loss: 0.0036761111114174128\n",
      "Epoch: 4, Batch: 378, Loss: 0.008698931895196438\n",
      "Epoch: 4, Batch: 379, Loss: 0.0028225425630807877\n",
      "Epoch: 4, Batch: 380, Loss: 0.0025586970150470734\n",
      "Epoch: 4, Batch: 381, Loss: 0.01537630520761013\n",
      "Epoch: 4, Batch: 382, Loss: 0.027521587908267975\n",
      "Epoch: 4, Batch: 383, Loss: 0.016972262412309647\n",
      "Epoch: 4, Batch: 384, Loss: 0.04267127811908722\n",
      "Epoch: 4, Batch: 385, Loss: 0.01691926270723343\n",
      "Epoch: 4, Batch: 386, Loss: 0.004146322142332792\n",
      "Epoch: 4, Batch: 387, Loss: 0.010194572620093822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Batch: 388, Loss: 0.007819081656634808\n",
      "Epoch: 4, Batch: 389, Loss: 0.05326426774263382\n",
      "Epoch: 4, Batch: 390, Loss: 0.04186528921127319\n",
      "Epoch: 4, Batch: 391, Loss: 0.010927385650575161\n",
      "Epoch: 4, Batch: 392, Loss: 0.020850498229265213\n",
      "Epoch: 4, Batch: 393, Loss: 0.05754349008202553\n",
      "Epoch: 4, Batch: 394, Loss: 0.03156900778412819\n",
      "Epoch: 4, Batch: 395, Loss: 0.0058869607746601105\n",
      "Epoch: 4, Batch: 396, Loss: 0.0007363542099483311\n",
      "Epoch: 4, Batch: 397, Loss: 0.010521739721298218\n",
      "Epoch: 4, Batch: 398, Loss: 0.007692029234021902\n",
      "Epoch: 4, Batch: 399, Loss: 0.0063488376326859\n",
      "Epoch: 4, Batch: 400, Loss: 0.12157467007637024\n",
      "Epoch: 4, Batch: 401, Loss: 0.0035345423966646194\n",
      "Epoch: 4, Batch: 402, Loss: 0.0664353147149086\n",
      "Epoch: 4, Batch: 403, Loss: 0.00806201808154583\n",
      "Epoch: 4, Batch: 404, Loss: 0.007802211679518223\n",
      "Epoch: 4, Batch: 405, Loss: 0.02556486427783966\n",
      "Epoch: 4, Batch: 406, Loss: 0.0028836093842983246\n",
      "Epoch: 4, Batch: 407, Loss: 0.054153524339199066\n",
      "Epoch: 4, Batch: 408, Loss: 0.06220404431223869\n",
      "Epoch: 4, Batch: 409, Loss: 0.0009638400515541434\n",
      "Epoch: 4, Batch: 410, Loss: 0.013186929747462273\n",
      "Epoch: 4, Batch: 411, Loss: 0.030831048265099525\n",
      "Epoch: 4, Batch: 412, Loss: 0.008070878684520721\n",
      "Epoch: 4, Batch: 413, Loss: 0.07052375376224518\n",
      "Epoch: 4, Batch: 414, Loss: 0.0028573093004524708\n",
      "Epoch: 4, Batch: 415, Loss: 0.054988715797662735\n",
      "Epoch: 4, Batch: 416, Loss: 0.07513097673654556\n",
      "Epoch: 4, Batch: 417, Loss: 0.001585183315910399\n",
      "Epoch: 4, Batch: 418, Loss: 0.07527048140764236\n",
      "Epoch: 4, Batch: 419, Loss: 0.0015660275239497423\n",
      "Epoch: 4, Batch: 420, Loss: 0.0021067988127470016\n",
      "Epoch: 4, Batch: 421, Loss: 0.05019345507025719\n",
      "Epoch: 4, Batch: 422, Loss: 0.00665616150945425\n",
      "Epoch: 4, Batch: 423, Loss: 0.030709262937307358\n",
      "Epoch: 4, Batch: 424, Loss: 0.1473098248243332\n",
      "Epoch: 4, Batch: 425, Loss: 0.019262252375483513\n",
      "Epoch: 4, Batch: 426, Loss: 0.13126063346862793\n",
      "Epoch: 4, Batch: 427, Loss: 0.008214537054300308\n",
      "Epoch: 4, Batch: 428, Loss: 0.0024373976048082113\n",
      "Epoch: 4, Batch: 429, Loss: 0.047876909375190735\n",
      "Epoch: 4, Batch: 430, Loss: 0.004621456377208233\n",
      "Epoch: 4, Batch: 431, Loss: 0.06183252111077309\n",
      "Epoch: 4, Batch: 432, Loss: 0.045616310089826584\n",
      "Epoch: 4, Batch: 433, Loss: 0.0022777055855840445\n",
      "Epoch: 4, Batch: 434, Loss: 0.029139405116438866\n",
      "Epoch: 4, Batch: 435, Loss: 0.009633013978600502\n",
      "Epoch: 4, Batch: 436, Loss: 0.05495249107480049\n",
      "Epoch: 4, Batch: 437, Loss: 0.005492707248777151\n",
      "Epoch: 4, Batch: 438, Loss: 0.023596134036779404\n",
      "Epoch: 4, Batch: 439, Loss: 0.006626841612160206\n",
      "Epoch: 4, Batch: 440, Loss: 0.009485880844295025\n",
      "Epoch: 4, Batch: 441, Loss: 0.03036109171807766\n",
      "Epoch: 4, Batch: 442, Loss: 0.01900651678442955\n",
      "Epoch: 4, Batch: 443, Loss: 0.009515650570392609\n",
      "Epoch: 4, Batch: 444, Loss: 0.0024532279931008816\n",
      "Epoch: 4, Batch: 445, Loss: 0.0062766848132014275\n",
      "Epoch: 4, Batch: 446, Loss: 0.02724839188158512\n",
      "Epoch: 4, Batch: 447, Loss: 0.010294558480381966\n",
      "Epoch: 4, Batch: 448, Loss: 0.006188170984387398\n",
      "Epoch: 4, Batch: 449, Loss: 0.007307677064090967\n",
      "Epoch: 4, Batch: 450, Loss: 0.016447395086288452\n",
      "Epoch: 4, Batch: 451, Loss: 0.006102816667407751\n",
      "Epoch: 4, Batch: 452, Loss: 0.04202348366379738\n",
      "Epoch: 4, Batch: 453, Loss: 0.031804513186216354\n",
      "Epoch: 4, Batch: 454, Loss: 0.011849918402731419\n",
      "Epoch: 4, Batch: 455, Loss: 0.01701299287378788\n",
      "Epoch: 4, Batch: 456, Loss: 0.037516962736845016\n",
      "Epoch: 4, Batch: 457, Loss: 0.012944789603352547\n",
      "Epoch: 4, Batch: 458, Loss: 0.012126576155424118\n",
      "Epoch: 4, Batch: 459, Loss: 0.005250919610261917\n",
      "Epoch: 4, Batch: 460, Loss: 0.035209424793720245\n",
      "Epoch: 4, Batch: 461, Loss: 0.007145589217543602\n",
      "Epoch: 4, Batch: 462, Loss: 0.001202849205583334\n",
      "Epoch: 4, Batch: 463, Loss: 0.00342067563906312\n",
      "Epoch: 4, Batch: 464, Loss: 0.00958832073956728\n",
      "Epoch: 4, Batch: 465, Loss: 0.0012772055342793465\n",
      "Epoch: 4, Batch: 466, Loss: 0.1296474039554596\n",
      "Epoch: 4, Batch: 467, Loss: 0.0007391522522084415\n",
      "Epoch: 4, Batch: 468, Loss: 0.023848669603466988\n",
      "Epoch: 4, Batch: 469, Loss: 0.003665509633719921\n",
      "Epoch: 4, Batch: 470, Loss: 0.0036945054307579994\n",
      "Epoch: 4, Batch: 471, Loss: 0.0057523176074028015\n",
      "Epoch: 4, Batch: 472, Loss: 0.028628407046198845\n",
      "Epoch: 4, Batch: 473, Loss: 0.13977526128292084\n",
      "Epoch: 4, Batch: 474, Loss: 0.018001161515712738\n",
      "Epoch: 4, Batch: 475, Loss: 0.005147135816514492\n",
      "Epoch: 4, Batch: 476, Loss: 0.009384826757013798\n",
      "Epoch: 4, Batch: 477, Loss: 0.0057543376460671425\n",
      "Epoch: 4, Batch: 478, Loss: 0.02891737036406994\n",
      "Epoch: 4, Batch: 479, Loss: 0.04355921968817711\n",
      "Epoch: 4, Batch: 480, Loss: 0.030401963740587234\n",
      "Epoch: 4, Batch: 481, Loss: 0.0030574421398341656\n",
      "Epoch: 4, Batch: 482, Loss: 0.027568746358156204\n",
      "Epoch: 4, Batch: 483, Loss: 0.013545706868171692\n",
      "Epoch: 4, Batch: 484, Loss: 0.016690924763679504\n",
      "Epoch: 4, Batch: 485, Loss: 0.05506327375769615\n",
      "Epoch: 4, Batch: 486, Loss: 0.0006218061316758394\n",
      "Epoch: 4, Batch: 487, Loss: 0.05993931367993355\n",
      "Epoch: 4, Batch: 488, Loss: 0.009904075413942337\n",
      "Epoch: 4, Batch: 489, Loss: 0.05577655881643295\n",
      "Epoch: 4, Batch: 490, Loss: 0.00468884501606226\n",
      "Epoch: 4, Batch: 491, Loss: 0.022353025153279305\n",
      "Epoch: 4, Batch: 492, Loss: 0.03923119232058525\n",
      "Epoch: 4, Batch: 493, Loss: 0.002983004553243518\n",
      "Epoch: 4, Batch: 494, Loss: 0.018421897664666176\n",
      "Epoch: 4, Batch: 495, Loss: 0.003395569510757923\n",
      "Epoch: 4, Batch: 496, Loss: 0.025810083374381065\n",
      "Epoch: 4, Batch: 497, Loss: 0.003940584138035774\n",
      "Epoch: 4, Batch: 498, Loss: 0.02850732021033764\n",
      "Epoch: 4, Batch: 499, Loss: 0.02026153914630413\n",
      "Epoch: 4, Batch: 500, Loss: 0.05128272622823715\n",
      "Epoch: 4, Batch: 501, Loss: 0.0032986621372401714\n",
      "Epoch: 4, Batch: 502, Loss: 0.005044738296419382\n",
      "Epoch: 4, Batch: 503, Loss: 0.026933547109365463\n",
      "Epoch: 4, Batch: 504, Loss: 0.010529283434152603\n",
      "Epoch: 4, Batch: 505, Loss: 0.04352332651615143\n",
      "Epoch: 4, Batch: 506, Loss: 0.0033785749692469835\n",
      "Epoch: 4, Batch: 507, Loss: 0.006959254387766123\n",
      "Epoch: 4, Batch: 508, Loss: 0.01545021403580904\n",
      "Epoch: 4, Batch: 509, Loss: 0.009790096431970596\n",
      "Epoch: 4, Batch: 510, Loss: 0.05722632259130478\n",
      "Epoch: 4, Batch: 511, Loss: 0.002533109625801444\n",
      "Epoch: 4, Batch: 512, Loss: 0.0659230500459671\n",
      "Epoch: 4, Batch: 513, Loss: 0.004041951149702072\n",
      "Epoch: 4, Batch: 514, Loss: 0.0010057345498353243\n",
      "Epoch: 4, Batch: 515, Loss: 0.0032072016038000584\n",
      "Epoch: 4, Batch: 516, Loss: 0.007846257649362087\n",
      "Epoch: 4, Batch: 517, Loss: 0.03427279740571976\n",
      "Epoch: 4, Batch: 518, Loss: 0.0041703530587255955\n",
      "Epoch: 4, Batch: 519, Loss: 0.059722647070884705\n",
      "Epoch: 4, Batch: 520, Loss: 0.007534750271588564\n",
      "Epoch: 4, Batch: 521, Loss: 0.0013910993002355099\n",
      "Epoch: 4, Batch: 522, Loss: 0.0052631935104727745\n",
      "Epoch: 4, Batch: 523, Loss: 0.00161509751342237\n",
      "Epoch: 4, Batch: 524, Loss: 0.10769660025835037\n",
      "Epoch: 4, Batch: 525, Loss: 0.004646941088140011\n",
      "Epoch: 4, Batch: 526, Loss: 0.057898230850696564\n",
      "Epoch: 4, Batch: 527, Loss: 0.02348640188574791\n",
      "Epoch: 4, Batch: 528, Loss: 0.05267972871661186\n",
      "Epoch: 4, Batch: 529, Loss: 0.020173707976937294\n",
      "Epoch: 4, Batch: 530, Loss: 0.09565488249063492\n",
      "Epoch: 4, Batch: 531, Loss: 0.0035129047464579344\n",
      "Epoch: 4, Batch: 532, Loss: 0.002727365121245384\n",
      "Epoch: 4, Batch: 533, Loss: 0.021173058077692986\n",
      "Epoch: 4, Batch: 534, Loss: 0.004695309326052666\n",
      "Epoch: 4, Batch: 535, Loss: 0.01334943063557148\n",
      "Epoch: 4, Batch: 536, Loss: 0.002211671555414796\n",
      "Epoch: 4, Batch: 537, Loss: 0.061971526592969894\n",
      "Epoch: 4, Batch: 538, Loss: 0.042490154504776\n",
      "Epoch: 4, Batch: 539, Loss: 0.03798333555459976\n",
      "Epoch: 4, Batch: 540, Loss: 0.0020335176959633827\n",
      "Epoch: 4, Batch: 541, Loss: 0.0047850473783910275\n",
      "Epoch: 4, Batch: 542, Loss: 0.007980351336300373\n",
      "Epoch: 4, Batch: 543, Loss: 0.037901975214481354\n",
      "Epoch: 4, Batch: 544, Loss: 0.0007564566913060844\n",
      "Epoch: 4, Batch: 545, Loss: 0.04241563007235527\n",
      "Epoch: 4, Batch: 546, Loss: 0.05540122464299202\n",
      "Epoch: 4, Batch: 547, Loss: 0.050314273685216904\n",
      "Epoch: 4, Batch: 548, Loss: 0.10883236676454544\n",
      "Epoch: 4, Batch: 549, Loss: 0.007114998530596495\n",
      "Epoch: 4, Batch: 550, Loss: 0.0050537255592644215\n",
      "Epoch: 4, Batch: 551, Loss: 0.0037930519320070744\n",
      "Epoch: 4, Batch: 552, Loss: 0.026227718219161034\n",
      "Epoch: 4, Batch: 553, Loss: 0.008375372737646103\n",
      "Epoch: 4, Batch: 554, Loss: 0.0012995004653930664\n",
      "Epoch: 4, Batch: 555, Loss: 0.003395847510546446\n",
      "Epoch: 4, Batch: 556, Loss: 0.05652523413300514\n",
      "Epoch: 4, Batch: 557, Loss: 0.00204727821983397\n",
      "Epoch: 4, Batch: 558, Loss: 0.05629244074225426\n",
      "Epoch: 4, Batch: 559, Loss: 0.02112421579658985\n",
      "Epoch: 4, Batch: 560, Loss: 0.004256377462297678\n",
      "Epoch: 4, Batch: 561, Loss: 0.009008344262838364\n",
      "Epoch: 4, Batch: 562, Loss: 0.00801855605095625\n",
      "Epoch: 4, Batch: 563, Loss: 0.002632874296978116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Batch: 564, Loss: 0.009252810850739479\n",
      "Epoch: 4, Batch: 565, Loss: 0.1187000647187233\n",
      "Epoch: 4, Batch: 566, Loss: 0.026308933272957802\n",
      "Epoch: 4, Batch: 567, Loss: 0.005665399134159088\n",
      "Epoch: 4, Batch: 568, Loss: 0.04689716175198555\n",
      "Epoch: 4, Batch: 569, Loss: 0.009421182796359062\n",
      "Epoch: 4, Batch: 570, Loss: 0.010881332680583\n",
      "Epoch: 4, Batch: 571, Loss: 0.005056746304035187\n",
      "Epoch: 4, Batch: 572, Loss: 0.008152002468705177\n",
      "Epoch: 4, Batch: 573, Loss: 0.008082951419055462\n",
      "Epoch: 4, Batch: 574, Loss: 0.092216357588768\n",
      "Epoch: 4, Batch: 575, Loss: 0.004158872179687023\n",
      "Epoch: 4, Batch: 576, Loss: 0.022494390606880188\n",
      "Epoch: 4, Batch: 577, Loss: 0.04980681464076042\n",
      "Epoch: 4, Batch: 578, Loss: 0.005640729796141386\n",
      "Epoch: 4, Batch: 579, Loss: 0.021259890869259834\n",
      "Epoch: 4, Batch: 580, Loss: 0.00833130907267332\n",
      "Epoch: 4, Batch: 581, Loss: 0.012703838758170605\n",
      "Epoch: 4, Batch: 582, Loss: 0.02895636484026909\n",
      "Epoch: 4, Batch: 583, Loss: 0.029962090775370598\n",
      "Epoch: 4, Batch: 584, Loss: 0.08465118706226349\n",
      "Epoch: 4, Batch: 585, Loss: 0.046841852366924286\n",
      "Epoch: 4, Batch: 586, Loss: 0.10848885029554367\n",
      "Epoch: 4, Batch: 587, Loss: 0.07058633118867874\n",
      "Epoch: 4, Batch: 588, Loss: 0.017693115398287773\n",
      "Epoch: 4, Batch: 589, Loss: 0.020686950534582138\n",
      "Epoch: 4, Batch: 590, Loss: 0.0028532452415674925\n",
      "Epoch: 4, Batch: 591, Loss: 0.006083544343709946\n",
      "Epoch: 4, Batch: 592, Loss: 0.007114435080438852\n",
      "Epoch: 4, Batch: 593, Loss: 0.021685078740119934\n",
      "Epoch: 4, Batch: 594, Loss: 0.12643963098526\n",
      "Epoch: 4, Batch: 595, Loss: 0.002454144414514303\n",
      "Epoch: 4, Batch: 596, Loss: 0.02499246411025524\n",
      "Epoch: 4, Batch: 597, Loss: 0.11886067688465118\n",
      "Epoch: 4, Batch: 598, Loss: 0.010232723318040371\n",
      "Epoch: 4, Batch: 599, Loss: 0.008487576618790627\n",
      "Epoch: 4, Batch: 600, Loss: 0.005168653558939695\n",
      "Epoch: 4, Batch: 601, Loss: 0.005921626463532448\n",
      "Epoch: 4, Batch: 602, Loss: 0.001734845689497888\n",
      "Epoch: 4, Batch: 603, Loss: 0.004052197560667992\n",
      "Epoch: 4, Batch: 604, Loss: 0.00371678383089602\n",
      "Epoch: 4, Batch: 605, Loss: 0.006977538112550974\n",
      "Epoch: 4, Batch: 606, Loss: 0.052440863102674484\n",
      "Epoch: 4, Batch: 607, Loss: 0.008319633081555367\n",
      "Epoch: 4, Batch: 608, Loss: 0.056681424379348755\n",
      "Epoch: 4, Batch: 609, Loss: 0.01925765536725521\n",
      "Epoch: 4, Batch: 610, Loss: 0.0015755998902022839\n",
      "Epoch: 4, Batch: 611, Loss: 0.008196530863642693\n",
      "Epoch: 4, Batch: 612, Loss: 0.0034034578129649162\n",
      "Epoch: 4, Batch: 613, Loss: 0.01714232563972473\n",
      "Epoch: 4, Batch: 614, Loss: 0.0007713959203101695\n",
      "Epoch: 4, Batch: 615, Loss: 0.019541045650839806\n",
      "Epoch: 4, Batch: 616, Loss: 0.04435937479138374\n",
      "Epoch: 4, Batch: 617, Loss: 0.04383820295333862\n",
      "Epoch: 4, Batch: 618, Loss: 0.00363610265776515\n",
      "Epoch: 4, Batch: 619, Loss: 0.003983637318015099\n",
      "Epoch: 4, Batch: 620, Loss: 0.006048313807696104\n",
      "Epoch: 4, Batch: 621, Loss: 0.015682868659496307\n",
      "Epoch: 4, Batch: 622, Loss: 0.001837582211010158\n",
      "Epoch: 4, Batch: 623, Loss: 0.006942116189748049\n",
      "Epoch: 4, Batch: 624, Loss: 0.0403938814997673\n",
      "Epoch: 4, Batch: 625, Loss: 0.00232368940487504\n",
      "Epoch: 4, Batch: 626, Loss: 0.011250403709709644\n",
      "Epoch: 4, Batch: 627, Loss: 0.004320225212723017\n",
      "Epoch: 4, Batch: 628, Loss: 0.009913930669426918\n",
      "Epoch: 4, Batch: 629, Loss: 0.005520012695342302\n",
      "Epoch: 4, Batch: 630, Loss: 0.004418495111167431\n",
      "Epoch: 4, Batch: 631, Loss: 0.08999235183000565\n",
      "Epoch: 4, Batch: 632, Loss: 0.006299155298620462\n",
      "Epoch: 4, Batch: 633, Loss: 0.005664628930389881\n",
      "Epoch: 4, Batch: 634, Loss: 0.01043098047375679\n",
      "Epoch: 4, Batch: 635, Loss: 0.020178237929940224\n",
      "Epoch: 4, Batch: 636, Loss: 0.04332892596721649\n",
      "Epoch: 4, Batch: 637, Loss: 0.051061879843473434\n",
      "Epoch: 4, Batch: 638, Loss: 0.00512737687677145\n",
      "Epoch: 4, Batch: 639, Loss: 0.038043148815631866\n",
      "Epoch: 4, Batch: 640, Loss: 0.006391041912138462\n",
      "Epoch: 4, Batch: 641, Loss: 0.10413431376218796\n",
      "Epoch: 4, Batch: 642, Loss: 0.004092828836292028\n",
      "Epoch: 4, Batch: 643, Loss: 0.002756671514362097\n",
      "Epoch: 4, Batch: 644, Loss: 0.009389298036694527\n",
      "Epoch: 4, Batch: 645, Loss: 0.027434783056378365\n",
      "Epoch: 4, Batch: 646, Loss: 0.060184232890605927\n",
      "Epoch: 4, Batch: 647, Loss: 0.005055378191173077\n",
      "Epoch: 4, Batch: 648, Loss: 0.005837833043187857\n",
      "Epoch: 4, Batch: 649, Loss: 0.0025155062321573496\n",
      "Epoch: 4, Batch: 650, Loss: 0.0007317668641917408\n",
      "Epoch: 4, Batch: 651, Loss: 0.001591233303770423\n",
      "Epoch: 4, Batch: 652, Loss: 0.08135535567998886\n",
      "Epoch: 4, Batch: 653, Loss: 0.09717907011508942\n",
      "Epoch: 4, Batch: 654, Loss: 0.11235280334949493\n",
      "Epoch: 4, Batch: 655, Loss: 0.0009164712973870337\n",
      "Epoch: 4, Batch: 656, Loss: 0.027713118121027946\n",
      "Epoch: 4, Batch: 657, Loss: 0.0022132056765258312\n",
      "Epoch: 4, Batch: 658, Loss: 0.020903287455439568\n",
      "Epoch: 4, Batch: 659, Loss: 0.005606202874332666\n",
      "Epoch: 4, Batch: 660, Loss: 0.04407462477684021\n",
      "Epoch: 4, Batch: 661, Loss: 0.002309732837602496\n",
      "Epoch: 4, Batch: 662, Loss: 0.06593912094831467\n",
      "Epoch: 4, Batch: 663, Loss: 0.005942103452980518\n",
      "Epoch: 4, Batch: 664, Loss: 0.0044619617983698845\n",
      "Epoch: 4, Batch: 665, Loss: 0.01787544973194599\n",
      "Epoch: 4, Batch: 666, Loss: 0.0007010928820818663\n",
      "Epoch: 4, Batch: 667, Loss: 0.013906539417803288\n",
      "Epoch: 4, Batch: 668, Loss: 0.005696597509086132\n",
      "Epoch: 4, Batch: 669, Loss: 0.034934185445308685\n",
      "Epoch: 4, Batch: 670, Loss: 0.060361314564943314\n",
      "Epoch: 4, Batch: 671, Loss: 0.11339832097291946\n",
      "Epoch: 4, Batch: 672, Loss: 0.012518680654466152\n",
      "Epoch: 4, Batch: 673, Loss: 0.00835377722978592\n",
      "Epoch: 4, Batch: 674, Loss: 0.08738750219345093\n",
      "Epoch: 4, Batch: 675, Loss: 0.010314779356122017\n",
      "Epoch: 4, Batch: 676, Loss: 0.01308398973196745\n",
      "Epoch: 4, Batch: 677, Loss: 0.015830714255571365\n",
      "Epoch: 4, Batch: 678, Loss: 0.002890584524720907\n",
      "Epoch: 4, Batch: 679, Loss: 0.009701602160930634\n",
      "Epoch: 4, Batch: 680, Loss: 0.0005236306460574269\n",
      "Epoch: 4, Batch: 681, Loss: 0.00914901401847601\n",
      "Epoch: 4, Batch: 682, Loss: 0.022076966241002083\n",
      "Epoch: 4, Batch: 683, Loss: 0.07734280824661255\n",
      "Epoch: 4, Batch: 684, Loss: 0.0030201647896319628\n",
      "Epoch: 4, Batch: 685, Loss: 0.027629675343632698\n",
      "Epoch: 4, Batch: 686, Loss: 0.0376865416765213\n",
      "Epoch: 4, Batch: 687, Loss: 0.015813522040843964\n",
      "Epoch: 4, Batch: 688, Loss: 0.047125112265348434\n",
      "Epoch: 4, Batch: 689, Loss: 0.07539604604244232\n",
      "Epoch: 4, Batch: 690, Loss: 0.002213150728493929\n",
      "Epoch: 4, Batch: 691, Loss: 0.006288651376962662\n",
      "Epoch: 4, Batch: 692, Loss: 0.03037683479487896\n",
      "Epoch: 4, Batch: 693, Loss: 0.015185859054327011\n",
      "Epoch: 4, Batch: 694, Loss: 0.024355309084057808\n",
      "Epoch: 4, Batch: 695, Loss: 0.01627451926469803\n",
      "Epoch: 4, Batch: 696, Loss: 0.04743783175945282\n",
      "Epoch: 4, Batch: 697, Loss: 0.011987295933067799\n",
      "Epoch: 4, Batch: 698, Loss: 0.012557712383568287\n",
      "Epoch: 4, Batch: 699, Loss: 0.02240326628088951\n",
      "Epoch: 4, Batch: 700, Loss: 0.05564925819635391\n",
      "Epoch: 4, Batch: 701, Loss: 0.023224253207445145\n",
      "Epoch: 4, Batch: 702, Loss: 0.011630685068666935\n",
      "Epoch: 4, Batch: 703, Loss: 0.009994755499064922\n",
      "Epoch: 4, Batch: 704, Loss: 0.1099521666765213\n",
      "Epoch: 4, Batch: 705, Loss: 0.0019834241829812527\n",
      "Epoch: 4, Batch: 706, Loss: 0.2817521393299103\n",
      "Epoch: 4, Batch: 707, Loss: 0.0781780481338501\n",
      "Epoch: 4, Batch: 708, Loss: 0.007957841269671917\n",
      "Epoch: 4, Batch: 709, Loss: 0.014148537069559097\n",
      "Epoch: 4, Batch: 710, Loss: 0.05769845470786095\n",
      "Epoch: 4, Batch: 711, Loss: 0.010869082063436508\n",
      "Epoch: 4, Batch: 712, Loss: 0.1538039743900299\n",
      "Epoch: 4, Batch: 713, Loss: 0.006225884426385164\n",
      "Epoch: 4, Batch: 714, Loss: 0.010162217542529106\n",
      "Epoch: 4, Batch: 715, Loss: 0.02724965289235115\n",
      "Epoch: 4, Batch: 716, Loss: 0.002264103852212429\n",
      "Epoch: 4, Batch: 717, Loss: 0.005976683460175991\n",
      "Epoch: 4, Batch: 718, Loss: 0.016401853412389755\n",
      "Epoch: 4, Batch: 719, Loss: 0.01572059653699398\n",
      "Epoch: 4, Batch: 720, Loss: 0.003687226912006736\n",
      "Epoch: 4, Batch: 721, Loss: 0.008413718082010746\n",
      "Epoch: 4, Batch: 722, Loss: 0.021626895293593407\n",
      "Epoch: 4, Batch: 723, Loss: 0.0034919497556984425\n",
      "Epoch: 4, Batch: 724, Loss: 0.03563226759433746\n",
      "Epoch: 4, Batch: 725, Loss: 0.031088992953300476\n",
      "Epoch: 4, Batch: 726, Loss: 0.012590032070875168\n",
      "Epoch: 4, Batch: 727, Loss: 0.008078992366790771\n",
      "Epoch: 4, Batch: 728, Loss: 0.017686277627944946\n",
      "Epoch: 4, Batch: 729, Loss: 0.0021415194496512413\n",
      "Epoch: 4, Batch: 730, Loss: 0.030031686648726463\n",
      "Epoch: 4, Batch: 731, Loss: 0.004833604209125042\n",
      "Epoch: 4, Batch: 732, Loss: 0.008042732253670692\n",
      "Epoch: 4, Batch: 733, Loss: 0.009318430908024311\n",
      "Epoch: 4, Batch: 734, Loss: 0.0043083433993160725\n",
      "Epoch: 4, Batch: 735, Loss: 0.06601983308792114\n",
      "Epoch: 4, Batch: 736, Loss: 0.01602613553404808\n",
      "Epoch: 4, Batch: 737, Loss: 0.011175240390002728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Batch: 738, Loss: 0.036758337169885635\n",
      "Epoch: 4, Batch: 739, Loss: 0.0038392203859984875\n",
      "Epoch: 4, Batch: 740, Loss: 0.0028411964885890484\n",
      "Epoch: 4, Batch: 741, Loss: 0.010255865752696991\n",
      "Epoch: 4, Batch: 742, Loss: 0.02977306768298149\n",
      "Epoch: 4, Batch: 743, Loss: 0.02624165453016758\n",
      "Epoch: 4, Batch: 744, Loss: 0.04120256379246712\n",
      "Epoch: 4, Batch: 745, Loss: 0.009013120085000992\n",
      "Epoch: 4, Batch: 746, Loss: 0.02354479394853115\n",
      "Epoch: 4, Batch: 747, Loss: 0.03317931666970253\n",
      "Epoch: 4, Batch: 748, Loss: 0.04337258264422417\n",
      "Epoch: 4, Batch: 749, Loss: 0.008846534416079521\n",
      "Epoch: 4, Batch: 750, Loss: 0.015085543505847454\n",
      "Epoch: 4, Batch: 751, Loss: 0.006727076601237059\n",
      "Epoch: 4, Batch: 752, Loss: 0.026962880045175552\n",
      "Epoch: 4, Batch: 753, Loss: 0.00980850774794817\n",
      "Epoch: 4, Batch: 754, Loss: 0.0015148692764341831\n",
      "Epoch: 4, Batch: 755, Loss: 0.002887218026444316\n",
      "Epoch: 4, Batch: 756, Loss: 0.09629181772470474\n",
      "Epoch: 4, Batch: 757, Loss: 0.058624301105737686\n",
      "Epoch: 4, Batch: 758, Loss: 0.011902936734259129\n",
      "Epoch: 4, Batch: 759, Loss: 0.0031107862014323473\n",
      "Epoch: 4, Batch: 760, Loss: 0.031961217522621155\n",
      "Epoch: 4, Batch: 761, Loss: 0.003285606624558568\n",
      "Epoch: 4, Batch: 762, Loss: 0.002287432551383972\n",
      "Epoch: 4, Batch: 763, Loss: 0.029558733105659485\n",
      "Epoch: 4, Batch: 764, Loss: 0.035965707153081894\n",
      "Epoch: 4, Batch: 765, Loss: 0.01483349222689867\n",
      "Epoch: 4, Batch: 766, Loss: 0.04674253985285759\n",
      "Epoch: 4, Batch: 767, Loss: 0.023808985948562622\n",
      "Epoch: 4, Batch: 768, Loss: 0.10068709403276443\n",
      "Epoch: 4, Batch: 769, Loss: 0.013114805333316326\n",
      "Epoch: 4, Batch: 770, Loss: 0.008881897665560246\n",
      "Epoch: 4, Batch: 771, Loss: 0.0010881760390475392\n",
      "Epoch: 4, Batch: 772, Loss: 0.02400822564959526\n",
      "Epoch: 4, Batch: 773, Loss: 0.0848187729716301\n",
      "Epoch: 4, Batch: 774, Loss: 0.10652972757816315\n",
      "Epoch: 4, Batch: 775, Loss: 0.029147379100322723\n",
      "Epoch: 4, Batch: 776, Loss: 0.038862474262714386\n",
      "Epoch: 4, Batch: 777, Loss: 0.008703170344233513\n",
      "Epoch: 4, Batch: 778, Loss: 0.01051854807883501\n",
      "Epoch: 4, Batch: 779, Loss: 0.01024017296731472\n",
      "Epoch: 4, Batch: 780, Loss: 0.01540939137339592\n",
      "Epoch: 4, Batch: 781, Loss: 0.0035857255570590496\n",
      "Epoch: 4, Batch: 782, Loss: 0.0030730292201042175\n",
      "Epoch: 4, Batch: 783, Loss: 0.048863284289836884\n",
      "Epoch: 4, Batch: 784, Loss: 0.12566232681274414\n",
      "Epoch: 4, Batch: 785, Loss: 0.02155713550746441\n",
      "Epoch: 4, Batch: 786, Loss: 0.009836745448410511\n",
      "Epoch: 4, Batch: 787, Loss: 0.0010373421246185899\n",
      "Epoch: 4, Batch: 788, Loss: 0.009516781195998192\n",
      "Epoch: 4, Batch: 789, Loss: 0.004557282198220491\n",
      "Epoch: 4, Batch: 790, Loss: 0.029567038640379906\n",
      "Epoch: 4, Batch: 791, Loss: 0.020900074392557144\n",
      "Epoch: 4, Batch: 792, Loss: 0.03501353785395622\n",
      "Epoch: 4, Batch: 793, Loss: 0.015261221677064896\n",
      "Epoch: 4, Batch: 794, Loss: 0.07415299862623215\n",
      "Epoch: 4, Batch: 795, Loss: 0.0037336177192628384\n",
      "Epoch: 4, Batch: 796, Loss: 0.0217738077044487\n",
      "Epoch: 4, Batch: 797, Loss: 0.0058240341022610664\n",
      "Epoch: 4, Batch: 798, Loss: 0.004688977263867855\n",
      "Epoch: 4, Batch: 799, Loss: 0.01592039130628109\n",
      "Epoch: 4, Batch: 800, Loss: 0.06502217054367065\n",
      "Epoch: 4, Batch: 801, Loss: 0.001506939297541976\n",
      "Epoch: 4, Batch: 802, Loss: 0.003660587826743722\n",
      "Epoch: 4, Batch: 803, Loss: 0.03279395401477814\n",
      "Epoch: 4, Batch: 804, Loss: 0.02862609550356865\n",
      "Epoch: 4, Batch: 805, Loss: 0.013014847412705421\n",
      "Epoch: 4, Batch: 806, Loss: 0.003796547884121537\n",
      "Epoch: 4, Batch: 807, Loss: 0.008103681728243828\n",
      "Epoch: 4, Batch: 808, Loss: 0.015196459367871284\n",
      "Epoch: 4, Batch: 809, Loss: 0.10207416117191315\n",
      "Epoch: 4, Batch: 810, Loss: 0.007042378187179565\n",
      "Epoch: 4, Batch: 811, Loss: 0.17739762365818024\n",
      "Epoch: 4, Batch: 812, Loss: 0.06427522748708725\n",
      "Epoch: 4, Batch: 813, Loss: 0.11194691061973572\n",
      "Epoch: 4, Batch: 814, Loss: 0.03541499003767967\n",
      "Epoch: 4, Batch: 815, Loss: 0.0055215316824615\n",
      "Epoch: 4, Batch: 816, Loss: 0.00444014323875308\n",
      "Epoch: 4, Batch: 817, Loss: 0.005409654229879379\n",
      "Epoch: 4, Batch: 818, Loss: 0.00614123372361064\n",
      "Epoch: 4, Batch: 819, Loss: 0.01121886819601059\n",
      "Epoch: 4, Batch: 820, Loss: 0.02052745595574379\n",
      "Epoch: 4, Batch: 821, Loss: 0.028978005051612854\n",
      "Epoch: 4, Batch: 822, Loss: 0.09451501816511154\n",
      "Epoch: 4, Batch: 823, Loss: 0.07717698067426682\n",
      "Epoch: 4, Batch: 824, Loss: 0.0008759378106333315\n",
      "Epoch: 4, Batch: 825, Loss: 0.0756133571267128\n",
      "Epoch: 4, Batch: 826, Loss: 0.007162376306951046\n",
      "Epoch: 4, Batch: 827, Loss: 0.016737177968025208\n",
      "Epoch: 4, Batch: 828, Loss: 0.05056067183613777\n",
      "Epoch: 4, Batch: 829, Loss: 0.043671637773513794\n",
      "Epoch: 4, Batch: 830, Loss: 0.01739652454853058\n",
      "Epoch: 4, Batch: 831, Loss: 0.007762422319501638\n",
      "Epoch: 4, Batch: 832, Loss: 0.017942868173122406\n",
      "Epoch: 4, Batch: 833, Loss: 0.009794223122298717\n",
      "Epoch: 4, Batch: 834, Loss: 0.02641594596207142\n",
      "Epoch: 4, Batch: 835, Loss: 0.016161320731043816\n",
      "Epoch: 4, Batch: 836, Loss: 0.008561207912862301\n",
      "Epoch: 4, Batch: 837, Loss: 0.0027136094868183136\n",
      "Epoch: 4, Batch: 838, Loss: 0.010914437472820282\n",
      "Epoch: 4, Batch: 839, Loss: 0.08302506804466248\n",
      "Epoch: 4, Batch: 840, Loss: 0.0029186783358454704\n",
      "Epoch: 4, Batch: 841, Loss: 0.0011517409002408385\n",
      "Epoch: 4, Batch: 842, Loss: 0.16257010400295258\n",
      "Epoch: 4, Batch: 843, Loss: 0.003509160364046693\n",
      "Epoch: 4, Batch: 844, Loss: 0.0073838140815496445\n",
      "Epoch: 4, Batch: 845, Loss: 0.0002792897284962237\n",
      "Epoch: 4, Batch: 846, Loss: 0.001198653131723404\n",
      "Epoch: 4, Batch: 847, Loss: 0.0033905399031937122\n",
      "Epoch: 4, Batch: 848, Loss: 0.01416084822267294\n",
      "Epoch: 4, Batch: 849, Loss: 0.014944138936698437\n",
      "Epoch: 4, Batch: 850, Loss: 0.0002026070433203131\n",
      "Epoch: 4, Batch: 851, Loss: 0.002656602533534169\n",
      "Epoch: 4, Batch: 852, Loss: 0.0545453280210495\n",
      "Epoch: 4, Batch: 853, Loss: 0.024466782808303833\n",
      "Epoch: 4, Batch: 854, Loss: 0.011718288995325565\n",
      "Epoch: 4, Batch: 855, Loss: 0.015831053256988525\n",
      "Epoch: 4, Batch: 856, Loss: 0.002043203916400671\n",
      "Epoch: 4, Batch: 857, Loss: 0.011069400236010551\n",
      "Epoch: 4, Batch: 858, Loss: 0.007252341136336327\n",
      "Epoch: 4, Batch: 859, Loss: 0.01215930562466383\n",
      "Epoch: 4, Batch: 860, Loss: 0.006242708303034306\n",
      "Epoch: 4, Batch: 861, Loss: 0.0008143690647557378\n",
      "Epoch: 4, Batch: 862, Loss: 0.01825093850493431\n",
      "Epoch: 4, Batch: 863, Loss: 0.0022191295865923166\n",
      "Epoch: 4, Batch: 864, Loss: 0.0072159543633461\n",
      "Epoch: 4, Batch: 865, Loss: 0.0024447741452604532\n",
      "Epoch: 4, Batch: 866, Loss: 0.018650539219379425\n",
      "Epoch: 4, Batch: 867, Loss: 0.024296080693602562\n",
      "Epoch: 4, Batch: 868, Loss: 0.002315661869943142\n",
      "Epoch: 4, Batch: 869, Loss: 0.0012571136467158794\n",
      "Epoch: 4, Batch: 870, Loss: 0.0018023865995928645\n",
      "Epoch: 4, Batch: 871, Loss: 0.037125393748283386\n",
      "Epoch: 4, Batch: 872, Loss: 0.021986432373523712\n",
      "Epoch: 4, Batch: 873, Loss: 0.0007813277188688517\n",
      "Epoch: 4, Batch: 874, Loss: 0.018569007515907288\n",
      "Epoch: 4, Batch: 875, Loss: 0.10634732246398926\n",
      "Epoch: 4, Batch: 876, Loss: 0.0013950372813269496\n",
      "Epoch: 4, Batch: 877, Loss: 0.010618462227284908\n",
      "Epoch: 4, Batch: 878, Loss: 0.01703711971640587\n",
      "Epoch: 4, Batch: 879, Loss: 0.011458247900009155\n",
      "Epoch: 4, Batch: 880, Loss: 0.03293093666434288\n",
      "Epoch: 4, Batch: 881, Loss: 0.0063848113641142845\n",
      "Epoch: 4, Batch: 882, Loss: 0.0035943291150033474\n",
      "Epoch: 4, Batch: 883, Loss: 0.02814655937254429\n",
      "Epoch: 4, Batch: 884, Loss: 0.0016305944882333279\n",
      "Epoch: 4, Batch: 885, Loss: 0.0585620142519474\n",
      "Epoch: 4, Batch: 886, Loss: 0.0009007417829707265\n",
      "Epoch: 4, Batch: 887, Loss: 0.010909742675721645\n",
      "Epoch: 4, Batch: 888, Loss: 0.022167151793837547\n",
      "Epoch: 4, Batch: 889, Loss: 0.0024450330529361963\n",
      "Epoch: 4, Batch: 890, Loss: 0.00038638044497929513\n",
      "Epoch: 4, Batch: 891, Loss: 0.016922861337661743\n",
      "Epoch: 4, Batch: 892, Loss: 0.0002185455959988758\n",
      "Epoch: 4, Batch: 893, Loss: 0.005386849399656057\n",
      "Epoch: 4, Batch: 894, Loss: 0.0012853790540248156\n",
      "Epoch: 4, Batch: 895, Loss: 0.007400345057249069\n",
      "Epoch: 4, Batch: 896, Loss: 0.0289610568434\n",
      "Epoch: 4, Batch: 897, Loss: 0.008734120056033134\n",
      "Epoch: 4, Batch: 898, Loss: 0.024440350010991096\n",
      "Epoch: 4, Batch: 899, Loss: 0.004405722953379154\n",
      "Epoch: 4, Batch: 900, Loss: 0.045356083661317825\n",
      "Epoch: 4, Batch: 901, Loss: 0.0014096980448812246\n",
      "Epoch: 4, Batch: 902, Loss: 0.018468936905264854\n",
      "Epoch: 4, Batch: 903, Loss: 0.04905882477760315\n",
      "Epoch: 4, Batch: 904, Loss: 0.0019907651003450155\n",
      "Epoch: 4, Batch: 905, Loss: 0.007656881585717201\n",
      "Epoch: 4, Batch: 906, Loss: 0.02151876501739025\n",
      "Epoch: 4, Batch: 907, Loss: 0.1145421490073204\n",
      "Epoch: 4, Batch: 908, Loss: 0.010333738289773464\n",
      "Epoch: 4, Batch: 909, Loss: 0.00913605373352766\n",
      "Epoch: 4, Batch: 910, Loss: 0.023634012788534164\n",
      "Epoch: 4, Batch: 911, Loss: 0.012737780809402466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Batch: 912, Loss: 0.11257459968328476\n",
      "Epoch: 4, Batch: 913, Loss: 0.026801545172929764\n",
      "Epoch: 4, Batch: 914, Loss: 0.04276429861783981\n",
      "Epoch: 4, Batch: 915, Loss: 0.0030392443295568228\n",
      "Epoch: 4, Batch: 916, Loss: 0.04671671614050865\n",
      "Epoch: 4, Batch: 917, Loss: 0.0023700371384620667\n",
      "Epoch: 4, Batch: 918, Loss: 0.003696268191561103\n",
      "Epoch: 4, Batch: 919, Loss: 4.844012437388301e-05\n",
      "Epoch: 4, Batch: 920, Loss: 0.10058441013097763\n",
      "Epoch: 4, Batch: 921, Loss: 0.016750071197748184\n",
      "Epoch: 4, Batch: 922, Loss: 0.0030651709530502558\n",
      "Epoch: 4, Batch: 923, Loss: 0.014398266561329365\n",
      "Epoch: 4, Batch: 924, Loss: 0.006347192917019129\n",
      "Epoch: 4, Batch: 925, Loss: 0.1722460687160492\n",
      "Epoch: 4, Batch: 926, Loss: 0.034787196666002274\n",
      "Epoch: 4, Batch: 927, Loss: 0.04952193796634674\n",
      "Epoch: 4, Batch: 928, Loss: 0.020827580243349075\n",
      "Epoch: 4, Batch: 929, Loss: 0.0008653925615362823\n",
      "Epoch: 4, Batch: 930, Loss: 0.007808630354702473\n",
      "Epoch: 4, Batch: 931, Loss: 0.001910185907036066\n",
      "Epoch: 4, Batch: 932, Loss: 0.052724845707416534\n",
      "Epoch: 4, Batch: 933, Loss: 0.008485374972224236\n",
      "Epoch: 4, Batch: 934, Loss: 0.03978751227259636\n",
      "Epoch: 4, Batch: 935, Loss: 0.052252430468797684\n",
      "Epoch: 4, Batch: 936, Loss: 0.03861551731824875\n",
      "Epoch: 4, Batch: 937, Loss: 0.0003040665469598025\n",
      "Epoch: 5, Batch: 0, Loss: 0.01705664023756981\n",
      "Epoch: 5, Batch: 1, Loss: 0.025597885251045227\n",
      "Epoch: 5, Batch: 2, Loss: 0.007422196678817272\n",
      "Epoch: 5, Batch: 3, Loss: 0.01932373084127903\n",
      "Epoch: 5, Batch: 4, Loss: 0.0674487054347992\n",
      "Epoch: 5, Batch: 5, Loss: 0.003206824418157339\n",
      "Epoch: 5, Batch: 6, Loss: 0.004632438533008099\n",
      "Epoch: 5, Batch: 7, Loss: 0.05090641975402832\n",
      "Epoch: 5, Batch: 8, Loss: 0.0008471629116684198\n",
      "Epoch: 5, Batch: 9, Loss: 0.03213714063167572\n",
      "Epoch: 5, Batch: 10, Loss: 0.1557949334383011\n",
      "Epoch: 5, Batch: 11, Loss: 0.013875285163521767\n",
      "Epoch: 5, Batch: 12, Loss: 0.08446952700614929\n",
      "Epoch: 5, Batch: 13, Loss: 0.05518298223614693\n",
      "Epoch: 5, Batch: 14, Loss: 0.005395747721195221\n",
      "Epoch: 5, Batch: 15, Loss: 0.04898311570286751\n",
      "Epoch: 5, Batch: 16, Loss: 0.014627693220973015\n",
      "Epoch: 5, Batch: 17, Loss: 0.09310612082481384\n",
      "Epoch: 5, Batch: 18, Loss: 0.002461882308125496\n",
      "Epoch: 5, Batch: 19, Loss: 0.02161836437880993\n",
      "Epoch: 5, Batch: 20, Loss: 0.001925463555380702\n",
      "Epoch: 5, Batch: 21, Loss: 0.005694087594747543\n",
      "Epoch: 5, Batch: 22, Loss: 0.011186252348124981\n",
      "Epoch: 5, Batch: 23, Loss: 0.002842188347131014\n",
      "Epoch: 5, Batch: 24, Loss: 0.0012554182903841138\n",
      "Epoch: 5, Batch: 25, Loss: 0.0020106069277971983\n",
      "Epoch: 5, Batch: 26, Loss: 0.07501337677240372\n",
      "Epoch: 5, Batch: 27, Loss: 0.010076007805764675\n",
      "Epoch: 5, Batch: 28, Loss: 0.00042805049451999366\n",
      "Epoch: 5, Batch: 29, Loss: 0.02964995615184307\n",
      "Epoch: 5, Batch: 30, Loss: 0.0038531236350536346\n",
      "Epoch: 5, Batch: 31, Loss: 0.12553457915782928\n",
      "Epoch: 5, Batch: 32, Loss: 0.0041253394447267056\n",
      "Epoch: 5, Batch: 33, Loss: 0.0013198340311646461\n",
      "Epoch: 5, Batch: 34, Loss: 0.017208157107234\n",
      "Epoch: 5, Batch: 35, Loss: 0.011966348625719547\n",
      "Epoch: 5, Batch: 36, Loss: 0.003178451443091035\n",
      "Epoch: 5, Batch: 37, Loss: 0.007031564600765705\n",
      "Epoch: 5, Batch: 38, Loss: 0.020298348739743233\n",
      "Epoch: 5, Batch: 39, Loss: 0.0029709055088460445\n",
      "Epoch: 5, Batch: 40, Loss: 0.0011555072851479053\n",
      "Epoch: 5, Batch: 41, Loss: 0.01271665096282959\n",
      "Epoch: 5, Batch: 42, Loss: 0.012728026136755943\n",
      "Epoch: 5, Batch: 43, Loss: 0.05785596743226051\n",
      "Epoch: 5, Batch: 44, Loss: 0.0015655211172997952\n",
      "Epoch: 5, Batch: 45, Loss: 0.011397475376725197\n",
      "Epoch: 5, Batch: 46, Loss: 0.04758010804653168\n",
      "Epoch: 5, Batch: 47, Loss: 0.0026410911232233047\n",
      "Epoch: 5, Batch: 48, Loss: 0.005685910116881132\n",
      "Epoch: 5, Batch: 49, Loss: 0.02292071282863617\n",
      "Epoch: 5, Batch: 50, Loss: 0.01666244864463806\n",
      "Epoch: 5, Batch: 51, Loss: 0.0035086562857031822\n",
      "Epoch: 5, Batch: 52, Loss: 0.023281076923012733\n",
      "Epoch: 5, Batch: 53, Loss: 0.0011596066178753972\n",
      "Epoch: 5, Batch: 54, Loss: 0.015086891129612923\n",
      "Epoch: 5, Batch: 55, Loss: 0.0029169886838644743\n",
      "Epoch: 5, Batch: 56, Loss: 0.028365358710289\n",
      "Epoch: 5, Batch: 57, Loss: 0.016921842470765114\n",
      "Epoch: 5, Batch: 58, Loss: 0.004387510474771261\n",
      "Epoch: 5, Batch: 59, Loss: 0.01908694952726364\n",
      "Epoch: 5, Batch: 60, Loss: 0.05881696939468384\n",
      "Epoch: 5, Batch: 61, Loss: 0.00020600826246663928\n",
      "Epoch: 5, Batch: 62, Loss: 0.0016541939694434404\n",
      "Epoch: 5, Batch: 63, Loss: 0.041086163371801376\n",
      "Epoch: 5, Batch: 64, Loss: 0.0040443153120577335\n",
      "Epoch: 5, Batch: 65, Loss: 0.003174528945237398\n",
      "Epoch: 5, Batch: 66, Loss: 0.01526733674108982\n",
      "Epoch: 5, Batch: 67, Loss: 0.004500029608607292\n",
      "Epoch: 5, Batch: 68, Loss: 0.00029935990460217\n",
      "Epoch: 5, Batch: 69, Loss: 0.031037529930472374\n",
      "Epoch: 5, Batch: 70, Loss: 0.04756196588277817\n",
      "Epoch: 5, Batch: 71, Loss: 0.032577306032180786\n",
      "Epoch: 5, Batch: 72, Loss: 0.08656763285398483\n",
      "Epoch: 5, Batch: 73, Loss: 0.04272763431072235\n",
      "Epoch: 5, Batch: 74, Loss: 0.006128367036581039\n",
      "Epoch: 5, Batch: 75, Loss: 0.0033780052326619625\n",
      "Epoch: 5, Batch: 76, Loss: 0.0007872107671573758\n",
      "Epoch: 5, Batch: 77, Loss: 0.033164579421281815\n",
      "Epoch: 5, Batch: 78, Loss: 0.006523459684103727\n",
      "Epoch: 5, Batch: 79, Loss: 0.028409913182258606\n",
      "Epoch: 5, Batch: 80, Loss: 0.011931262910366058\n",
      "Epoch: 5, Batch: 81, Loss: 0.005195240490138531\n",
      "Epoch: 5, Batch: 82, Loss: 0.001279648975469172\n",
      "Epoch: 5, Batch: 83, Loss: 0.012326943688094616\n",
      "Epoch: 5, Batch: 84, Loss: 0.00342938001267612\n",
      "Epoch: 5, Batch: 85, Loss: 0.00197676382958889\n",
      "Epoch: 5, Batch: 86, Loss: 0.02926148660480976\n",
      "Epoch: 5, Batch: 87, Loss: 0.011458388529717922\n",
      "Epoch: 5, Batch: 88, Loss: 0.0023743438068777323\n",
      "Epoch: 5, Batch: 89, Loss: 0.015064436942338943\n",
      "Epoch: 5, Batch: 90, Loss: 0.0236833319067955\n",
      "Epoch: 5, Batch: 91, Loss: 0.013080010190606117\n",
      "Epoch: 5, Batch: 92, Loss: 0.009050502441823483\n",
      "Epoch: 5, Batch: 93, Loss: 0.004330530762672424\n",
      "Epoch: 5, Batch: 94, Loss: 0.006580311805009842\n",
      "Epoch: 5, Batch: 95, Loss: 0.009349174797534943\n",
      "Epoch: 5, Batch: 96, Loss: 0.04650940001010895\n",
      "Epoch: 5, Batch: 97, Loss: 0.0021015172824263573\n",
      "Epoch: 5, Batch: 98, Loss: 0.02584909461438656\n",
      "Epoch: 5, Batch: 99, Loss: 0.02971482090651989\n",
      "Epoch: 5, Batch: 100, Loss: 0.006651123985648155\n",
      "Epoch: 5, Batch: 101, Loss: 0.010503926314413548\n",
      "Epoch: 5, Batch: 102, Loss: 0.0010209843749180436\n",
      "Epoch: 5, Batch: 103, Loss: 0.009924371726810932\n",
      "Epoch: 5, Batch: 104, Loss: 0.0009530220413580537\n",
      "Epoch: 5, Batch: 105, Loss: 0.024519072845578194\n",
      "Epoch: 5, Batch: 106, Loss: 0.0037547352258116007\n",
      "Epoch: 5, Batch: 107, Loss: 0.0015135444700717926\n",
      "Epoch: 5, Batch: 108, Loss: 0.09473916888237\n",
      "Epoch: 5, Batch: 109, Loss: 0.001498158322647214\n",
      "Epoch: 5, Batch: 110, Loss: 0.031839508563280106\n",
      "Epoch: 5, Batch: 111, Loss: 0.007468433119356632\n",
      "Epoch: 5, Batch: 112, Loss: 0.03613368794322014\n",
      "Epoch: 5, Batch: 113, Loss: 0.00641428679227829\n",
      "Epoch: 5, Batch: 114, Loss: 0.08667238056659698\n",
      "Epoch: 5, Batch: 115, Loss: 0.06495468318462372\n",
      "Epoch: 5, Batch: 116, Loss: 0.005182242952287197\n",
      "Epoch: 5, Batch: 117, Loss: 0.01024045329540968\n",
      "Epoch: 5, Batch: 118, Loss: 0.012676545418798923\n",
      "Epoch: 5, Batch: 119, Loss: 0.011446505784988403\n",
      "Epoch: 5, Batch: 120, Loss: 0.031521715223789215\n",
      "Epoch: 5, Batch: 121, Loss: 0.10014468431472778\n",
      "Epoch: 5, Batch: 122, Loss: 0.001101838774047792\n",
      "Epoch: 5, Batch: 123, Loss: 0.08629611134529114\n",
      "Epoch: 5, Batch: 124, Loss: 0.01337941363453865\n",
      "Epoch: 5, Batch: 125, Loss: 0.003871917026117444\n",
      "Epoch: 5, Batch: 126, Loss: 0.0030344990082085133\n",
      "Epoch: 5, Batch: 127, Loss: 0.007244485896080732\n",
      "Epoch: 5, Batch: 128, Loss: 0.001012301305308938\n",
      "Epoch: 5, Batch: 129, Loss: 0.0017800440546125174\n",
      "Epoch: 5, Batch: 130, Loss: 0.029918532818555832\n",
      "Epoch: 5, Batch: 131, Loss: 0.0020678662694990635\n",
      "Epoch: 5, Batch: 132, Loss: 0.018050964921712875\n",
      "Epoch: 5, Batch: 133, Loss: 0.011902330443263054\n",
      "Epoch: 5, Batch: 134, Loss: 0.0018868068000301719\n",
      "Epoch: 5, Batch: 135, Loss: 0.0025994356255978346\n",
      "Epoch: 5, Batch: 136, Loss: 0.011436257511377335\n",
      "Epoch: 5, Batch: 137, Loss: 0.006915871053934097\n",
      "Epoch: 5, Batch: 138, Loss: 0.007549112197011709\n",
      "Epoch: 5, Batch: 139, Loss: 0.004661108832806349\n",
      "Epoch: 5, Batch: 140, Loss: 0.004812042694538832\n",
      "Epoch: 5, Batch: 141, Loss: 0.00702126557007432\n",
      "Epoch: 5, Batch: 142, Loss: 0.024600572884082794\n",
      "Epoch: 5, Batch: 143, Loss: 0.048352375626564026\n",
      "Epoch: 5, Batch: 144, Loss: 0.005712263286113739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Batch: 145, Loss: 0.004907711409032345\n",
      "Epoch: 5, Batch: 146, Loss: 0.06313683837652206\n",
      "Epoch: 5, Batch: 147, Loss: 0.007614759262651205\n",
      "Epoch: 5, Batch: 148, Loss: 0.012426182627677917\n",
      "Epoch: 5, Batch: 149, Loss: 0.04772759974002838\n",
      "Epoch: 5, Batch: 150, Loss: 0.010345948860049248\n",
      "Epoch: 5, Batch: 151, Loss: 0.028930921107530594\n",
      "Epoch: 5, Batch: 152, Loss: 0.008035306818783283\n",
      "Epoch: 5, Batch: 153, Loss: 0.0014538641553372145\n",
      "Epoch: 5, Batch: 154, Loss: 0.004265108145773411\n",
      "Epoch: 5, Batch: 155, Loss: 0.000170215149410069\n",
      "Epoch: 5, Batch: 156, Loss: 0.0022893636487424374\n",
      "Epoch: 5, Batch: 157, Loss: 0.01673583872616291\n",
      "Epoch: 5, Batch: 158, Loss: 0.028064239770174026\n",
      "Epoch: 5, Batch: 159, Loss: 0.0165976844727993\n",
      "Epoch: 5, Batch: 160, Loss: 0.04633244127035141\n",
      "Epoch: 5, Batch: 161, Loss: 0.01999390311539173\n",
      "Epoch: 5, Batch: 162, Loss: 0.001037613837979734\n",
      "Epoch: 5, Batch: 163, Loss: 0.002232889411970973\n",
      "Epoch: 5, Batch: 164, Loss: 0.0027297630440443754\n",
      "Epoch: 5, Batch: 165, Loss: 0.06205575540661812\n",
      "Epoch: 5, Batch: 166, Loss: 0.02378801815211773\n",
      "Epoch: 5, Batch: 167, Loss: 0.027204306796193123\n",
      "Epoch: 5, Batch: 168, Loss: 0.00464613875374198\n",
      "Epoch: 5, Batch: 169, Loss: 0.030884375795722008\n",
      "Epoch: 5, Batch: 170, Loss: 0.004329510033130646\n",
      "Epoch: 5, Batch: 171, Loss: 0.014055801555514336\n",
      "Epoch: 5, Batch: 172, Loss: 0.00033900715061463416\n",
      "Epoch: 5, Batch: 173, Loss: 0.0043996660970151424\n",
      "Epoch: 5, Batch: 174, Loss: 0.04286385700106621\n",
      "Epoch: 5, Batch: 175, Loss: 0.027136221528053284\n",
      "Epoch: 5, Batch: 176, Loss: 0.000946743180975318\n",
      "Epoch: 5, Batch: 177, Loss: 0.0032037198543548584\n",
      "Epoch: 5, Batch: 178, Loss: 0.0018778129015117884\n",
      "Epoch: 5, Batch: 179, Loss: 0.0044067720882594585\n",
      "Epoch: 5, Batch: 180, Loss: 0.024785079061985016\n",
      "Epoch: 5, Batch: 181, Loss: 0.012381479144096375\n",
      "Epoch: 5, Batch: 182, Loss: 0.021928712725639343\n",
      "Epoch: 5, Batch: 183, Loss: 0.0021543996408581734\n",
      "Epoch: 5, Batch: 184, Loss: 9.031783702084795e-05\n",
      "Epoch: 5, Batch: 185, Loss: 0.012031222693622112\n",
      "Epoch: 5, Batch: 186, Loss: 0.00435036513954401\n",
      "Epoch: 5, Batch: 187, Loss: 0.0072891321033239365\n",
      "Epoch: 5, Batch: 188, Loss: 0.006528582889586687\n",
      "Epoch: 5, Batch: 189, Loss: 0.0019840516615659\n",
      "Epoch: 5, Batch: 190, Loss: 0.024327469989657402\n",
      "Epoch: 5, Batch: 191, Loss: 0.006427704822272062\n",
      "Epoch: 5, Batch: 192, Loss: 0.1021939292550087\n",
      "Epoch: 5, Batch: 193, Loss: 0.02564018964767456\n",
      "Epoch: 5, Batch: 194, Loss: 0.0032855381723493338\n",
      "Epoch: 5, Batch: 195, Loss: 0.061832524836063385\n",
      "Epoch: 5, Batch: 196, Loss: 0.0037163535598665476\n",
      "Epoch: 5, Batch: 197, Loss: 0.022720497101545334\n",
      "Epoch: 5, Batch: 198, Loss: 0.0343715101480484\n",
      "Epoch: 5, Batch: 199, Loss: 0.00031531183049082756\n",
      "Epoch: 5, Batch: 200, Loss: 0.011859393678605556\n",
      "Epoch: 5, Batch: 201, Loss: 0.0005027695442549884\n",
      "Epoch: 5, Batch: 202, Loss: 0.019317300990223885\n",
      "Epoch: 5, Batch: 203, Loss: 0.012888492085039616\n",
      "Epoch: 5, Batch: 204, Loss: 0.0016066250391304493\n",
      "Epoch: 5, Batch: 205, Loss: 0.003282801480963826\n",
      "Epoch: 5, Batch: 206, Loss: 0.06532019376754761\n",
      "Epoch: 5, Batch: 207, Loss: 0.0051173316314816475\n",
      "Epoch: 5, Batch: 208, Loss: 0.0385160855948925\n",
      "Epoch: 5, Batch: 209, Loss: 0.022924646735191345\n",
      "Epoch: 5, Batch: 210, Loss: 0.1554749608039856\n",
      "Epoch: 5, Batch: 211, Loss: 0.019667912274599075\n",
      "Epoch: 5, Batch: 212, Loss: 0.005104784853756428\n",
      "Epoch: 5, Batch: 213, Loss: 0.006631770636886358\n",
      "Epoch: 5, Batch: 214, Loss: 0.0015802751295268536\n",
      "Epoch: 5, Batch: 215, Loss: 0.0012475200928747654\n",
      "Epoch: 5, Batch: 216, Loss: 0.044598910957574844\n",
      "Epoch: 5, Batch: 217, Loss: 0.09379494935274124\n",
      "Epoch: 5, Batch: 218, Loss: 0.047090038657188416\n",
      "Epoch: 5, Batch: 219, Loss: 0.007517690770328045\n",
      "Epoch: 5, Batch: 220, Loss: 0.0257402416318655\n",
      "Epoch: 5, Batch: 221, Loss: 0.11451983451843262\n",
      "Epoch: 5, Batch: 222, Loss: 0.012805573642253876\n",
      "Epoch: 5, Batch: 223, Loss: 0.0041844830848276615\n",
      "Epoch: 5, Batch: 224, Loss: 0.0038152241613715887\n",
      "Epoch: 5, Batch: 225, Loss: 0.002857305807992816\n",
      "Epoch: 5, Batch: 226, Loss: 0.023751195520162582\n",
      "Epoch: 5, Batch: 227, Loss: 0.003927936311811209\n",
      "Epoch: 5, Batch: 228, Loss: 0.029844779521226883\n",
      "Epoch: 5, Batch: 229, Loss: 0.00823228433728218\n",
      "Epoch: 5, Batch: 230, Loss: 0.001840494922362268\n",
      "Epoch: 5, Batch: 231, Loss: 0.034885428845882416\n",
      "Epoch: 5, Batch: 232, Loss: 0.0016179705271497369\n",
      "Epoch: 5, Batch: 233, Loss: 0.0386941097676754\n",
      "Epoch: 5, Batch: 234, Loss: 0.019547846168279648\n",
      "Epoch: 5, Batch: 235, Loss: 0.003263555932790041\n",
      "Epoch: 5, Batch: 236, Loss: 0.03439539670944214\n",
      "Epoch: 5, Batch: 237, Loss: 0.0031153743620961905\n",
      "Epoch: 5, Batch: 238, Loss: 0.0015242749359458685\n",
      "Epoch: 5, Batch: 239, Loss: 0.012741470709443092\n",
      "Epoch: 5, Batch: 240, Loss: 0.018874017521739006\n",
      "Epoch: 5, Batch: 241, Loss: 0.06221165508031845\n",
      "Epoch: 5, Batch: 242, Loss: 0.0014788187108933926\n",
      "Epoch: 5, Batch: 243, Loss: 0.008198798634111881\n",
      "Epoch: 5, Batch: 244, Loss: 0.05621933564543724\n",
      "Epoch: 5, Batch: 245, Loss: 0.0057871402241289616\n",
      "Epoch: 5, Batch: 246, Loss: 0.026746436953544617\n",
      "Epoch: 5, Batch: 247, Loss: 0.034307438880205154\n",
      "Epoch: 5, Batch: 248, Loss: 0.0005905518773943186\n",
      "Epoch: 5, Batch: 249, Loss: 0.005524683278053999\n",
      "Epoch: 5, Batch: 250, Loss: 0.0038191124331206083\n",
      "Epoch: 5, Batch: 251, Loss: 0.032388828694820404\n",
      "Epoch: 5, Batch: 252, Loss: 0.011300656944513321\n",
      "Epoch: 5, Batch: 253, Loss: 0.04423462226986885\n",
      "Epoch: 5, Batch: 254, Loss: 0.11015108227729797\n",
      "Epoch: 5, Batch: 255, Loss: 0.07642632722854614\n",
      "Epoch: 5, Batch: 256, Loss: 0.010620892979204655\n",
      "Epoch: 5, Batch: 257, Loss: 0.00353718432597816\n",
      "Epoch: 5, Batch: 258, Loss: 0.02676001377403736\n",
      "Epoch: 5, Batch: 259, Loss: 0.023592963814735413\n",
      "Epoch: 5, Batch: 260, Loss: 0.07792950421571732\n",
      "Epoch: 5, Batch: 261, Loss: 0.0005325346137396991\n",
      "Epoch: 5, Batch: 262, Loss: 0.0031987526454031467\n",
      "Epoch: 5, Batch: 263, Loss: 0.1459047496318817\n",
      "Epoch: 5, Batch: 264, Loss: 0.002893323078751564\n",
      "Epoch: 5, Batch: 265, Loss: 0.0015152785927057266\n",
      "Epoch: 5, Batch: 266, Loss: 0.006441730540245771\n",
      "Epoch: 5, Batch: 267, Loss: 0.001282104873098433\n",
      "Epoch: 5, Batch: 268, Loss: 0.008148026652634144\n",
      "Epoch: 5, Batch: 269, Loss: 0.0050870757550001144\n",
      "Epoch: 5, Batch: 270, Loss: 0.001226794091053307\n",
      "Epoch: 5, Batch: 271, Loss: 0.00018594853463582695\n",
      "Epoch: 5, Batch: 272, Loss: 0.026372335851192474\n",
      "Epoch: 5, Batch: 273, Loss: 0.005439423490315676\n",
      "Epoch: 5, Batch: 274, Loss: 0.009331995621323586\n",
      "Epoch: 5, Batch: 275, Loss: 0.0017818629276007414\n",
      "Epoch: 5, Batch: 276, Loss: 0.006427132058888674\n",
      "Epoch: 5, Batch: 277, Loss: 0.0016608549049124122\n",
      "Epoch: 5, Batch: 278, Loss: 0.09486757218837738\n",
      "Epoch: 5, Batch: 279, Loss: 0.0058433497324585915\n",
      "Epoch: 5, Batch: 280, Loss: 0.0008112873183563352\n",
      "Epoch: 5, Batch: 281, Loss: 0.01258376706391573\n",
      "Epoch: 5, Batch: 282, Loss: 0.032228920608758926\n",
      "Epoch: 5, Batch: 283, Loss: 0.0042183781042695045\n",
      "Epoch: 5, Batch: 284, Loss: 0.004911503754556179\n",
      "Epoch: 5, Batch: 285, Loss: 0.0007965004188008606\n",
      "Epoch: 5, Batch: 286, Loss: 0.08760077506303787\n",
      "Epoch: 5, Batch: 287, Loss: 0.009383407421410084\n",
      "Epoch: 5, Batch: 288, Loss: 0.04214169457554817\n",
      "Epoch: 5, Batch: 289, Loss: 0.0024111836683005095\n",
      "Epoch: 5, Batch: 290, Loss: 0.001534862327389419\n",
      "Epoch: 5, Batch: 291, Loss: 0.0083205197006464\n",
      "Epoch: 5, Batch: 292, Loss: 0.005986116826534271\n",
      "Epoch: 5, Batch: 293, Loss: 0.007520706858485937\n",
      "Epoch: 5, Batch: 294, Loss: 0.00908596720546484\n",
      "Epoch: 5, Batch: 295, Loss: 0.04398088902235031\n",
      "Epoch: 5, Batch: 296, Loss: 0.02821594849228859\n",
      "Epoch: 5, Batch: 297, Loss: 0.0058216070756316185\n",
      "Epoch: 5, Batch: 298, Loss: 0.004241146147251129\n",
      "Epoch: 5, Batch: 299, Loss: 0.015148035250604153\n",
      "Epoch: 5, Batch: 300, Loss: 0.062321435660123825\n",
      "Epoch: 5, Batch: 301, Loss: 0.01951306313276291\n",
      "Epoch: 5, Batch: 302, Loss: 0.0009460928267799318\n",
      "Epoch: 5, Batch: 303, Loss: 0.027765905484557152\n",
      "Epoch: 5, Batch: 304, Loss: 0.05991380289196968\n",
      "Epoch: 5, Batch: 305, Loss: 0.002338864142075181\n",
      "Epoch: 5, Batch: 306, Loss: 0.12354682385921478\n",
      "Epoch: 5, Batch: 307, Loss: 0.03037276118993759\n",
      "Epoch: 5, Batch: 308, Loss: 0.018762880936264992\n",
      "Epoch: 5, Batch: 309, Loss: 0.006405012682080269\n",
      "Epoch: 5, Batch: 310, Loss: 0.013233603909611702\n",
      "Epoch: 5, Batch: 311, Loss: 0.003308243351057172\n",
      "Epoch: 5, Batch: 312, Loss: 0.005847789812833071\n",
      "Epoch: 5, Batch: 313, Loss: 0.03232025355100632\n",
      "Epoch: 5, Batch: 314, Loss: 0.0017607861664146185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Batch: 315, Loss: 0.06330293416976929\n",
      "Epoch: 5, Batch: 316, Loss: 0.0009340049000456929\n",
      "Epoch: 5, Batch: 317, Loss: 0.0017850486328825355\n",
      "Epoch: 5, Batch: 318, Loss: 0.024887125939130783\n",
      "Epoch: 5, Batch: 319, Loss: 0.007520388811826706\n",
      "Epoch: 5, Batch: 320, Loss: 0.0038752895779907703\n",
      "Epoch: 5, Batch: 321, Loss: 0.06094803661108017\n",
      "Epoch: 5, Batch: 322, Loss: 0.030018724501132965\n",
      "Epoch: 5, Batch: 323, Loss: 0.01921641267836094\n",
      "Epoch: 5, Batch: 324, Loss: 0.034299228340387344\n",
      "Epoch: 5, Batch: 325, Loss: 0.003353317966684699\n",
      "Epoch: 5, Batch: 326, Loss: 0.0018500417936593294\n",
      "Epoch: 5, Batch: 327, Loss: 0.015193406492471695\n",
      "Epoch: 5, Batch: 328, Loss: 0.0077361539006233215\n",
      "Epoch: 5, Batch: 329, Loss: 0.0036179707385599613\n",
      "Epoch: 5, Batch: 330, Loss: 0.0165562741458416\n",
      "Epoch: 5, Batch: 331, Loss: 0.004227038938552141\n",
      "Epoch: 5, Batch: 332, Loss: 0.00292764394544065\n",
      "Epoch: 5, Batch: 333, Loss: 0.024890922009944916\n",
      "Epoch: 5, Batch: 334, Loss: 0.0024171776603907347\n",
      "Epoch: 5, Batch: 335, Loss: 0.001435678219422698\n",
      "Epoch: 5, Batch: 336, Loss: 0.005651591811329126\n",
      "Epoch: 5, Batch: 337, Loss: 0.009184205904603004\n",
      "Epoch: 5, Batch: 338, Loss: 0.024294734001159668\n",
      "Epoch: 5, Batch: 339, Loss: 0.011665843427181244\n",
      "Epoch: 5, Batch: 340, Loss: 0.06930369138717651\n",
      "Epoch: 5, Batch: 341, Loss: 0.007229984272271395\n",
      "Epoch: 5, Batch: 342, Loss: 0.06459210813045502\n",
      "Epoch: 5, Batch: 343, Loss: 0.00876516755670309\n",
      "Epoch: 5, Batch: 344, Loss: 0.09674499183893204\n",
      "Epoch: 5, Batch: 345, Loss: 0.001332459389232099\n",
      "Epoch: 5, Batch: 346, Loss: 0.029428616166114807\n",
      "Epoch: 5, Batch: 347, Loss: 0.0015475866384804249\n",
      "Epoch: 5, Batch: 348, Loss: 0.005908649414777756\n",
      "Epoch: 5, Batch: 349, Loss: 0.007144944742321968\n",
      "Epoch: 5, Batch: 350, Loss: 0.001231122063472867\n",
      "Epoch: 5, Batch: 351, Loss: 0.047955382615327835\n",
      "Epoch: 5, Batch: 352, Loss: 0.002121138619259\n",
      "Epoch: 5, Batch: 353, Loss: 0.026345331221818924\n",
      "Epoch: 5, Batch: 354, Loss: 0.05382952466607094\n",
      "Epoch: 5, Batch: 355, Loss: 0.021213006228208542\n",
      "Epoch: 5, Batch: 356, Loss: 0.0018167432863265276\n",
      "Epoch: 5, Batch: 357, Loss: 0.008169742301106453\n",
      "Epoch: 5, Batch: 358, Loss: 0.01994982361793518\n",
      "Epoch: 5, Batch: 359, Loss: 0.0014697867445647717\n",
      "Epoch: 5, Batch: 360, Loss: 0.014732972718775272\n",
      "Epoch: 5, Batch: 361, Loss: 0.020168012008070946\n",
      "Epoch: 5, Batch: 362, Loss: 0.024587811902165413\n",
      "Epoch: 5, Batch: 363, Loss: 0.007414615247398615\n",
      "Epoch: 5, Batch: 364, Loss: 0.022758428007364273\n",
      "Epoch: 5, Batch: 365, Loss: 0.04942357912659645\n",
      "Epoch: 5, Batch: 366, Loss: 0.0009643547818996012\n",
      "Epoch: 5, Batch: 367, Loss: 0.015380770899355412\n",
      "Epoch: 5, Batch: 368, Loss: 0.0058148885145783424\n",
      "Epoch: 5, Batch: 369, Loss: 0.006856029853224754\n",
      "Epoch: 5, Batch: 370, Loss: 0.0010353700490668416\n",
      "Epoch: 5, Batch: 371, Loss: 0.006577386520802975\n",
      "Epoch: 5, Batch: 372, Loss: 0.007848870940506458\n",
      "Epoch: 5, Batch: 373, Loss: 0.0010470780543982983\n",
      "Epoch: 5, Batch: 374, Loss: 0.0013541075168177485\n",
      "Epoch: 5, Batch: 375, Loss: 0.006129050627350807\n",
      "Epoch: 5, Batch: 376, Loss: 0.0005515362718142569\n",
      "Epoch: 5, Batch: 377, Loss: 0.0017681883182376623\n",
      "Epoch: 5, Batch: 378, Loss: 0.0024251784197986126\n",
      "Epoch: 5, Batch: 379, Loss: 0.012015460059046745\n",
      "Epoch: 5, Batch: 380, Loss: 0.0292092002928257\n",
      "Epoch: 5, Batch: 381, Loss: 0.007652437314391136\n",
      "Epoch: 5, Batch: 382, Loss: 0.017930710688233376\n",
      "Epoch: 5, Batch: 383, Loss: 0.00125981611199677\n",
      "Epoch: 5, Batch: 384, Loss: 0.01014136616140604\n",
      "Epoch: 5, Batch: 385, Loss: 0.0014143326552584767\n",
      "Epoch: 5, Batch: 386, Loss: 0.1371089071035385\n",
      "Epoch: 5, Batch: 387, Loss: 0.12451598048210144\n",
      "Epoch: 5, Batch: 388, Loss: 0.00876675732433796\n",
      "Epoch: 5, Batch: 389, Loss: 0.0005696014268323779\n",
      "Epoch: 5, Batch: 390, Loss: 0.009539203718304634\n",
      "Epoch: 5, Batch: 391, Loss: 0.003915815148502588\n",
      "Epoch: 5, Batch: 392, Loss: 0.05483631789684296\n",
      "Epoch: 5, Batch: 393, Loss: 0.00044198986142873764\n",
      "Epoch: 5, Batch: 394, Loss: 0.01879766769707203\n",
      "Epoch: 5, Batch: 395, Loss: 0.012001530267298222\n",
      "Epoch: 5, Batch: 396, Loss: 0.0035609398037195206\n",
      "Epoch: 5, Batch: 397, Loss: 0.007161786779761314\n",
      "Epoch: 5, Batch: 398, Loss: 0.0046707093715667725\n",
      "Epoch: 5, Batch: 399, Loss: 0.07474926859140396\n",
      "Epoch: 5, Batch: 400, Loss: 0.0006957977311685681\n",
      "Epoch: 5, Batch: 401, Loss: 0.0038495822809636593\n",
      "Epoch: 5, Batch: 402, Loss: 0.01763404905796051\n",
      "Epoch: 5, Batch: 403, Loss: 0.003458690829575062\n",
      "Epoch: 5, Batch: 404, Loss: 0.0010809735395014286\n",
      "Epoch: 5, Batch: 405, Loss: 0.024952763691544533\n",
      "Epoch: 5, Batch: 406, Loss: 0.0026457910425961018\n",
      "Epoch: 5, Batch: 407, Loss: 0.003380383364856243\n",
      "Epoch: 5, Batch: 408, Loss: 0.025088606402277946\n",
      "Epoch: 5, Batch: 409, Loss: 0.03742093965411186\n",
      "Epoch: 5, Batch: 410, Loss: 0.004362786654382944\n",
      "Epoch: 5, Batch: 411, Loss: 0.025718973949551582\n",
      "Epoch: 5, Batch: 412, Loss: 0.004572870675474405\n",
      "Epoch: 5, Batch: 413, Loss: 0.0026824742089957\n",
      "Epoch: 5, Batch: 414, Loss: 0.0036302281077951193\n",
      "Epoch: 5, Batch: 415, Loss: 0.003106574295088649\n",
      "Epoch: 5, Batch: 416, Loss: 0.04941746965050697\n",
      "Epoch: 5, Batch: 417, Loss: 0.0012830122141167521\n",
      "Epoch: 5, Batch: 418, Loss: 0.008635208010673523\n",
      "Epoch: 5, Batch: 419, Loss: 0.0001771728857420385\n",
      "Epoch: 5, Batch: 420, Loss: 0.005150509998202324\n",
      "Epoch: 5, Batch: 421, Loss: 0.0002756887988653034\n",
      "Epoch: 5, Batch: 422, Loss: 0.16514919698238373\n",
      "Epoch: 5, Batch: 423, Loss: 0.006594775710254908\n",
      "Epoch: 5, Batch: 424, Loss: 0.00021671620197594166\n",
      "Epoch: 5, Batch: 425, Loss: 0.12960293889045715\n",
      "Epoch: 5, Batch: 426, Loss: 0.0005550918285734951\n",
      "Epoch: 5, Batch: 427, Loss: 0.007224070839583874\n",
      "Epoch: 5, Batch: 428, Loss: 0.012196037918329239\n",
      "Epoch: 5, Batch: 429, Loss: 0.023231714963912964\n",
      "Epoch: 5, Batch: 430, Loss: 0.007917843759059906\n",
      "Epoch: 5, Batch: 431, Loss: 0.0004449512925930321\n",
      "Epoch: 5, Batch: 432, Loss: 0.12069305777549744\n",
      "Epoch: 5, Batch: 433, Loss: 0.03945637494325638\n",
      "Epoch: 5, Batch: 434, Loss: 0.0038941102102398872\n",
      "Epoch: 5, Batch: 435, Loss: 0.00015932708629406989\n",
      "Epoch: 5, Batch: 436, Loss: 0.008542870171368122\n",
      "Epoch: 5, Batch: 437, Loss: 0.005657293368130922\n",
      "Epoch: 5, Batch: 438, Loss: 0.0024349333252757788\n",
      "Epoch: 5, Batch: 439, Loss: 0.00857302825897932\n",
      "Epoch: 5, Batch: 440, Loss: 0.0031316352542489767\n",
      "Epoch: 5, Batch: 441, Loss: 0.00837380439043045\n",
      "Epoch: 5, Batch: 442, Loss: 0.028234781697392464\n",
      "Epoch: 5, Batch: 443, Loss: 0.01211301889270544\n",
      "Epoch: 5, Batch: 444, Loss: 0.006925978232175112\n",
      "Epoch: 5, Batch: 445, Loss: 0.01350511983036995\n",
      "Epoch: 5, Batch: 446, Loss: 0.010900049470365047\n",
      "Epoch: 5, Batch: 447, Loss: 0.011652493849396706\n",
      "Epoch: 5, Batch: 448, Loss: 0.009325750172138214\n",
      "Epoch: 5, Batch: 449, Loss: 0.014475801028311253\n",
      "Epoch: 5, Batch: 450, Loss: 0.0012273519532755017\n",
      "Epoch: 5, Batch: 451, Loss: 0.02857855148613453\n",
      "Epoch: 5, Batch: 452, Loss: 0.0014461716637015343\n",
      "Epoch: 5, Batch: 453, Loss: 0.02452051267027855\n",
      "Epoch: 5, Batch: 454, Loss: 0.0005231124814599752\n",
      "Epoch: 5, Batch: 455, Loss: 0.001080561662092805\n",
      "Epoch: 5, Batch: 456, Loss: 0.014729997143149376\n",
      "Epoch: 5, Batch: 457, Loss: 0.015780363231897354\n",
      "Epoch: 5, Batch: 458, Loss: 0.016276901587843895\n",
      "Epoch: 5, Batch: 459, Loss: 0.17994889616966248\n",
      "Epoch: 5, Batch: 460, Loss: 0.001878057955764234\n",
      "Epoch: 5, Batch: 461, Loss: 0.03398557007312775\n",
      "Epoch: 5, Batch: 462, Loss: 0.03207934647798538\n",
      "Epoch: 5, Batch: 463, Loss: 0.017163986340165138\n",
      "Epoch: 5, Batch: 464, Loss: 0.0012235420290380716\n",
      "Epoch: 5, Batch: 465, Loss: 0.00016365188639611006\n",
      "Epoch: 5, Batch: 466, Loss: 0.005909624043852091\n",
      "Epoch: 5, Batch: 467, Loss: 0.025172466412186623\n",
      "Epoch: 5, Batch: 468, Loss: 0.00022356609406415373\n",
      "Epoch: 5, Batch: 469, Loss: 0.023894766345620155\n",
      "Epoch: 5, Batch: 470, Loss: 0.10489725321531296\n",
      "Epoch: 5, Batch: 471, Loss: 0.019598254933953285\n",
      "Epoch: 5, Batch: 472, Loss: 0.0011406867997720838\n",
      "Epoch: 5, Batch: 473, Loss: 0.019113946706056595\n",
      "Epoch: 5, Batch: 474, Loss: 0.004119482357054949\n",
      "Epoch: 5, Batch: 475, Loss: 0.02039777860045433\n",
      "Epoch: 5, Batch: 476, Loss: 0.05869193747639656\n",
      "Epoch: 5, Batch: 477, Loss: 0.027972029522061348\n",
      "Epoch: 5, Batch: 478, Loss: 0.01064324751496315\n",
      "Epoch: 5, Batch: 479, Loss: 0.002395403804257512\n",
      "Epoch: 5, Batch: 480, Loss: 0.002598702209070325\n",
      "Epoch: 5, Batch: 481, Loss: 0.011880709789693356\n",
      "Epoch: 5, Batch: 482, Loss: 0.009106932207942009\n",
      "Epoch: 5, Batch: 483, Loss: 0.013798786327242851\n",
      "Epoch: 5, Batch: 484, Loss: 0.07704772055149078\n",
      "Epoch: 5, Batch: 485, Loss: 0.0870189517736435\n",
      "Epoch: 5, Batch: 486, Loss: 0.016309311613440514\n",
      "Epoch: 5, Batch: 487, Loss: 0.002371633192524314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Batch: 488, Loss: 0.026761546730995178\n",
      "Epoch: 5, Batch: 489, Loss: 0.025636721402406693\n",
      "Epoch: 5, Batch: 490, Loss: 0.0017560620326548815\n",
      "Epoch: 5, Batch: 491, Loss: 0.003022326622158289\n",
      "Epoch: 5, Batch: 492, Loss: 0.014896403066813946\n",
      "Epoch: 5, Batch: 493, Loss: 0.0011506748851388693\n",
      "Epoch: 5, Batch: 494, Loss: 0.03249431774020195\n",
      "Epoch: 5, Batch: 495, Loss: 0.0217910036444664\n",
      "Epoch: 5, Batch: 496, Loss: 0.0009889618959277868\n",
      "Epoch: 5, Batch: 497, Loss: 0.07913477718830109\n",
      "Epoch: 5, Batch: 498, Loss: 0.006567028351128101\n",
      "Epoch: 5, Batch: 499, Loss: 0.052774615585803986\n",
      "Epoch: 5, Batch: 500, Loss: 0.03971385583281517\n",
      "Epoch: 5, Batch: 501, Loss: 0.0037954605650156736\n",
      "Epoch: 5, Batch: 502, Loss: 0.0043023573234677315\n",
      "Epoch: 5, Batch: 503, Loss: 0.01826944202184677\n",
      "Epoch: 5, Batch: 504, Loss: 0.03471664711833\n",
      "Epoch: 5, Batch: 505, Loss: 0.022051436826586723\n",
      "Epoch: 5, Batch: 506, Loss: 0.020627982914447784\n",
      "Epoch: 5, Batch: 507, Loss: 0.0013806469505652785\n",
      "Epoch: 5, Batch: 508, Loss: 0.0009294968913309276\n",
      "Epoch: 5, Batch: 509, Loss: 0.01809081993997097\n",
      "Epoch: 5, Batch: 510, Loss: 0.012795807793736458\n",
      "Epoch: 5, Batch: 511, Loss: 0.004027793183922768\n",
      "Epoch: 5, Batch: 512, Loss: 0.0035346727818250656\n",
      "Epoch: 5, Batch: 513, Loss: 0.0032402481883764267\n",
      "Epoch: 5, Batch: 514, Loss: 0.0024001181591302156\n",
      "Epoch: 5, Batch: 515, Loss: 0.0008499564719386399\n",
      "Epoch: 5, Batch: 516, Loss: 0.0015299268998205662\n",
      "Epoch: 5, Batch: 517, Loss: 0.05503508448600769\n",
      "Epoch: 5, Batch: 518, Loss: 0.016551079228520393\n",
      "Epoch: 5, Batch: 519, Loss: 0.04421016946434975\n",
      "Epoch: 5, Batch: 520, Loss: 0.010194474831223488\n",
      "Epoch: 5, Batch: 521, Loss: 0.0018536520656198263\n",
      "Epoch: 5, Batch: 522, Loss: 0.0002865800051949918\n",
      "Epoch: 5, Batch: 523, Loss: 0.023507051169872284\n",
      "Epoch: 5, Batch: 524, Loss: 0.01646466925740242\n",
      "Epoch: 5, Batch: 525, Loss: 0.0007955721230246127\n",
      "Epoch: 5, Batch: 526, Loss: 0.09602217376232147\n",
      "Epoch: 5, Batch: 527, Loss: 0.003103811526671052\n",
      "Epoch: 5, Batch: 528, Loss: 0.10299897193908691\n",
      "Epoch: 5, Batch: 529, Loss: 0.00641749519854784\n",
      "Epoch: 5, Batch: 530, Loss: 0.0025377152487635612\n",
      "Epoch: 5, Batch: 531, Loss: 0.0014745621010661125\n",
      "Epoch: 5, Batch: 532, Loss: 0.027397487312555313\n",
      "Epoch: 5, Batch: 533, Loss: 0.037238284945487976\n",
      "Epoch: 5, Batch: 534, Loss: 0.0010373827535659075\n",
      "Epoch: 5, Batch: 535, Loss: 0.004017076455056667\n",
      "Epoch: 5, Batch: 536, Loss: 0.02116454392671585\n",
      "Epoch: 5, Batch: 537, Loss: 0.005514351185411215\n",
      "Epoch: 5, Batch: 538, Loss: 0.004391022026538849\n",
      "Epoch: 5, Batch: 539, Loss: 0.002251582220196724\n",
      "Epoch: 5, Batch: 540, Loss: 0.005012091714888811\n",
      "Epoch: 5, Batch: 541, Loss: 0.002803632989525795\n",
      "Epoch: 5, Batch: 542, Loss: 0.03552964702248573\n",
      "Epoch: 5, Batch: 543, Loss: 0.003995462786406279\n",
      "Epoch: 5, Batch: 544, Loss: 0.05060361325740814\n",
      "Epoch: 5, Batch: 545, Loss: 0.0010016924934461713\n",
      "Epoch: 5, Batch: 546, Loss: 0.0011766072129830718\n",
      "Epoch: 5, Batch: 547, Loss: 0.00032814586302265525\n",
      "Epoch: 5, Batch: 548, Loss: 0.00018666447431314737\n",
      "Epoch: 5, Batch: 549, Loss: 0.0011962286662310362\n",
      "Epoch: 5, Batch: 550, Loss: 0.003987591713666916\n",
      "Epoch: 5, Batch: 551, Loss: 0.003959625959396362\n",
      "Epoch: 5, Batch: 552, Loss: 0.00968870334327221\n",
      "Epoch: 5, Batch: 553, Loss: 0.08450596034526825\n",
      "Epoch: 5, Batch: 554, Loss: 0.053844235837459564\n",
      "Epoch: 5, Batch: 555, Loss: 0.032989729195833206\n",
      "Epoch: 5, Batch: 556, Loss: 0.002124856226146221\n",
      "Epoch: 5, Batch: 557, Loss: 0.001721625099889934\n",
      "Epoch: 5, Batch: 558, Loss: 0.0044504012912511826\n",
      "Epoch: 5, Batch: 559, Loss: 0.016906175762414932\n",
      "Epoch: 5, Batch: 560, Loss: 0.015996962785720825\n",
      "Epoch: 5, Batch: 561, Loss: 0.0024939021095633507\n",
      "Epoch: 5, Batch: 562, Loss: 0.077820785343647\n",
      "Epoch: 5, Batch: 563, Loss: 0.0016322362935170531\n",
      "Epoch: 5, Batch: 564, Loss: 0.0016910076374188066\n",
      "Epoch: 5, Batch: 565, Loss: 0.007792208809405565\n",
      "Epoch: 5, Batch: 566, Loss: 0.002687979256734252\n",
      "Epoch: 5, Batch: 567, Loss: 0.05425083264708519\n",
      "Epoch: 5, Batch: 568, Loss: 0.013393753208220005\n",
      "Epoch: 5, Batch: 569, Loss: 0.07215965539216995\n",
      "Epoch: 5, Batch: 570, Loss: 0.013567660935223103\n",
      "Epoch: 5, Batch: 571, Loss: 0.006245063617825508\n",
      "Epoch: 5, Batch: 572, Loss: 3.9160710002761334e-05\n",
      "Epoch: 5, Batch: 573, Loss: 0.005603460129350424\n",
      "Epoch: 5, Batch: 574, Loss: 0.00293313292786479\n",
      "Epoch: 5, Batch: 575, Loss: 0.049951303750276566\n",
      "Epoch: 5, Batch: 576, Loss: 0.006026349030435085\n",
      "Epoch: 5, Batch: 577, Loss: 0.003080085152760148\n",
      "Epoch: 5, Batch: 578, Loss: 0.0010162771213799715\n",
      "Epoch: 5, Batch: 579, Loss: 0.04749118164181709\n",
      "Epoch: 5, Batch: 580, Loss: 0.032440200448036194\n",
      "Epoch: 5, Batch: 581, Loss: 0.0291678998619318\n",
      "Epoch: 5, Batch: 582, Loss: 0.0058586616069078445\n",
      "Epoch: 5, Batch: 583, Loss: 0.0005519230617210269\n",
      "Epoch: 5, Batch: 584, Loss: 0.028998136520385742\n",
      "Epoch: 5, Batch: 585, Loss: 0.0058999210596084595\n",
      "Epoch: 5, Batch: 586, Loss: 0.005702147725969553\n",
      "Epoch: 5, Batch: 587, Loss: 0.001238031662069261\n",
      "Epoch: 5, Batch: 588, Loss: 0.002902038861066103\n",
      "Epoch: 5, Batch: 589, Loss: 0.04898850619792938\n",
      "Epoch: 5, Batch: 590, Loss: 0.005759925581514835\n",
      "Epoch: 5, Batch: 591, Loss: 0.001480915816500783\n",
      "Epoch: 5, Batch: 592, Loss: 0.04120515286922455\n",
      "Epoch: 5, Batch: 593, Loss: 0.00042714711162261665\n",
      "Epoch: 5, Batch: 594, Loss: 0.014202116057276726\n",
      "Epoch: 5, Batch: 595, Loss: 0.0030790800228714943\n",
      "Epoch: 5, Batch: 596, Loss: 0.007373021449893713\n",
      "Epoch: 5, Batch: 597, Loss: 0.0009503404144197702\n",
      "Epoch: 5, Batch: 598, Loss: 0.0021565642673522234\n",
      "Epoch: 5, Batch: 599, Loss: 0.015351520851254463\n",
      "Epoch: 5, Batch: 600, Loss: 0.0013604287523776293\n",
      "Epoch: 5, Batch: 601, Loss: 0.021120335906744003\n",
      "Epoch: 5, Batch: 602, Loss: 0.00881275162100792\n",
      "Epoch: 5, Batch: 603, Loss: 0.0014639946166425943\n",
      "Epoch: 5, Batch: 604, Loss: 0.0022534425370395184\n",
      "Epoch: 5, Batch: 605, Loss: 0.00787663459777832\n",
      "Epoch: 5, Batch: 606, Loss: 0.0009964975761249661\n",
      "Epoch: 5, Batch: 607, Loss: 0.011600689962506294\n",
      "Epoch: 5, Batch: 608, Loss: 0.009440531022846699\n",
      "Epoch: 5, Batch: 609, Loss: 0.04352780431509018\n",
      "Epoch: 5, Batch: 610, Loss: 0.0012827812461182475\n",
      "Epoch: 5, Batch: 611, Loss: 0.030706249177455902\n",
      "Epoch: 5, Batch: 612, Loss: 0.0032907607965171337\n",
      "Epoch: 5, Batch: 613, Loss: 0.027264101430773735\n",
      "Epoch: 5, Batch: 614, Loss: 0.014798635616898537\n",
      "Epoch: 5, Batch: 615, Loss: 0.0029055264312773943\n",
      "Epoch: 5, Batch: 616, Loss: 0.039649803191423416\n",
      "Epoch: 5, Batch: 617, Loss: 0.0013158798683434725\n",
      "Epoch: 5, Batch: 618, Loss: 0.00511556351557374\n",
      "Epoch: 5, Batch: 619, Loss: 0.021036187186837196\n",
      "Epoch: 5, Batch: 620, Loss: 0.08626066148281097\n",
      "Epoch: 5, Batch: 621, Loss: 0.06607754528522491\n",
      "Epoch: 5, Batch: 622, Loss: 0.0018837088719010353\n",
      "Epoch: 5, Batch: 623, Loss: 0.002056701108813286\n",
      "Epoch: 5, Batch: 624, Loss: 0.03567075356841087\n",
      "Epoch: 5, Batch: 625, Loss: 0.0006253846804611385\n",
      "Epoch: 5, Batch: 626, Loss: 0.09944856911897659\n",
      "Epoch: 5, Batch: 627, Loss: 0.20784702897071838\n",
      "Epoch: 5, Batch: 628, Loss: 0.0019091732101514935\n",
      "Epoch: 5, Batch: 629, Loss: 0.002958083525300026\n",
      "Epoch: 5, Batch: 630, Loss: 0.018731744959950447\n",
      "Epoch: 5, Batch: 631, Loss: 0.005409027449786663\n",
      "Epoch: 5, Batch: 632, Loss: 0.024046286940574646\n",
      "Epoch: 5, Batch: 633, Loss: 0.011181862093508244\n",
      "Epoch: 5, Batch: 634, Loss: 0.005098643712699413\n",
      "Epoch: 5, Batch: 635, Loss: 0.06240934133529663\n",
      "Epoch: 5, Batch: 636, Loss: 0.09576260298490524\n",
      "Epoch: 5, Batch: 637, Loss: 0.0328773558139801\n",
      "Epoch: 5, Batch: 638, Loss: 0.02981610968708992\n",
      "Epoch: 5, Batch: 639, Loss: 0.06821955740451813\n",
      "Epoch: 5, Batch: 640, Loss: 0.004298965446650982\n",
      "Epoch: 5, Batch: 641, Loss: 0.006330049596726894\n",
      "Epoch: 5, Batch: 642, Loss: 0.01033187098801136\n",
      "Epoch: 5, Batch: 643, Loss: 0.008618531748652458\n",
      "Epoch: 5, Batch: 644, Loss: 0.015298610553145409\n",
      "Epoch: 5, Batch: 645, Loss: 0.0008921127882786095\n",
      "Epoch: 5, Batch: 646, Loss: 0.0469878651201725\n",
      "Epoch: 5, Batch: 647, Loss: 0.006306474097073078\n",
      "Epoch: 5, Batch: 648, Loss: 0.028445804491639137\n",
      "Epoch: 5, Batch: 649, Loss: 0.0002078947436530143\n",
      "Epoch: 5, Batch: 650, Loss: 0.0010039302287623286\n",
      "Epoch: 5, Batch: 651, Loss: 0.08146587759256363\n",
      "Epoch: 5, Batch: 652, Loss: 0.026888974010944366\n",
      "Epoch: 5, Batch: 653, Loss: 0.030586430802941322\n",
      "Epoch: 5, Batch: 654, Loss: 0.02602250687777996\n",
      "Epoch: 5, Batch: 655, Loss: 0.035470150411129\n",
      "Epoch: 5, Batch: 656, Loss: 0.03826601803302765\n",
      "Epoch: 5, Batch: 657, Loss: 0.021816395223140717\n",
      "Epoch: 5, Batch: 658, Loss: 0.05664088577032089\n",
      "Epoch: 5, Batch: 659, Loss: 0.002699675038456917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Batch: 660, Loss: 0.026066100224852562\n",
      "Epoch: 5, Batch: 661, Loss: 0.017620420083403587\n",
      "Epoch: 5, Batch: 662, Loss: 0.09607391804456711\n",
      "Epoch: 5, Batch: 663, Loss: 0.012448528781533241\n",
      "Epoch: 5, Batch: 664, Loss: 0.003234265837818384\n",
      "Epoch: 5, Batch: 665, Loss: 0.06570397317409515\n",
      "Epoch: 5, Batch: 666, Loss: 0.0035545299760997295\n",
      "Epoch: 5, Batch: 667, Loss: 0.03718492016196251\n",
      "Epoch: 5, Batch: 668, Loss: 0.03046383336186409\n",
      "Epoch: 5, Batch: 669, Loss: 0.02378821186721325\n",
      "Epoch: 5, Batch: 670, Loss: 0.08504069596529007\n",
      "Epoch: 5, Batch: 671, Loss: 0.014870555140078068\n",
      "Epoch: 5, Batch: 672, Loss: 0.010505441576242447\n",
      "Epoch: 5, Batch: 673, Loss: 0.0033411281183362007\n",
      "Epoch: 5, Batch: 674, Loss: 0.006274838466197252\n",
      "Epoch: 5, Batch: 675, Loss: 0.0025303782895207405\n",
      "Epoch: 5, Batch: 676, Loss: 0.0023450700100511312\n",
      "Epoch: 5, Batch: 677, Loss: 0.0008746972889639437\n",
      "Epoch: 5, Batch: 678, Loss: 0.0415198989212513\n",
      "Epoch: 5, Batch: 679, Loss: 0.0045391106978058815\n",
      "Epoch: 5, Batch: 680, Loss: 0.011001271195709705\n",
      "Epoch: 5, Batch: 681, Loss: 0.018158117309212685\n",
      "Epoch: 5, Batch: 682, Loss: 0.06234966218471527\n",
      "Epoch: 5, Batch: 683, Loss: 0.041432417929172516\n",
      "Epoch: 5, Batch: 684, Loss: 0.003015173366293311\n",
      "Epoch: 5, Batch: 685, Loss: 0.048591919243335724\n",
      "Epoch: 5, Batch: 686, Loss: 0.05061129853129387\n",
      "Epoch: 5, Batch: 687, Loss: 0.04612438380718231\n",
      "Epoch: 5, Batch: 688, Loss: 0.06834185123443604\n",
      "Epoch: 5, Batch: 689, Loss: 0.053374890238046646\n",
      "Epoch: 5, Batch: 690, Loss: 0.00490651885047555\n",
      "Epoch: 5, Batch: 691, Loss: 0.0048009175807237625\n",
      "Epoch: 5, Batch: 692, Loss: 0.00593902450054884\n",
      "Epoch: 5, Batch: 693, Loss: 0.06539369374513626\n",
      "Epoch: 5, Batch: 694, Loss: 0.014538540504872799\n",
      "Epoch: 5, Batch: 695, Loss: 0.017196770757436752\n",
      "Epoch: 5, Batch: 696, Loss: 0.09489227086305618\n",
      "Epoch: 5, Batch: 697, Loss: 0.01605117693543434\n",
      "Epoch: 5, Batch: 698, Loss: 0.014933598227798939\n",
      "Epoch: 5, Batch: 699, Loss: 0.050148192793130875\n",
      "Epoch: 5, Batch: 700, Loss: 0.0008226976497098804\n",
      "Epoch: 5, Batch: 701, Loss: 0.003998314496129751\n",
      "Epoch: 5, Batch: 702, Loss: 0.00820012204349041\n",
      "Epoch: 5, Batch: 703, Loss: 0.008879357948899269\n",
      "Epoch: 5, Batch: 704, Loss: 0.034741152077913284\n",
      "Epoch: 5, Batch: 705, Loss: 0.017983553931117058\n",
      "Epoch: 5, Batch: 706, Loss: 0.06273090094327927\n",
      "Epoch: 5, Batch: 707, Loss: 0.036888331174850464\n",
      "Epoch: 5, Batch: 708, Loss: 0.0029266148339957\n",
      "Epoch: 5, Batch: 709, Loss: 0.026134418323636055\n",
      "Epoch: 5, Batch: 710, Loss: 0.04398230463266373\n",
      "Epoch: 5, Batch: 711, Loss: 0.025471139699220657\n",
      "Epoch: 5, Batch: 712, Loss: 0.0007116594933904707\n",
      "Epoch: 5, Batch: 713, Loss: 0.27874666452407837\n",
      "Epoch: 5, Batch: 714, Loss: 0.04756338521838188\n",
      "Epoch: 5, Batch: 715, Loss: 0.11683399975299835\n",
      "Epoch: 5, Batch: 716, Loss: 0.059152740985155106\n",
      "Epoch: 5, Batch: 717, Loss: 0.0007629623869433999\n",
      "Epoch: 5, Batch: 718, Loss: 0.008376647718250751\n",
      "Epoch: 5, Batch: 719, Loss: 0.009630754590034485\n",
      "Epoch: 5, Batch: 720, Loss: 0.0029635357204824686\n",
      "Epoch: 5, Batch: 721, Loss: 0.014357168227434158\n",
      "Epoch: 5, Batch: 722, Loss: 0.0036463914439082146\n",
      "Epoch: 5, Batch: 723, Loss: 0.009615292772650719\n",
      "Epoch: 5, Batch: 724, Loss: 0.04142753407359123\n",
      "Epoch: 5, Batch: 725, Loss: 0.014614221639931202\n",
      "Epoch: 5, Batch: 726, Loss: 0.017671139910817146\n",
      "Epoch: 5, Batch: 727, Loss: 0.0017766263335943222\n",
      "Epoch: 5, Batch: 728, Loss: 0.0203853826969862\n",
      "Epoch: 5, Batch: 729, Loss: 0.011491898447275162\n",
      "Epoch: 5, Batch: 730, Loss: 0.01587112620472908\n",
      "Epoch: 5, Batch: 731, Loss: 0.011737748980522156\n",
      "Epoch: 5, Batch: 732, Loss: 0.03301234915852547\n",
      "Epoch: 5, Batch: 733, Loss: 0.012622080743312836\n",
      "Epoch: 5, Batch: 734, Loss: 0.033078525215387344\n",
      "Epoch: 5, Batch: 735, Loss: 0.016756542026996613\n",
      "Epoch: 5, Batch: 736, Loss: 0.07669056206941605\n",
      "Epoch: 5, Batch: 737, Loss: 0.007533018942922354\n",
      "Epoch: 5, Batch: 738, Loss: 0.0046798670664429665\n",
      "Epoch: 5, Batch: 739, Loss: 0.0008850558078847826\n",
      "Epoch: 5, Batch: 740, Loss: 0.00880722887814045\n",
      "Epoch: 5, Batch: 741, Loss: 0.003955381456762552\n",
      "Epoch: 5, Batch: 742, Loss: 0.05786651372909546\n",
      "Epoch: 5, Batch: 743, Loss: 0.006301608867943287\n",
      "Epoch: 5, Batch: 744, Loss: 0.0018684436799958348\n",
      "Epoch: 5, Batch: 745, Loss: 0.007092391140758991\n",
      "Epoch: 5, Batch: 746, Loss: 0.008602742105722427\n",
      "Epoch: 5, Batch: 747, Loss: 0.0035459925420582294\n",
      "Epoch: 5, Batch: 748, Loss: 0.01544148102402687\n",
      "Epoch: 5, Batch: 749, Loss: 0.0012424300657585263\n",
      "Epoch: 5, Batch: 750, Loss: 0.007449504919350147\n",
      "Epoch: 5, Batch: 751, Loss: 0.005228925030678511\n",
      "Epoch: 5, Batch: 752, Loss: 0.010770589113235474\n",
      "Epoch: 5, Batch: 753, Loss: 0.06396802514791489\n",
      "Epoch: 5, Batch: 754, Loss: 0.134463369846344\n",
      "Epoch: 5, Batch: 755, Loss: 0.0028652858454734087\n",
      "Epoch: 5, Batch: 756, Loss: 0.07734744995832443\n",
      "Epoch: 5, Batch: 757, Loss: 0.10867162048816681\n",
      "Epoch: 5, Batch: 758, Loss: 0.014101080596446991\n",
      "Epoch: 5, Batch: 759, Loss: 0.007450695149600506\n",
      "Epoch: 5, Batch: 760, Loss: 0.0023290105164051056\n",
      "Epoch: 5, Batch: 761, Loss: 0.004414125345647335\n",
      "Epoch: 5, Batch: 762, Loss: 0.0023679574951529503\n",
      "Epoch: 5, Batch: 763, Loss: 0.0005087992758490145\n",
      "Epoch: 5, Batch: 764, Loss: 0.018207106739282608\n",
      "Epoch: 5, Batch: 765, Loss: 0.006809004116803408\n",
      "Epoch: 5, Batch: 766, Loss: 0.09949368238449097\n",
      "Epoch: 5, Batch: 767, Loss: 0.0013930608984082937\n",
      "Epoch: 5, Batch: 768, Loss: 0.010892540216445923\n",
      "Epoch: 5, Batch: 769, Loss: 0.025695914402604103\n",
      "Epoch: 5, Batch: 770, Loss: 0.059325072914361954\n",
      "Epoch: 5, Batch: 771, Loss: 0.003736466635018587\n",
      "Epoch: 5, Batch: 772, Loss: 0.07524951547384262\n",
      "Epoch: 5, Batch: 773, Loss: 0.0114100631326437\n",
      "Epoch: 5, Batch: 774, Loss: 0.01753322035074234\n",
      "Epoch: 5, Batch: 775, Loss: 0.053698163479566574\n",
      "Epoch: 5, Batch: 776, Loss: 0.021809712052345276\n",
      "Epoch: 5, Batch: 777, Loss: 0.004375480115413666\n",
      "Epoch: 5, Batch: 778, Loss: 0.10870347917079926\n",
      "Epoch: 5, Batch: 779, Loss: 0.00503897201269865\n",
      "Epoch: 5, Batch: 780, Loss: 0.00874729361385107\n",
      "Epoch: 5, Batch: 781, Loss: 0.0019429423846304417\n",
      "Epoch: 5, Batch: 782, Loss: 0.014647336676716805\n",
      "Epoch: 5, Batch: 783, Loss: 0.004681820049881935\n",
      "Epoch: 5, Batch: 784, Loss: 0.013474568724632263\n",
      "Epoch: 5, Batch: 785, Loss: 0.006353422999382019\n",
      "Epoch: 5, Batch: 786, Loss: 0.046478405594825745\n",
      "Epoch: 5, Batch: 787, Loss: 0.002921361243352294\n",
      "Epoch: 5, Batch: 788, Loss: 0.007313833571970463\n",
      "Epoch: 5, Batch: 789, Loss: 0.001530340639874339\n",
      "Epoch: 5, Batch: 790, Loss: 0.008649355731904507\n",
      "Epoch: 5, Batch: 791, Loss: 0.01718481257557869\n",
      "Epoch: 5, Batch: 792, Loss: 0.008207322098314762\n",
      "Epoch: 5, Batch: 793, Loss: 0.0026100571267306805\n",
      "Epoch: 5, Batch: 794, Loss: 0.0006416795076802373\n",
      "Epoch: 5, Batch: 795, Loss: 0.004413201939314604\n",
      "Epoch: 5, Batch: 796, Loss: 0.012561650015413761\n",
      "Epoch: 5, Batch: 797, Loss: 0.01431701797991991\n",
      "Epoch: 5, Batch: 798, Loss: 0.042574893683195114\n",
      "Epoch: 5, Batch: 799, Loss: 0.006967570167034864\n",
      "Epoch: 5, Batch: 800, Loss: 0.0035213427618145943\n",
      "Epoch: 5, Batch: 801, Loss: 0.1080150306224823\n",
      "Epoch: 5, Batch: 802, Loss: 0.004138113930821419\n",
      "Epoch: 5, Batch: 803, Loss: 0.0017268944066017866\n",
      "Epoch: 5, Batch: 804, Loss: 0.02038712240755558\n",
      "Epoch: 5, Batch: 805, Loss: 0.0038993405178189278\n",
      "Epoch: 5, Batch: 806, Loss: 0.005942653398960829\n",
      "Epoch: 5, Batch: 807, Loss: 0.014527823776006699\n",
      "Epoch: 5, Batch: 808, Loss: 0.002208427060395479\n",
      "Epoch: 5, Batch: 809, Loss: 0.015277333557605743\n",
      "Epoch: 5, Batch: 810, Loss: 0.017089011147618294\n",
      "Epoch: 5, Batch: 811, Loss: 0.002939897822216153\n",
      "Epoch: 5, Batch: 812, Loss: 0.010198240168392658\n",
      "Epoch: 5, Batch: 813, Loss: 0.0016736219404265285\n",
      "Epoch: 5, Batch: 814, Loss: 0.0010629799216985703\n",
      "Epoch: 5, Batch: 815, Loss: 0.00760893989354372\n",
      "Epoch: 5, Batch: 816, Loss: 0.018150843679904938\n",
      "Epoch: 5, Batch: 817, Loss: 0.005007469095289707\n",
      "Epoch: 5, Batch: 818, Loss: 0.00011399621143937111\n",
      "Epoch: 5, Batch: 819, Loss: 0.04347817972302437\n",
      "Epoch: 5, Batch: 820, Loss: 0.09809954464435577\n",
      "Epoch: 5, Batch: 821, Loss: 0.0775718241930008\n",
      "Epoch: 5, Batch: 822, Loss: 0.025871306657791138\n",
      "Epoch: 5, Batch: 823, Loss: 0.01449376717209816\n",
      "Epoch: 5, Batch: 824, Loss: 0.10909146070480347\n",
      "Epoch: 5, Batch: 825, Loss: 0.0708465725183487\n",
      "Epoch: 5, Batch: 826, Loss: 0.0163367111235857\n",
      "Epoch: 5, Batch: 827, Loss: 0.003716072766110301\n",
      "Epoch: 5, Batch: 828, Loss: 0.005555886309593916\n",
      "Epoch: 5, Batch: 829, Loss: 0.0009663044475018978\n",
      "Epoch: 5, Batch: 830, Loss: 0.0016411440446972847\n",
      "Epoch: 5, Batch: 831, Loss: 0.018795954063534737\n",
      "Epoch: 5, Batch: 832, Loss: 0.004391960799694061\n",
      "Epoch: 5, Batch: 833, Loss: 0.018781185150146484\n",
      "Epoch: 5, Batch: 834, Loss: 0.0002142924931831658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Batch: 835, Loss: 0.007058869581669569\n",
      "Epoch: 5, Batch: 836, Loss: 0.008917530067265034\n",
      "Epoch: 5, Batch: 837, Loss: 0.01664903573691845\n",
      "Epoch: 5, Batch: 838, Loss: 0.04259027913212776\n",
      "Epoch: 5, Batch: 839, Loss: 0.004599700681865215\n",
      "Epoch: 5, Batch: 840, Loss: 0.004849073477089405\n",
      "Epoch: 5, Batch: 841, Loss: 0.0032918930519372225\n",
      "Epoch: 5, Batch: 842, Loss: 0.003114835824817419\n",
      "Epoch: 5, Batch: 843, Loss: 0.0037136413156986237\n",
      "Epoch: 5, Batch: 844, Loss: 0.002631779294461012\n",
      "Epoch: 5, Batch: 845, Loss: 0.005414774641394615\n",
      "Epoch: 5, Batch: 846, Loss: 0.0014410142321139574\n",
      "Epoch: 5, Batch: 847, Loss: 0.10770641267299652\n",
      "Epoch: 5, Batch: 848, Loss: 0.0005163279129192233\n",
      "Epoch: 5, Batch: 849, Loss: 0.008502736687660217\n",
      "Epoch: 5, Batch: 850, Loss: 0.0033535510301589966\n",
      "Epoch: 5, Batch: 851, Loss: 0.01773492805659771\n",
      "Epoch: 5, Batch: 852, Loss: 0.00035432519507594407\n",
      "Epoch: 5, Batch: 853, Loss: 0.0220118910074234\n",
      "Epoch: 5, Batch: 854, Loss: 0.0028891712427139282\n",
      "Epoch: 5, Batch: 855, Loss: 0.02826525829732418\n",
      "Epoch: 5, Batch: 856, Loss: 0.017008084803819656\n",
      "Epoch: 5, Batch: 857, Loss: 0.0055501824244856834\n",
      "Epoch: 5, Batch: 858, Loss: 0.0014840565854683518\n",
      "Epoch: 5, Batch: 859, Loss: 0.013028502464294434\n",
      "Epoch: 5, Batch: 860, Loss: 0.0008873743936419487\n",
      "Epoch: 5, Batch: 861, Loss: 0.0006068249349482358\n",
      "Epoch: 5, Batch: 862, Loss: 0.0678049623966217\n",
      "Epoch: 5, Batch: 863, Loss: 0.035989537835121155\n",
      "Epoch: 5, Batch: 864, Loss: 0.02472583018243313\n",
      "Epoch: 5, Batch: 865, Loss: 0.0013128385180607438\n",
      "Epoch: 5, Batch: 866, Loss: 0.00415636645630002\n",
      "Epoch: 5, Batch: 867, Loss: 0.03050217218697071\n",
      "Epoch: 5, Batch: 868, Loss: 0.025162409991025925\n",
      "Epoch: 5, Batch: 869, Loss: 0.00222000596113503\n",
      "Epoch: 5, Batch: 870, Loss: 0.07867413014173508\n",
      "Epoch: 5, Batch: 871, Loss: 0.0175616554915905\n",
      "Epoch: 5, Batch: 872, Loss: 0.001365778036415577\n",
      "Epoch: 5, Batch: 873, Loss: 0.07675732672214508\n",
      "Epoch: 5, Batch: 874, Loss: 0.006455131806433201\n",
      "Epoch: 5, Batch: 875, Loss: 0.004112841561436653\n",
      "Epoch: 5, Batch: 876, Loss: 0.0010193114867433906\n",
      "Epoch: 5, Batch: 877, Loss: 0.009773404337465763\n",
      "Epoch: 5, Batch: 878, Loss: 0.0008360896608792245\n",
      "Epoch: 5, Batch: 879, Loss: 0.011028747074306011\n",
      "Epoch: 5, Batch: 880, Loss: 0.027083277702331543\n",
      "Epoch: 5, Batch: 881, Loss: 0.006551519501954317\n",
      "Epoch: 5, Batch: 882, Loss: 0.01619013398885727\n",
      "Epoch: 5, Batch: 883, Loss: 0.009186872281134129\n",
      "Epoch: 5, Batch: 884, Loss: 0.003164752386510372\n",
      "Epoch: 5, Batch: 885, Loss: 0.0020770204719156027\n",
      "Epoch: 5, Batch: 886, Loss: 0.043728165328502655\n",
      "Epoch: 5, Batch: 887, Loss: 0.00014805138926021755\n",
      "Epoch: 5, Batch: 888, Loss: 0.02640591375529766\n",
      "Epoch: 5, Batch: 889, Loss: 0.005259358324110508\n",
      "Epoch: 5, Batch: 890, Loss: 0.019112173467874527\n",
      "Epoch: 5, Batch: 891, Loss: 0.004158351570367813\n",
      "Epoch: 5, Batch: 892, Loss: 0.013166900724172592\n",
      "Epoch: 5, Batch: 893, Loss: 0.01445976085960865\n",
      "Epoch: 5, Batch: 894, Loss: 0.04286849498748779\n",
      "Epoch: 5, Batch: 895, Loss: 0.015805019065737724\n",
      "Epoch: 5, Batch: 896, Loss: 0.007157684303820133\n",
      "Epoch: 5, Batch: 897, Loss: 0.00263964687474072\n",
      "Epoch: 5, Batch: 898, Loss: 0.011185266077518463\n",
      "Epoch: 5, Batch: 899, Loss: 0.08203558623790741\n",
      "Epoch: 5, Batch: 900, Loss: 0.009210765361785889\n",
      "Epoch: 5, Batch: 901, Loss: 0.043844375759363174\n",
      "Epoch: 5, Batch: 902, Loss: 0.0017347849206998944\n",
      "Epoch: 5, Batch: 903, Loss: 0.004211734049022198\n",
      "Epoch: 5, Batch: 904, Loss: 0.0016359025612473488\n",
      "Epoch: 5, Batch: 905, Loss: 0.00913662277162075\n",
      "Epoch: 5, Batch: 906, Loss: 0.015133555047214031\n",
      "Epoch: 5, Batch: 907, Loss: 0.019630076363682747\n",
      "Epoch: 5, Batch: 908, Loss: 0.0006880535511299968\n",
      "Epoch: 5, Batch: 909, Loss: 0.02572598122060299\n",
      "Epoch: 5, Batch: 910, Loss: 0.01937621459364891\n",
      "Epoch: 5, Batch: 911, Loss: 0.006400942336767912\n",
      "Epoch: 5, Batch: 912, Loss: 0.009400798007845879\n",
      "Epoch: 5, Batch: 913, Loss: 0.009061921387910843\n",
      "Epoch: 5, Batch: 914, Loss: 0.002538571134209633\n",
      "Epoch: 5, Batch: 915, Loss: 0.03163902461528778\n",
      "Epoch: 5, Batch: 916, Loss: 0.01698443852365017\n",
      "Epoch: 5, Batch: 917, Loss: 0.004553502891212702\n",
      "Epoch: 5, Batch: 918, Loss: 0.004757083021104336\n",
      "Epoch: 5, Batch: 919, Loss: 0.006018823944032192\n",
      "Epoch: 5, Batch: 920, Loss: 4.396944495965727e-05\n",
      "Epoch: 5, Batch: 921, Loss: 0.048756975680589676\n",
      "Epoch: 5, Batch: 922, Loss: 0.0010867704404518008\n",
      "Epoch: 5, Batch: 923, Loss: 0.005086066201329231\n",
      "Epoch: 5, Batch: 924, Loss: 0.0393252894282341\n",
      "Epoch: 5, Batch: 925, Loss: 0.00012664668611250818\n",
      "Epoch: 5, Batch: 926, Loss: 0.011860737577080727\n",
      "Epoch: 5, Batch: 927, Loss: 0.045805465430021286\n",
      "Epoch: 5, Batch: 928, Loss: 0.050259124487638474\n",
      "Epoch: 5, Batch: 929, Loss: 0.0023601099383085966\n",
      "Epoch: 5, Batch: 930, Loss: 0.001394382445141673\n",
      "Epoch: 5, Batch: 931, Loss: 0.01637163758277893\n",
      "Epoch: 5, Batch: 932, Loss: 0.0006263524410314858\n",
      "Epoch: 5, Batch: 933, Loss: 0.010447440668940544\n",
      "Epoch: 5, Batch: 934, Loss: 0.0078731095418334\n",
      "Epoch: 5, Batch: 935, Loss: 0.001109790406189859\n",
      "Epoch: 5, Batch: 936, Loss: 0.03361847251653671\n",
      "Epoch: 5, Batch: 937, Loss: 0.26304543018341064\n",
      "Epoch: 6, Batch: 0, Loss: 0.003224759129807353\n",
      "Epoch: 6, Batch: 1, Loss: 0.014600616879761219\n",
      "Epoch: 6, Batch: 2, Loss: 0.00891484972089529\n",
      "Epoch: 6, Batch: 3, Loss: 0.0013148749712854624\n",
      "Epoch: 6, Batch: 4, Loss: 0.002977584255859256\n",
      "Epoch: 6, Batch: 5, Loss: 0.0071939826011657715\n",
      "Epoch: 6, Batch: 6, Loss: 0.005519011989235878\n",
      "Epoch: 6, Batch: 7, Loss: 0.005357847549021244\n",
      "Epoch: 6, Batch: 8, Loss: 0.005234039854258299\n",
      "Epoch: 6, Batch: 9, Loss: 0.009015897288918495\n",
      "Epoch: 6, Batch: 10, Loss: 0.007239754311740398\n",
      "Epoch: 6, Batch: 11, Loss: 0.019305342808365822\n",
      "Epoch: 6, Batch: 12, Loss: 0.05247350037097931\n",
      "Epoch: 6, Batch: 13, Loss: 0.005340224597603083\n",
      "Epoch: 6, Batch: 14, Loss: 0.03174680843949318\n",
      "Epoch: 6, Batch: 15, Loss: 0.0014377369079738855\n",
      "Epoch: 6, Batch: 16, Loss: 0.04431042820215225\n",
      "Epoch: 6, Batch: 17, Loss: 0.015273666940629482\n",
      "Epoch: 6, Batch: 18, Loss: 0.0009096706635318696\n",
      "Epoch: 6, Batch: 19, Loss: 0.04330635070800781\n",
      "Epoch: 6, Batch: 20, Loss: 0.011095693334937096\n",
      "Epoch: 6, Batch: 21, Loss: 0.002715072361752391\n",
      "Epoch: 6, Batch: 22, Loss: 0.0006008376367390156\n",
      "Epoch: 6, Batch: 23, Loss: 0.0024530761875212193\n",
      "Epoch: 6, Batch: 24, Loss: 0.016598260030150414\n",
      "Epoch: 6, Batch: 25, Loss: 0.0004205422883387655\n",
      "Epoch: 6, Batch: 26, Loss: 0.002298602368682623\n",
      "Epoch: 6, Batch: 27, Loss: 0.011104497127234936\n",
      "Epoch: 6, Batch: 28, Loss: 0.0025631983298808336\n",
      "Epoch: 6, Batch: 29, Loss: 0.02064386196434498\n",
      "Epoch: 6, Batch: 30, Loss: 0.0005976827815175056\n",
      "Epoch: 6, Batch: 31, Loss: 0.003311253385618329\n",
      "Epoch: 6, Batch: 32, Loss: 0.003055485663935542\n",
      "Epoch: 6, Batch: 33, Loss: 0.0010701349237933755\n",
      "Epoch: 6, Batch: 34, Loss: 0.009754424914717674\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m     61\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[0;32m---> 62\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     63\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Batch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    527\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m _engine_run_backward(\n\u001b[1;32m    268\u001b[0m     tensors,\n\u001b[1;32m    269\u001b[0m     grad_tensors_,\n\u001b[1;32m    270\u001b[0m     retain_graph,\n\u001b[1;32m    271\u001b[0m     create_graph,\n\u001b[1;32m    272\u001b[0m     inputs,\n\u001b[1;32m    273\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    274\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.layer2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.layer3 = nn.Linear(64*7*7, 128)\n",
    "        self.layer4 = nn.Dropout(p=0.25)\n",
    "        self.layer5 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.layer1(x)))\n",
    "        x = self.pool(F.relu(self.layer2(x)))\n",
    "        x = x.view(-1, 64*7*7)\n",
    "        x = F.relu(self.layer3(x))\n",
    "        x = self.layer4(x)\n",
    "        x = F.log_softmax(self.layer5(x), dim=1)\n",
    "        return x\n",
    "\n",
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "# Initialize the model, criterion, and optimizer\n",
    "model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Print the summary of the model\n",
    "summary(model, input_size=(1, 28, 28))\n",
    "\n",
    "# Training loop\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91bee2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9873\n",
      "0.9873\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(outputs, labels):\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    return correct\n",
    "\n",
    "net_correct = 0\n",
    "net_accuracy = 0\n",
    "\n",
    "for data in test_dataset:\n",
    "    x, y = data\n",
    "    output = model(x)\n",
    "    net_correct += calculate_accuracy(output, y)\n",
    "    \n",
    "net_accuracy = net_correct/len(test_dataset)\n",
    "print(net_correct)\n",
    "print(net_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
