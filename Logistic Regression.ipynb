{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3740340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d7cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"framingham.csv\")\n",
    "df = df.dropna()\n",
    "print(df.columns)\n",
    "print(df.head(20))\n",
    "labels = df.TenYearCHD.to_numpy()\n",
    "print(labels)\n",
    "## I used this line to take different combinations of different feature values and then see their rate of positives,\n",
    "## even in very severe conditions just like being now, there is still just 25% of them who have 1 as response.\n",
    "len(df[(df.prevalentHyp == 1) & (df.education == 1) & (df.totChol <= 400) & (df.totChol >= 250) & (df.age <= 60) & (df.currentSmoker == 1) & (df.TenYearCHD == 1)])/len(df[(df.prevalentHyp == 1) & (df.education == 1) & (df.totChol <= 400) & (df.totChol >= 250) & (df.age <= 60) & (df.currentSmoker == 1)])\n",
    "df = df.drop(columns=[\"TenYearCHD\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6ca7a6",
   "metadata": {},
   "source": [
    "Now will try to analyze some features in order to get the correlations between features or the relevant features in order to improve the accuracy, but it did not gave too much of help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095f054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Heatmap of Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de3b444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pointbiserialr\n",
    "\n",
    "phi_corr_matrix = pd.DataFrame(index=df.columns, columns=df.columns)\n",
    "\n",
    "# Compute the phi correlation coefficient for each pair of binary variables\n",
    "for col1 in df.columns:\n",
    "    for col2 in df.columns:\n",
    "        if col1 != col2:\n",
    "            phi_corr, _ = pointbiserialr(df[col1], df[col2])\n",
    "            phi_corr_matrix.loc[col1, col2] = phi_corr\n",
    "\n",
    "# Fill diagonal with NaNs (since correlation of a variable with itself is always 1)\n",
    "# phi_corr_matrix.values[[range(len(df.columns))]*2] = np.nan\n",
    "\n",
    "# Print the phi correlation matrix\n",
    "print(\"Phi Correlation Matrix:\")\n",
    "print(phi_corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7ed75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(phi_corr_matrix.astype(float), annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Phi Correlation Matrix Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57921849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I plotted many graphs between different features and try to understand if taking log, exp or sqrt or squaring\n",
    "# of the features will help or not, but none of them have a much significant impact on accuracy, ultimately there \n",
    "# are many outliers in the data due to which accuracy is not that great\n",
    "plt.scatter(np.sqrt(df.currentSmoker), np.sqrt(df.cigsPerDay))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd41544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now bp related columns have some significant effect on response, also they are quite interrelated, so now adding some\n",
    "# features including the product of these features\n",
    "\n",
    "df[\"nf1\"] = df[\"prevalentHyp\"]*df[\"diaBP\"]\n",
    "df[\"nf2\"] = df[\"prevalentHyp\"]*df[\"sysBP\"]\n",
    "df[\"nf3\"] = df[\"sysBP\"]*df[\"diaBP\"]*df[\"prevalentHyp\"] ## this feature will highlight more of the hypertension and hypertension has\n",
    "## a good corelation with 10yearchd in comparison to other features.\n",
    "# df[\"nf4\"] = df[\"age\"]*df[\"sysBP\"]\n",
    "# df[\"nf5\"] = df[\"glucose\"]*df[\"diabetes\"] ## this \n",
    "# df[\"nf6\"] = df[\"age\"]*df[\"totChol\"]\n",
    "## although adding above features have almost no effect on the accuracy of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f849277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def another_preprocess_data(df, labels):\n",
    "    mean_val = np.mean(df, axis=0)\n",
    "    std_dev_val = np.std(df, axis=0)\n",
    "    df = df - mean_val\n",
    "    df /= std_dev_val\n",
    "    l = len(df)\n",
    "    l_train = (4*l)//5\n",
    "    train_df = df[:l_train].to_numpy()\n",
    "    test_df = df[l_train:].to_numpy()\n",
    "    return train_df, test_df, labels[:l_train], labels[l_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04df50f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = another_preprocess_data(df, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71482e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6234bd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class logistic_regression:\n",
    "    def __init__(self, a, epochs):\n",
    "        self.a = a\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def sigmoid(self, n):\n",
    "        return 1/(1+np.exp(-n))\n",
    "    \n",
    "    def normalize(self, data):\n",
    "        data = (data-self.mean)/self.std\n",
    "        return data\n",
    "    \n",
    "    def update_w_and_b(self, data,labels,w, b, a):\n",
    "        # w being a numpy array with dimensions feat,\n",
    "        # data dim n*feat\n",
    "        # labels dimensions n,\n",
    "        feat = np.shape(data)[0]\n",
    "        n = np.shape(data)[0]\n",
    "        diff = self.sigmoid(np.sum(data*w, axis=1).astype(float)+b)-labels\n",
    "        dw = np.dot(data.T, diff) / n\n",
    "        db = np.sum(diff) / n\n",
    "        w -= a*dw\n",
    "        b -= a*db\n",
    "        return w, b\n",
    "    \n",
    "    def train(self, data, labels):\n",
    "        feat = np.shape(data)[1]\n",
    "        n = np.shape(data)[0]\n",
    "        self.w = np.zeros(feat).astype(float)\n",
    "        self.b = 0\n",
    "        self.mean = np.mean(data, axis=0)\n",
    "        self.std = np.std(data, axis=0)\n",
    "        epochs = self.epochs\n",
    "        for epoch in range(epochs):\n",
    "            self.w, self.b = self.update_w_and_b(data, labels, self.w, self.b, self.a)\n",
    "            fnp, fpp = self.evaluate(data, labels)\n",
    "            print(\"fnr: \", fnp, \"fpr, \", fpp)\n",
    "    \n",
    "    def evaluate(self,data, labels):\n",
    "        w = self.w\n",
    "        b = self.b\n",
    "        z = np.dot(data, w) + b\n",
    "        result = self.sigmoid(z)\n",
    "        result[result > 0.15]=1\n",
    "        result[result <= 0.15] = 0\n",
    "        inaccuracies = result - labels\n",
    "        false_negatives_rate = np.sum(inaccuracies == -1)/len(labels[labels == 1])\n",
    "        false_positive_rate = np.sum(inaccuracies == 1)/len(labels[labels == 0]) \n",
    "        return false_negatives_rate, false_positive_rate\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = self.normalize(X)\n",
    "        w = self.w\n",
    "        b = self.b\n",
    "        z = np.dot(X, w) + b\n",
    "        result = self.sigmoid(z)\n",
    "        result[result > 0.15]=1\n",
    "        result[result <= 0.15] = 0\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909de587",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = logistic_regression(a = 0.01, epochs = 10000)\n",
    "model.train(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdec223",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prediction = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ddcdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_prediction.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd33897",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fnr, test_fpr = model.evaluate(test_data, test_labels)\n",
    "print(f\"Test False negative rate: {test_fnr}\")\n",
    "print(f\"Test False positive rate: {test_fpr}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
