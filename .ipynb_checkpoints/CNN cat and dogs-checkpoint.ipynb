{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc1b6d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "base_dir = \"Downloads/cat and dog dataset\"\n",
    "train_path_cats = base_dir + \"/training_set/training_set/cats\"\n",
    "train_path_dogs = base_dir + \"/training_set/training_set/dogs\"\n",
    "\n",
    "test_path_cats = base_dir + \"/test_set/test_set/cats\"        \n",
    "test_path_dogs = base_dir + \"/test_set/test_set/dogs\"\n",
    "\n",
    "# print(train_path_cats)\n",
    "# print(train_path_dogs)\n",
    "# print(test_path_cats)\n",
    "# print(test_path_dogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aaabab7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Downloads/cat and dog dataset/training_set/training_set/cats'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m             images\u001b[38;5;241m.\u001b[39mappend(img)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m images\n\u001b[0;32m---> 23\u001b[0m train_cat \u001b[38;5;241m=\u001b[39m load_data_from_folder(train_path_cats)\n\u001b[1;32m     24\u001b[0m t_cat_label \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(train_cat))\n\u001b[1;32m     25\u001b[0m train_dog \u001b[38;5;241m=\u001b[39m load_data_from_folder(train_path_dogs)\n",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m, in \u001b[0;36mload_data_from_folder\u001b[0;34m(folder_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data_from_folder\u001b[39m(folder_path):\n\u001b[1;32m      5\u001b[0m     images\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(folder_path):\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m      8\u001b[0m             img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, filename)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Downloads/cat and dog dataset/training_set/training_set/cats'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "img_size = (128, 128)\n",
    "def load_data_from_folder(folder_path):\n",
    "    images=[]\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('jpg', 'png')):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "    #         print(img_path)\n",
    "            img = Image.open(img_path)\n",
    "            img = img.resize(img_size, Image.Resampling.LANCZOS)\n",
    "            img = img.convert('L')\n",
    "            \n",
    "            img = np.array(img)\n",
    "            img = img.reshape(1, 128, 128)\n",
    "    #         plt.imshow(img, cmap='gray')\n",
    "    #         plt.axis('off')\n",
    "    #         plt.show()\n",
    "            images.append(img)\n",
    "    \n",
    "    return images\n",
    "        \n",
    "train_cat = load_data_from_folder(train_path_cats)\n",
    "t_cat_label = np.zeros(len(train_cat))\n",
    "train_dog = load_data_from_folder(train_path_dogs)\n",
    "t_dog_label = np.ones(len(train_dog))\n",
    "\n",
    "train_data = np.vstack((train_cat, train_dog))\n",
    "train_label = np.hstack((t_dog_label, t_cat_label))\n",
    "# print(np.shape(train_dog))\n",
    "# print(np.shape(train_cat))\n",
    "# print(np.shape(train_data))\n",
    "print(np.shape(train_data))\n",
    "print(np.shape(train_label))\n",
    "\n",
    "index = np.arange(8005)\n",
    "print(index)\n",
    "np.random.shuffle(index)\n",
    "print(index)\n",
    "train_data = train_data[index]\n",
    "train_label = train_label[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dfd0cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2023, 1, 128, 128)\n",
      "(2023,)\n"
     ]
    }
   ],
   "source": [
    "test_cat = load_data_from_folder(test_path_cats)\n",
    "t_cat_label = np.zeros(len(test_cat))\n",
    "test_dog = load_data_from_folder(test_path_dogs)\n",
    "t_dog_label = np.ones(len(test_dog))\n",
    "\n",
    "test_data = np.vstack((test_cat, test_dog))\n",
    "test_label = np.hstack((t_dog_label, t_cat_label))\n",
    "train_data = train_data/255\n",
    "test_data = test_data/255\n",
    "# print(np.shape(train_dog))\n",
    "# print(np.shape(train_cat))\n",
    "# print(np.shape(train_data))\n",
    "print(np.shape(test_data))\n",
    "print(np.shape(test_label))\n",
    "\n",
    "index = np.arange(len(test_data))\n",
    "np.random.shuffle(index)\n",
    "test_data = test_data[index]\n",
    "test_label = test_label[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "142cff5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8005, 1, 128, 128])\n",
      "torch.Size([8005])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "train_data = torch.tensor(train_data, dtype=torch.float32)\n",
    "train_label = torch.tensor(train_label, dtype=torch.long)\n",
    "test_data = torch.tensor(test_data, dtype=torch.float32)\n",
    "test_label = torch.tensor(test_label, dtype=torch.long)\n",
    "train_data = train_data.view(8005, 1, 128, 128)\n",
    "train_label = train_label.view(8005)\n",
    "test_data = test_data.view(2023, 1, 128, 128)\n",
    "test_label = test_label.view(2023)\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbd0b894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.TensorDataset object at 0x102c6d210>\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train = TensorDataset(train_data, train_label)\n",
    "print(train)\n",
    "trainset = DataLoader(train, batch_size = 32, shuffle=True)\n",
    "# for data in trainset:\n",
    "#     x, y = data\n",
    "#     print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2003320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0.2667, 0.2627, 0.2745,  ..., 0.2941, 0.2784, 0.2745],\n",
      "          [0.2667, 0.2667, 0.2706,  ..., 0.2941, 0.2824, 0.2784],\n",
      "          [0.2667, 0.2627, 0.2667,  ..., 0.2863, 0.2863, 0.2824],\n",
      "          ...,\n",
      "          [0.3490, 0.3490, 0.3451,  ..., 0.3294, 0.3294, 0.3216],\n",
      "          [0.3412, 0.3412, 0.3412,  ..., 0.3176, 0.3216, 0.3137],\n",
      "          [0.3373, 0.3373, 0.3412,  ..., 0.3137, 0.3098, 0.3020]]],\n",
      "\n",
      "\n",
      "        [[[0.6784, 0.6745, 0.5255,  ..., 0.1373, 0.1529, 0.1647],\n",
      "          [0.4471, 0.7098, 0.7020,  ..., 0.1451, 0.1569, 0.1725],\n",
      "          [0.2314, 0.5725, 0.6627,  ..., 0.1490, 0.1647, 0.1647],\n",
      "          ...,\n",
      "          [0.3412, 0.3412, 0.3373,  ..., 0.3961, 0.3059, 0.2980],\n",
      "          [0.3176, 0.3412, 0.3333,  ..., 0.7725, 0.4667, 0.3843],\n",
      "          [0.3176, 0.3373, 0.3255,  ..., 0.6706, 0.6235, 0.5882]]],\n",
      "\n",
      "\n",
      "        [[[0.7686, 0.7608, 0.7529,  ..., 0.2118, 0.2078, 0.2000],\n",
      "          [0.7529, 0.7451, 0.7451,  ..., 0.1961, 0.1961, 0.2039],\n",
      "          [0.7529, 0.7412, 0.7490,  ..., 0.1922, 0.1961, 0.2039],\n",
      "          ...,\n",
      "          [0.6510, 0.5922, 0.6000,  ..., 0.5725, 0.5804, 0.5529],\n",
      "          [0.6157, 0.6196, 0.6353,  ..., 0.6275, 0.6157, 0.6000],\n",
      "          [0.6510, 0.6353, 0.6392,  ..., 0.6078, 0.6118, 0.6588]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0039, 0.0039, 0.0039,  ..., 0.1686, 0.2078, 0.2275],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.1765, 0.2157, 0.2157],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.1922, 0.2353, 0.2078],\n",
      "          ...,\n",
      "          [0.0941, 0.1725, 0.2549,  ..., 0.5412, 0.5333, 0.5294],\n",
      "          [0.1059, 0.1765, 0.2549,  ..., 0.5412, 0.5333, 0.5294],\n",
      "          [0.1098, 0.1765, 0.2510,  ..., 0.5373, 0.5333, 0.5294]]],\n",
      "\n",
      "\n",
      "        [[[0.2824, 0.2667, 0.2627,  ..., 0.6863, 0.6824, 0.6824],\n",
      "          [0.3608, 0.2275, 0.2549,  ..., 0.6824, 0.6824, 0.6902],\n",
      "          [0.4039, 0.3059, 0.2471,  ..., 0.6784, 0.6784, 0.6863],\n",
      "          ...,\n",
      "          [0.6235, 0.6275, 0.6235,  ..., 0.4471, 0.4549, 0.4667],\n",
      "          [0.6275, 0.6275, 0.6235,  ..., 0.4392, 0.4392, 0.4431],\n",
      "          [0.6471, 0.6392, 0.6471,  ..., 0.4471, 0.4471, 0.4588]]],\n",
      "\n",
      "\n",
      "        [[[0.2118, 0.2118, 0.2039,  ..., 0.5137, 0.5176, 0.5137],\n",
      "          [0.2078, 0.2078, 0.2039,  ..., 0.5137, 0.5176, 0.5176],\n",
      "          [0.2078, 0.2039, 0.2039,  ..., 0.5137, 0.5176, 0.5176],\n",
      "          ...,\n",
      "          [0.4706, 0.4314, 0.3804,  ..., 0.7569, 0.7569, 0.7490],\n",
      "          [0.4431, 0.4078, 0.3765,  ..., 0.7725, 0.7765, 0.7608],\n",
      "          [0.4157, 0.4275, 0.4431,  ..., 0.8314, 0.7922, 0.7804]]]]), tensor([1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 1])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb729371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.l2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.l3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.l5 = nn.Linear(128*16*16, 512)\n",
    "        self.l6 = nn.Linear(512, 2)\n",
    "#         self.l5 = nn.Linear(32, 2)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.l1(x)))\n",
    "        x = self.pool(F.relu(self.l2(x)))\n",
    "        x = self.pool(F.relu(self.l3(x)))\n",
    "#         x = self.pool(F.relu(self.l4(x)))\n",
    "        x = x.view(-1, 128*16*16)\n",
    "        x = F.relu(self.l5(x))\n",
    "#         x = self.dropout(x)\n",
    "#         x = F.relu(self.l4(x))\n",
    "        x = F.log_softmax(self.l6(x), dim=1)\n",
    "        return x\n",
    "    \n",
    "model = cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01de257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "criterian = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da5c65a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m EPOCH \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epochs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCH):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m trainset:\n\u001b[1;32m      5\u001b[0m         x,y \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m      6\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainset' is not defined"
     ]
    }
   ],
   "source": [
    "EPOCH = 50\n",
    "for epochs in range(EPOCH):\n",
    "    for data in trainset:\n",
    "        \n",
    "        x,y = data\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        new_o = model(x)\n",
    "        loss = criterian(new_o, y)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "    print(f'Epochs: {epochs}, loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92d0cfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570\n",
      "0.7760751359367276\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(outputs, labels):\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    return correct\n",
    "\n",
    "test = TensorDataset(test_data, test_label)\n",
    "testset = DataLoader(test, batch_size=2023, shuffle=True)\n",
    "net_correct = 0\n",
    "net_accuracy = 0\n",
    "\n",
    "for data in testset:\n",
    "    x, y = data\n",
    "    output = model(x)\n",
    "    net_correct += calculate_accuracy(output, y)\n",
    "    \n",
    "net_accuracy = net_correct/2023\n",
    "print(net_correct)\n",
    "print(net_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d08ca33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7971\n",
      "3.940187839841819\n"
     ]
    }
   ],
   "source": [
    "net_correct = 0\n",
    "net_accuracy = 0\n",
    "\n",
    "for data in trainset:\n",
    "    x, y = data\n",
    "    output = model(x)\n",
    "    net_correct += calculate_accuracy(output, y)\n",
    "    \n",
    "net_accuracy = net_correct/8005\n",
    "print(net_correct)\n",
    "print(net_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
